[{"title":"简博士统计学习笔记（持续更新）","date":"2026-01-06T12:00:00.000Z","path":"categories/research/学习笔记/简博士统计学习笔记/","permalink":"https://middlemanz.com/categories/research/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AE%80%E5%8D%9A%E5%A3%AB%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","text":"本文章是为B站简博士统计学习所做的笔记【合集】十分钟 机器学习 系列视频 《统计学习方法》——监督学习篇 by 简博士 （由于我看完了前三个视频才想起来要做笔记，所以笔记从1.4开始） 1.统计学习概论1.4 模型评估与模型选择1.4.1 训练误差和测试误差 训练误差是在学习系统上，对训练集的模型结果和实际结果的误差。 测试误差是在已经完成学习的系统上，对测试集的模型结果和实际结果的误差。 1.4.2 误差率和准确率 示性函数是用 0 和 1 来表示“属于某集合”这个条件是否成立的函数。 误差率：预测值和真实值不相等的样本点的个数占测试集里样本总个数的比例 准确率：预测值和真实值相等的样本点的个数占测试集里样本总个数的比例 误差率 + 准确率 &#x3D; 1 1.4.3 过拟合 龙格现象：龙格现象是高次多项式插值在等距节点上出现的端点振荡。节点越多越糟，插值曲线在两端会大幅偏离原函数。 过拟合：学习所得模型包含参数过多，出现对已知数据预测很好，但对未知数据预测很差的现象 1.5 正则化和交叉验证1.5.1 正则化 实现结构风险的最小化策略 L1 正则（L1 norm）：在损失函数里，加上 “所有权重的绝对值之和”。 L2 正则（L2 norm）：在损失函数里，加上 “所有权重平方的和”。 L1 正则让权重稀疏（变 0），L2 正则让权重变小（但不为 0）——两者都是为了防止过拟合。 奥卡姆剃刀原理：在模型选择时，选择所有可能模型中，能很好解释已知数据并且十分简单的模型 1.5.2 交叉验证 数据充足的情况下：分成训练集，验证集，测试集 不充足： 简单交叉验证：训练集，测试集 S折交叉验证：随即将数据分成S个互不相交大小相等的子集，S-1个座位训练集，余下的为测试集 S折交叉验证 1.6 泛化能力1.6.1 泛化误差 和 泛化误差上界 模型在从未见过的新数据上的误差，就是泛化误差。 泛化误差上界：模型在未来最糟糕情况下，也不会比某个水平更差。 1.7 生成模型和判别模型1.7.1 生成模型和判别模型 生成模型：先学会 X 和 Y 的联合分布 P(X, Y)，再用它推导出 P(Y|X) 来做预测。例：朴素贝叶斯和隐马尔科夫模型 判别模型：由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测模型。例：k近邻法，感知机，决策树 1.8 监督学习应用：分类问题1.8.1 分类问题：评价指标 分类准确率：对于给定测试数据集，分类器正确分类的样本与总样本数之比对于二分类问题： 预测&#x2F;真实 正类 负类 正类 TP（True positive） FP 负类 FN（False negative） TN 评价指标： 精确率： $P &#x3D; \\frac{TP}{TP+FP}$ 召回率： $R &#x3D; \\frac{TP}{TP+FN}$ 调和值： $\\frac{2}{F_{1}} &#x3D; \\frac{1}{P}+\\frac{1}{R}$ 1.8(2) 监督学习应用：回归问题和标注问题1.8.1 回归问题 类型： 按输入变量个数：一元回归，多元回归 损失函数： 平方损失 2.感知机2.1 模型介绍和学习策略2.1.1模型介绍 感知机（Perceptron） 是一种最简单的线性二分类模型，也是神经网络的起点。 给定输入向量x 感知机计算 $y &#x3D; sign(w \\cdot x + b)$ w：权重 b：偏置 sign():输出+1或-1 模型介绍：几何含义 2.1.2 学习策略 只能解决线性可分问题 损失函数： 感知机通过最大化误分类样本的函数间隔（使其变正），让所有样本最终被正确分类。$$L(w,b) &#x3D; - \\sum_{x_{i}\\in M} Y_{i}(w \\cdot x_{i}+b)$$也就是说：如果模型把某个样本分错了，就把超平面往该样本的方向稍微推一下，使它下次更容易被分对。 2.2 梯度下降法2.2.1 概念 梯度：某一函数在该点处最大的方向导数，沿着该方向可取得最大的变化率$$\\lambda &#x3D; \\frac{\\partial f(\\theta)}{\\partial \\theta}$$ 算法： 梯度下降法的算法（伪代码）1234567891011121314151617181920212223#输入：目标函数 f(θ)、步长 η、精度 ε#输出：f(θ) 的极小点 θ*#(1) 选择初始点 θ(0)theta = initial_valuek = 0while True: # (2) 计算当前函数值 f(θ(k)) f_k = f(θ) # (3) 计算梯度 ∇f(θ(k)) grad_k = gradient_of_f(θ) # (4) 按梯度下降方向更新 θ(k+1) θ_next = θ - η * grad_k # 计算更新后的函数值 f_next = f(θ_next) # 若函数变化很小 或 参数变化很小，则停止 if abs(f_next - f_k) &lt; ε or norm(θ_next - θ) &lt; ε: θ_star = θ_next break # 否则继续迭代 θ = θ_next k = k + 1#输出 θ*return θ_star 2.3 算法2.3.1 原始形式损失函数：$$L(w,b) &#x3D; - \\sum_{x_{i}\\in M} y_{i}(w \\cdot x_{i}+b)$$ 梯度： $ \\nabla_{w}L(w,b) &#x3D; - sum_{x_{i}\\in M}y_{i}x_{i} $ $ \\nabla_{b}L(w,b) &#x3D; - sum_{x_{i}\\in M}y_{i} $ 参数更新： 批量梯度下降法(batch gradient descent): 每次迭代是使用所有误分类点来进行参数更新 随机梯度下降法(stochastic gradient descent): 每次随机选出一个误分类点 感知机使用随机梯度下降法 感知机原始形式算法 2.3.2 对偶形式相比于基础形式每次都要修改w,b，对偶形式则为用所有样本的加权组合表示w,不直接存w。 $w &#x3D; \\sum_{i&#x3D;1}^{N}a_{i}y_{i}x_{i}$ $b &#x3D; \\sum_{i&#x3D;1}^{N}a_{i}y_{i}$ 2.3.3 感知机收敛定理Novikoff 感知机收敛定理：只要数据线性可分，感知机算法必定在有限步内收敛 更新次数 $k&lt;&#x3D;(\\frac{R}{r})^{2}$ 其中 r:数据间隔（两个类别的距离，越大越容易分开） R：样本向量的最大长度（数据越大越难分） 3.K近邻法（KNN）3.1概念k近邻法k近邻法是一种基本的回归和分类方法。主要思想：假定给定一个训练数据集，其中实例标签已定，当输入新的实例时，可以更具最近的K个训练实例的标签，预测新实例对应的标注信息 其中： 分类问题为通过多数表决的形式；回归问题为通过均值计算的形式。 3.1.1 误差率考虑最近邻法（k&#x3D;1）：1-近邻预测错误的概率，就是： 对每一个类别 $c_j$，新点真实是 $c_j$（概率 $P(a&#x3D;c_j)$），但最近邻不是 $c_j$（概率 $1 - P(b&#x3D;c_j)$）的概率之和。 这里最开始我没太看懂，问了一下gpt让他给我举例子： 我们做一个二分类（二类 K&#x3D;2）的问题：类别：c₁ &#x3D; 猫；c₂ &#x3D; 狗现在来了一个新样本 x，它到底是猫还是狗？ 对于新样本 x，我们知道： 它是猫的概率：$P(a&#x3D;c₁|x)$ &#x3D; 0.7;它是狗的概率：$P(a&#x3D;c₂|x)$ &#x3D; 0.3 对于它的最近邻 $x_i$，我们知道： 最近邻是猫的概率：$P(b&#x3D;c₁|x_i)$ &#x3D; 0.4;最近邻是狗的概率：$P(b&#x3D;c₂|x_i)$ &#x3D; 0.6（现实中概率来自模型估计，这里只做举例。）公式：$$Err &#x3D; \\sum^{2}_{j&#x3D;1}P(a&#x3D;c_j|x)\\cdot (1-P(b&#x3D;c_j|x_i))$$ 如果真实是猫但最近不是的话：0.7*0.6&#x3D;0.42如果真实是狗但最近不是的话：0.3*0.4&#x3D;0.12 误差率:Err&#x3D;0.42+0.12&#x3D;0.54（这个解释的我觉得非常好。） 接下来我们讨论误差率的理论上下界： 当样本无限多的时候：x的最临近点无限接近x，也就是两个点本质上相同，那么最临近的类别概率&#x3D;x的真实类别概率。所以1-NN&#x2F;k-NN(k-&gt;inf)的误差最终只由x自己决定。$$Err &#x3D; 1 - \\sum_j P(a&#x3D;c_{j})^{2}$$过程省略。 用人话解释一下就是：如果样本量已经足够大的话，影响机器分类的因素只有目标本身的分类难易程度（和机器无关）（例如：目标又像猫又像狗） 这是 k-NN 的理论误差率在样本无限多时的极限（asymptotic error）。 在继续说这个之前，我们先解释一下什么是贝叶斯误差： 贝叶斯误差贝叶斯误差是真实世界中，样本x本身就不可区分的那部分错误率，是任何分类器都无法避免的最低错误率$$P^{*}(err|x)=1-P(c^{*}|x)=1-p$$贝叶斯误差是任何分类其误差的下界，既所有分类器的误差肯定要比贝叶斯误差大。因为这是属于被预测体本身的不确定性，和模型无关 1-NN 的极限误差下界（最优情况下）达到贝叶斯误差。也就是说，1-NN 不可能比 Bayes error 更好，这也是机器学习的理论极限。通过计算可发现理论预测误差上界为2*贝叶斯误差即：$P^*&lt;&#x3D;Err_{1NN}&lt;&#x3D;2P^*$也就是说 1-NN 在最差情况下，误差最多是最优分类器的两倍，但不会更坏。 对于k-NN来说，在样本量趋向无穷大的时候，如果k随着样本量增加且满足$k→\\infty and \\frac{k}{N}→0$则k-NN的误差收敛到贝叶斯误差。（人话版：如果有无限多的数据，并且k随数据增长，k-NN会成为世界上最好的分类器） 3.2三要素3.2.1模型k近邻法(k-nearest neighbor,k-NN)不具有显性学习过程，实际上是利用训练数据集对特征向量空间进行划分，以作为分类的模型。 特征向量空间每个样本是一个向量，这些向量有很多特征（比如一只猫有特征身长和体重等等），所有这些向量所在的空间就叫特征向量空间 3.2.2距离度量$L_p$距离：$$L_p(x_i,x_j)&#x3D;(\\sum_{I&#x3D;1}^N |x_i^{(I)}-x_{j}^{(I)}|^{P})^{\\frac{1}{p}}, p\\geq 1$$ 注： 如果p&#x3D;2的话就是我们平常熟知的欧氏距离，也就是两点间距离公式$\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$ p&#x3D;1时叫做曼哈顿距离（因为走起来只能横竖走，像曼哈顿的街区一样）比如从(1,2)走到(4,6)就是(4-1)+(6-2)&#x3D;7。 p&#x3D;正无穷的时候叫做切比雪夫距离(Chebyshev distance)：走任意方向，代价由“最大的坐标差来决定”，比如之前的那个例子的话从(1,2)走到(4,6)就是max(|x1-x2|,|y1-y2|)&#x3D;4。（其实这个是国际象棋王的移动方式，上下左右斜。一步可以改变两个方向，所以距离等于最大方向差） $L_p$距离中,P越大，越强调各个坐标差值的最大值。当P趋近于无穷时，$L_p$完全由最大差值决定 不同的距离度量，也就是不同的P，取得的最近邻点也是不同的 3.2.3 k-值的选择 较小的k值，学习的近似误差减少，但是估计误差增大，敏感性增强，模型复杂容易过拟合 较大的k值，减少学习的估计误差，但近似误差增大，而且模型简单 近似误差模型能不能代表真实规律——模型本身有多差 估计误差数据不够多导致估计模型参数是出现的误差 随着 k 的增大，kNN 的预测由更大范围的样本平均决定，模型对局部噪声的敏感性降低，决策边界更加平滑，可表示的函数空间受到更强约束，因此模型复杂度降低。 3.2.4 分类决策规则 多数表决规则：有输入实例的k个近邻训练示例中的多数类决定输入实例的类。 为了形式化这一规则，引入指示函数 I(⋅)。当条件成立时I(⋅)&#x3D;1，否则为 0。因此，I(yi&#x3D;cj) 表示第𝑖个近邻样本是否属于类别 cj。 误分类率：$$\\frac{1}{k}\\sum_{x_i\\in N_k(x)}I(y_i \\neq c_j )&#x3D;1-\\frac{1}{k}\\sum_{x_i\\in N_k(x)}I(y_i &#x3D; c_j)$$ 最小化误分类率也就是最大化正确率等价于：$$arg max \\sum_{x_i\\in N_k(x)}I(y_i &#x3D; c_j)$$ 上式表明，kNN 分类的最优决策等价于在近邻集合中选择样本数最多的类别，即多数表决原则。","content":"<p>本文章是为B站简博士统计学习所做的笔记<br><u>【合集】十分钟 机器学习 系列视频 《统计学习方法》——监督学习篇</u> by 简博士</p>\n<span id=\"more\"></span>\n\n<p>（由于我看完了前三个视频才想起来要做笔记，所以笔记从1.4开始）</p>\n<h2 id=\"1-统计学习概论\"><a href=\"#1-统计学习概论\" class=\"headerlink\" title=\"1.统计学习概论\"></a>1.统计学习概论</h2><h2 id=\"1-4-模型评估与模型选择\"><a href=\"#1-4-模型评估与模型选择\" class=\"headerlink\" title=\"1.4 模型评估与模型选择\"></a>1.4 模型评估与模型选择</h2><h3 id=\"1-4-1-训练误差和测试误差\"><a href=\"#1-4-1-训练误差和测试误差\" class=\"headerlink\" title=\"1.4.1 训练误差和测试误差\"></a>1.4.1 训练误差和测试误差</h3><ul>\n<li>训练误差是在学习系统上，对训练集的模型结果和实际结果的误差。</li>\n<li>测试误差是在已经完成学习的系统上，对测试集的模型结果和实际结果的误差。</li>\n</ul>\n<h3 id=\"1-4-2-误差率和准确率\"><a href=\"#1-4-2-误差率和准确率\" class=\"headerlink\" title=\"1.4.2 误差率和准确率\"></a>1.4.2 误差率和准确率</h3><ul>\n<li>示性函数是用 0 和 1 来表示“属于某集合”这个条件是否成立的函数。</li>\n<li><u>误差率：</u>预测值和真实值不相等的样本点的个数占测试集里样本总个数的比例</li>\n<li><u>准确率</u>：预测值和真实值相等的样本点的个数占测试集里样本总个数的比例</li>\n<li><u>误差率 + 准确率 &#x3D; 1</u></li>\n</ul>\n<h3 id=\"1-4-3-过拟合\"><a href=\"#1-4-3-过拟合\" class=\"headerlink\" title=\"1.4.3 过拟合\"></a>1.4.3 过拟合</h3><ul>\n<li><u>龙格现象：</u>龙格现象是高次多项式插值在等距节点上出现的端点振荡。节点越多越糟，插值曲线在两端会大幅偏离原函数。</li>\n<li><u>过拟合：</u>学习所得模型包含参数过多，出现对已知数据预测很好，但对未知数据预测很差的现象</li>\n</ul>\n<h2 id=\"1-5-正则化和交叉验证\"><a href=\"#1-5-正则化和交叉验证\" class=\"headerlink\" title=\"1.5 正则化和交叉验证\"></a>1.5 正则化和交叉验证</h2><h3 id=\"1-5-1-正则化\"><a href=\"#1-5-1-正则化\" class=\"headerlink\" title=\"1.5.1 正则化\"></a>1.5.1 正则化</h3><ul>\n<li>实现结构风险的最小化策略</li>\n<li><u>L1 正则（L1 norm）：</u>在损失函数里，加上 “所有权重的绝对值之和”。</li>\n<li><u>L2 正则（L2 norm）：</u>在损失函数里，加上 “所有权重平方的和”。<ul>\n<li>L1 正则让权重稀疏（变 0），L2 正则让权重变小（但不为 0）——两者都是为了防止过拟合。</li>\n</ul>\n</li>\n<li><u>奥卡姆剃刀原理：</u>在模型选择时，选择所有可能模型中，能很好解释已知数据并且十分简单的模型</li>\n</ul>\n<h3 id=\"1-5-2-交叉验证\"><a href=\"#1-5-2-交叉验证\" class=\"headerlink\" title=\"1.5.2 交叉验证\"></a>1.5.2 交叉验证</h3><ul>\n<li><u>数据充足的情况下：</u>分成训练集，验证集，测试集</li>\n<li><u>不充足</u>：<ul>\n<li><u>简单交叉验证：</u>训练集，测试集</li>\n<li><u>S折交叉验证：</u>随即将数据分成S个互不相交大小相等的子集，S-1个座位训练集，余下的为测试集</li>\n</ul>\n</li>\n</ul>\n<div align=\"center\">\n  <img src=\"/images/research/notes/简博士统计学习笔记/S折交叉验证.png\" class=\"lazyload\" data-srcset=\"/images/research/notes/简博士统计学习笔记/S折交叉验证.png\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"描述文字\" width=\"70%\">\n  <p style=\"text-align:center;\">S折交叉验证</p >\n</div>\n\n<h2 id=\"1-6-泛化能力\"><a href=\"#1-6-泛化能力\" class=\"headerlink\" title=\"1.6 泛化能力\"></a>1.6 泛化能力</h2><h3 id=\"1-6-1-泛化误差-和-泛化误差上界\"><a href=\"#1-6-1-泛化误差-和-泛化误差上界\" class=\"headerlink\" title=\"1.6.1 泛化误差 和 泛化误差上界\"></a>1.6.1 泛化误差 和 泛化误差上界</h3><ul>\n<li>模型在从未见过的新数据上的误差，就是泛化误差。</li>\n<li><u>泛化误差上界：</u>模型在未来最糟糕情况下，也不会比某个水平更差。</li>\n</ul>\n<h2 id=\"1-7-生成模型和判别模型\"><a href=\"#1-7-生成模型和判别模型\" class=\"headerlink\" title=\"1.7 生成模型和判别模型\"></a>1.7 生成模型和判别模型</h2><h3 id=\"1-7-1-生成模型和判别模型\"><a href=\"#1-7-1-生成模型和判别模型\" class=\"headerlink\" title=\"1.7.1 生成模型和判别模型\"></a>1.7.1 生成模型和判别模型</h3><ul>\n<li><u>生成模型：</u>先学会 X 和 Y 的联合分布 P(X, Y)，再用它推导出 P(Y|X) 来做预测。例：朴素贝叶斯和隐马尔科夫模型</li>\n<li><u>判别模型：</u>由数据直接学习决策函数f(X)或者条件概率分布P(Y|X)作为预测模型。例：k近邻法，感知机，决策树</li>\n</ul>\n<h2 id=\"1-8-监督学习应用：分类问题\"><a href=\"#1-8-监督学习应用：分类问题\" class=\"headerlink\" title=\"1.8 监督学习应用：分类问题\"></a>1.8 监督学习应用：分类问题</h2><h3 id=\"1-8-1-分类问题：评价指标\"><a href=\"#1-8-1-分类问题：评价指标\" class=\"headerlink\" title=\"1.8.1 分类问题：评价指标\"></a>1.8.1 分类问题：评价指标</h3><ul>\n<li><u>分类准确率：</u>对于给定测试数据集，分类器正确分类的样本与总样本数之比<br>对于二分类问题：</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>预测&#x2F;真实</th>\n<th>正类</th>\n<th>负类</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>正类</td>\n<td>TP（True positive）</td>\n<td>FP</td>\n</tr>\n<tr>\n<td>负类</td>\n<td>FN（False negative）</td>\n<td>TN</td>\n</tr>\n</tbody></table>\n<p><u>评价指标：</u></p>\n<ul>\n<li><u>精确率：</u> $P &#x3D; \\frac{TP}{TP+FP}$</li>\n<li><u>召回率：</u> $R &#x3D; \\frac{TP}{TP+FN}$</li>\n<li><u>调和值：</u> $\\frac{2}{F_{1}} &#x3D; \\frac{1}{P}+\\frac{1}{R}$</li>\n</ul>\n<h2 id=\"1-8-2-监督学习应用：回归问题和标注问题\"><a href=\"#1-8-2-监督学习应用：回归问题和标注问题\" class=\"headerlink\" title=\"1.8(2) 监督学习应用：回归问题和标注问题\"></a>1.8(2) 监督学习应用：回归问题和标注问题</h2><h3 id=\"1-8-1-回归问题\"><a href=\"#1-8-1-回归问题\" class=\"headerlink\" title=\"1.8.1 回归问题\"></a>1.8.1 回归问题</h3><ul>\n<li>类型：</li>\n<li>按输入变量个数：一元回归，多元回归</li>\n<li>损失函数： 平方损失</li>\n</ul>\n<h2 id=\"2-感知机\"><a href=\"#2-感知机\" class=\"headerlink\" title=\"2.感知机\"></a>2.感知机</h2><h2 id=\"2-1-模型介绍和学习策略\"><a href=\"#2-1-模型介绍和学习策略\" class=\"headerlink\" title=\"2.1 模型介绍和学习策略\"></a>2.1 模型介绍和学习策略</h2><h3 id=\"2-1-1模型介绍\"><a href=\"#2-1-1模型介绍\" class=\"headerlink\" title=\"2.1.1模型介绍\"></a>2.1.1模型介绍</h3><ul>\n<li>感知机（Perceptron） 是一种最简单的线性二分类模型，也是神经网络的起点。</li>\n<li>给定输入向量x 感知机计算 $y &#x3D; sign(w \\cdot x + b)$<ul>\n<li>w：权重</li>\n<li>b：偏置</li>\n<li>sign():输出+1或-1</li>\n</ul>\n</li>\n</ul>\n<div align=\"center\">\n  <img src=\"/images/research/notes/简博士统计学习笔记/感知机模型介绍.png\" class=\"lazyload\" data-srcset=\"/images/research/notes/简博士统计学习笔记/感知机模型介绍.png\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"描述文字\" width=\"70%\">\n  <p style=\"text-align:center;\">模型介绍：几何含义</p >\n</div>\n\n<h3 id=\"2-1-2-学习策略\"><a href=\"#2-1-2-学习策略\" class=\"headerlink\" title=\"2.1.2 学习策略\"></a>2.1.2 学习策略</h3><ul>\n<li>只能解决线性可分问题</li>\n<li><u>损失函数：</u> 感知机通过最大化误分类样本的函数间隔（使其变正），让所有样本最终被正确分类。<br>$$L(w,b) &#x3D; - \\sum_{x_{i}\\in M} Y_{i}(w \\cdot x_{i}+b)$$<br>也就是说：如果模型把某个样本分错了，就把超平面往该样本的方向稍微推一下，使它下次更容易被分对。</li>\n</ul>\n<h2 id=\"2-2-梯度下降法\"><a href=\"#2-2-梯度下降法\" class=\"headerlink\" title=\"2.2 梯度下降法\"></a>2.2 梯度下降法</h2><h3 id=\"2-2-1-概念\"><a href=\"#2-2-1-概念\" class=\"headerlink\" title=\"2.2.1 概念\"></a>2.2.1 概念</h3><ul>\n<li><u>梯度：</u>某一函数在该点处最大的方向导数，沿着该方向可取得最大的变化率<br>$$\\lambda &#x3D; \\frac{\\partial f(\\theta)}{\\partial \\theta}$$</li>\n<li><u>算法：</u></li>\n</ul>\n<figure class=\"highlight python\"><figcaption><span>梯度下降法的算法（伪代码）</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#输入：目标函数 f(θ)、步长 η、精度 ε</span></span><br><span class=\"line\"><span class=\"comment\">#输出：f(θ) 的极小点 θ*</span></span><br><span class=\"line\"><span class=\"comment\">#(1) 选择初始点 θ(0)</span></span><br><span class=\"line\">theta = initial_value</span><br><span class=\"line\">k = <span class=\"number\">0</span></span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    <span class=\"comment\"># (2) 计算当前函数值 f(θ(k))</span></span><br><span class=\"line\">    f_k = f(θ)</span><br><span class=\"line\">    <span class=\"comment\"># (3) 计算梯度 ∇f(θ(k))</span></span><br><span class=\"line\">    grad_k = gradient_of_f(θ)</span><br><span class=\"line\">    <span class=\"comment\"># (4) 按梯度下降方向更新 θ(k+1)</span></span><br><span class=\"line\">    θ_<span class=\"built_in\">next</span> = θ - η * grad_k</span><br><span class=\"line\">    <span class=\"comment\"># 计算更新后的函数值</span></span><br><span class=\"line\">    f_next = f(θ_<span class=\"built_in\">next</span>)</span><br><span class=\"line\">    <span class=\"comment\"># 若函数变化很小 或 参数变化很小，则停止</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">abs</span>(f_next - f_k) &lt; ε <span class=\"keyword\">or</span> norm(θ_<span class=\"built_in\">next</span> - θ) &lt; ε:</span><br><span class=\"line\">        θ_star = θ_<span class=\"built_in\">next</span></span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">    <span class=\"comment\"># 否则继续迭代</span></span><br><span class=\"line\">    θ = θ_<span class=\"built_in\">next</span></span><br><span class=\"line\">    k = k + <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"comment\">#输出 θ*</span></span><br><span class=\"line\"><span class=\"keyword\">return</span> θ_star</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"2-3-算法\"><a href=\"#2-3-算法\" class=\"headerlink\" title=\"2.3 算法\"></a>2.3 算法</h2><h3 id=\"2-3-1-原始形式\"><a href=\"#2-3-1-原始形式\" class=\"headerlink\" title=\"2.3.1 原始形式\"></a>2.3.1 原始形式</h3><p><u>损失函数：</u><br>$$<br>L(w,b) &#x3D; - \\sum_{x_{i}\\in M} y_{i}(w \\cdot x_{i}+b)<br>$$</p>\n<p><u>梯度：</u></p>\n<ul>\n<li>$ \\nabla_{w}L(w,b) &#x3D; - sum_{x_{i}\\in M}y_{i}x_{i} $ </li>\n<li>$ \\nabla_{b}L(w,b) &#x3D; - sum_{x_{i}\\in M}y_{i} $</li>\n</ul>\n<p><u>参数更新：</u></p>\n<ul>\n<li>批量梯度下降法(batch gradient descent): 每次迭代是使用所有误分类点来进行参数更新</li>\n<li>随机梯度下降法(stochastic gradient descent): 每次随机选出一个误分类点</li>\n<li><u>感知机使用随机梯度下降法</u></li>\n</ul>\n<div align=\"center\">\n  <img src=\"/images/record/notes/简博士统计学习笔记/感知机原始形式算法.jpg\" class=\"lazyload\" data-srcset=\"/images/record/notes/简博士统计学习笔记/感知机原始形式算法.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"描述文字\" width=\"70%\">\n  <p style=\"text-align:center;\">感知机原始形式算法</p >\n</div>\n\n<h3 id=\"2-3-2-对偶形式\"><a href=\"#2-3-2-对偶形式\" class=\"headerlink\" title=\"2.3.2 对偶形式\"></a>2.3.2 对偶形式</h3><p>相比于基础形式每次都要修改w,b，对偶形式则为用所有样本的加权组合表示w,不直接存w。</p>\n<ul>\n<li>$w &#x3D; \\sum_{i&#x3D;1}^{N}a_{i}y_{i}x_{i}$</li>\n<li>$b &#x3D; \\sum_{i&#x3D;1}^{N}a_{i}y_{i}$</li>\n</ul>\n<h3 id=\"2-3-3-感知机收敛定理\"><a href=\"#2-3-3-感知机收敛定理\" class=\"headerlink\" title=\"2.3.3 感知机收敛定理\"></a>2.3.3 感知机收敛定理</h3><p><u>Novikoff 感知机收敛定理：</u>只要数据线性可分，感知机算法必定在有限步内收敛 </p>\n<ul>\n<li>更新次数 $k&lt;&#x3D;(\\frac{R}{r})^{2}$</li>\n<li>其中 r:数据间隔（两个类别的距离，越大越容易分开）</li>\n<li>R：样本向量的最大长度（数据越大越难分）</li>\n</ul>\n<h2 id=\"3-K近邻法（KNN）\"><a href=\"#3-K近邻法（KNN）\" class=\"headerlink\" title=\"3.K近邻法（KNN）\"></a>3.K近邻法（KNN）</h2><h2 id=\"3-1概念\"><a href=\"#3-1概念\" class=\"headerlink\" title=\"3.1概念\"></a>3.1概念</h2><div class=\"note info\"><p>k近邻法<br>k近邻法是一种基本的回归和分类方法。<br>主要思想：假定给定一个训练数据集，其中实例标签已定，当输入新的实例时，可以更具最近的K个训练实例的标签，预测新实例对应的标注信息</p></div>\n<p>其中： 分类问题为通过多数表决的形式；回归问题为通过均值计算的形式。</p>\n<h3 id=\"3-1-1-误差率\"><a href=\"#3-1-1-误差率\" class=\"headerlink\" title=\"3.1.1 误差率\"></a>3.1.1 误差率</h3><p>考虑最近邻法（k&#x3D;1）：1-近邻预测错误的概率，就是：</p>\n<p>对每一个类别 $c_j$，新点真实是 $c_j$（概率 $P(a&#x3D;c_j)$），但最近邻不是 $c_j$（概率 $1 - P(b&#x3D;c_j)$）的概率之和。</p>\n<p>这里最开始我没太看懂，问了一下gpt让他给我举例子：</p>\n<hr>\n<p>我们做一个<u>二分类（二类 K&#x3D;2）</u>的问题：<br><br>类别：c₁ &#x3D; 猫；c₂ &#x3D; 狗<br>现在来了一个新样本 x，它到底是猫还是狗？<br></p>\n<p>对于新样本 x，我们知道：<br></p>\n<p>它是猫的概率：$P(a&#x3D;c₁|x)$ &#x3D; 0.7;<br><br>它是狗的概率：$P(a&#x3D;c₂|x)$ &#x3D; 0.3 <br></p>\n<p>对于它的最近邻 $x_i$，我们知道： <br></p>\n<p>最近邻是猫的概率：$P(b&#x3D;c₁|x_i)$ &#x3D; 0.4;<br><br>最近邻是狗的概率：$P(b&#x3D;c₂|x_i)$ &#x3D; 0.6<br><br>（现实中概率来自模型估计，这里只做举例。）<br><br>公式：<br>$$<br>Err &#x3D; \\sum^{2}_{j&#x3D;1}P(a&#x3D;c_j|x)\\cdot (1-P(b&#x3D;c_j|x_i))<br>$$</p>\n<p>如果真实是猫但最近不是的话：0.7*0.6&#x3D;0.42<br><br>如果真实是狗但最近不是的话：0.3*0.4&#x3D;0.12<br></p>\n<p><u>误差率:</u>Err&#x3D;0.42+0.12&#x3D;0.54<br>（这个解释的我觉得非常好。）</p>\n<hr>\n<p><u>接下来我们讨论误差率的理论上下界：</u></p>\n<p>当样本无限多的时候：x的最临近点无限接近x，也就是两个点本质上相同，那么最临近的类别概率&#x3D;x的真实类别概率。所以1-NN&#x2F;k-NN(k-&gt;inf)的误差最终只由x自己决定。<br>$$<br>Err &#x3D; 1 - \\sum_j P(a&#x3D;c_{j})^{2}<br>$$<br>过程省略。</p>\n<p>用人话解释一下就是：如果样本量已经足够大的话，影响机器分类的因素只有目标本身的分类难易程度（和机器无关）（例如：目标又像猫又像狗）</p>\n<p>这是 k-NN 的理论误差率在样本无限多时的极限（asymptotic error）。</p>\n<hr>\n<p>在继续说这个之前，我们先解释一下什么是贝叶斯误差：</p>\n<div class=\"note info\"><h4>贝叶斯误差</h4>贝叶斯误差是真实世界中，样本x本身就不可区分的那部分错误率，是任何分类器都无法避免的最低错误率$$P^{*}(err|x)=1-P(c^{*}|x)=1-p$$贝叶斯误差是任何分类其误差的下界，既所有分类器的误差肯定要比贝叶斯误差大。因为这是属于被预测体本身的不确定性，和模型无关</div>\n\n<p>1-NN 的极限误差下界（最优情况下）达到贝叶斯误差。也就是说，1-NN 不可能比 Bayes error 更好，这也是机器学习的理论极限。通过计算可发现<u>理论预测误差上界为2*贝叶斯误差</u>即：<br>$P^*&lt;&#x3D;Err_{1NN}&lt;&#x3D;2P^*$也就是说 1-NN 在最差情况下，误差最多是最优分类器的两倍，但不会更坏。</p>\n<p>对于k-NN来说，在样本量趋向无穷大的时候，如果k随着样本量增加且满足$k→\\infty and \\frac{k}{N}→0$则k-NN的误差收敛到贝叶斯误差。（人话版：如果有无限多的数据，并且k随数据增长，k-NN会成为世界上最好的分类器）</p>\n<h2 id=\"3-2三要素\"><a href=\"#3-2三要素\" class=\"headerlink\" title=\"3.2三要素\"></a>3.2三要素</h2><h3 id=\"3-2-1模型\"><a href=\"#3-2-1模型\" class=\"headerlink\" title=\"3.2.1模型\"></a>3.2.1模型</h3><p>k近邻法(k-nearest neighbor,k-NN)不具有显性学习过程，实际上是利用训练数据集对特征向量空间进行划分，以作为分类的模型。</p>\n<div class=\"note info\"><h4>特征向量空间</h4>每个样本是一个向量，这些向量有很多特征（比如一只猫有特征身长和体重等等），所有这些向量所在的空间就叫特征向量空间</div>\n\n<h3 id=\"3-2-2距离度量\"><a href=\"#3-2-2距离度量\" class=\"headerlink\" title=\"3.2.2距离度量\"></a>3.2.2距离度量</h3><p>$L_p$距离：<br>$$<br>L_p(x_i,x_j)&#x3D;(\\sum_{I&#x3D;1}^N |x_i^{(I)}-x_{j}^{(I)}|^{P})^{\\frac{1}{p}}, p\\geq 1<br>$$</p>\n<p>注：</p>\n<ul>\n<li><p>如果p&#x3D;2的话就是我们平常熟知的欧氏距离，也就是两点间距离公式$\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$</p>\n</li>\n<li><p>p&#x3D;1时叫做曼哈顿距离（因为走起来只能横竖走，像曼哈顿的街区一样）比如从(1,2)走到(4,6)就是(4-1)+(6-2)&#x3D;7。</p>\n</li>\n<li><p>p&#x3D;正无穷的时候叫做切比雪夫距离(Chebyshev distance)：走任意方向，代价由“最大的坐标差来决定”，比如之前的那个例子的话从(1,2)走到(4,6)就是max(|x1-x2|,|y1-y2|)&#x3D;4。（其实这个是国际象棋王的移动方式，上下左右斜。一步可以改变两个方向，所以距离等于最大方向差）</p>\n</li>\n<li><p>$L_p$距离中,P越大，越强调各个坐标差值的最大值。当P趋近于无穷时，$L_p$完全由最大差值决定</p>\n</li>\n<li><p><u>不同的距离度量，也就是不同的P，取得的最近邻点也是不同的</u></p>\n</li>\n</ul>\n<h3 id=\"3-2-3-k-值的选择\"><a href=\"#3-2-3-k-值的选择\" class=\"headerlink\" title=\"3.2.3 k-值的选择\"></a>3.2.3 k-值的选择</h3><ul>\n<li>较小的k值，学习的近似误差减少，但是估计误差增大，敏感性增强，模型复杂容易过拟合</li>\n<li>较大的k值，减少学习的估计误差，但近似误差增大，而且模型简单</li>\n</ul>\n<div class=\"note info\"><h4>近似误差</h4>模型能不能代表真实规律——模型本身有多差</div>\n<div class=\"note info\"><h4>估计误差</h4>数据不够多导致估计模型参数是出现的误差</div>\n<ul>\n<li>随着 k 的增大，kNN 的预测由更大范围的样本平均决定，模型对局部噪声的敏感性降低，决策边界更加平滑，可表示的函数空间受到更强约束，因此模型复杂度降低。</li>\n<li></li>\n</ul>\n<h3 id=\"3-2-4-分类决策规则\"><a href=\"#3-2-4-分类决策规则\" class=\"headerlink\" title=\"3.2.4 分类决策规则\"></a>3.2.4 分类决策规则</h3><ul>\n<li>多数表决规则：有输入实例的k个近邻训练示例中的多数类决定输入实例的类。</li>\n<li>为了形式化这一规则，引入指示函数 I(⋅)。当条件成立时I(⋅)&#x3D;1，否则为 0。因此，I(yi&#x3D;cj) 表示第𝑖个近邻样本是否属于类别 cj。</li>\n<li>误分类率：<br>$$<br>\\frac{1}{k}\\sum_{x_i\\in N_k(x)}I(y_i \\neq c_j )&#x3D;1-\\frac{1}{k}\\sum_{x_i\\in N_k(x)}I(y_i &#x3D; c_j)<br>$$</li>\n<li>最小化误分类率也就是最大化正确率等价于：<br>$$<br>arg max \\sum_{x_i\\in N_k(x)}I(y_i &#x3D; c_j)<br>$$</li>\n<li>上式表明，kNN 分类的最优决策等价于在近邻集合中选择样本数最多的类别，即多数表决原则。</li>\n</ul>\n","categories":[{"name":"research","slug":"research","permalink":"https://middlemanz.com/categories/research/"},{"name":"学习笔记","slug":"research/notes","permalink":"https://middlemanz.com/categories/research/notes/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://middlemanz.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"学习笔记","slug":"学习笔记","permalink":"https://middlemanz.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"},{"name":"统计学习","slug":"统计学习","permalink":"https://middlemanz.com/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/"}]},{"title":"炸弹克星短评","date":"2025-11-23T09:31:00.000Z","path":"categories/daily/桌游/炸弹克星短评/","permalink":"https://middlemanz.com/categories/daily/%E6%A1%8C%E6%B8%B8/%E7%82%B8%E5%BC%B9%E5%85%8B%E6%98%9F%E7%9F%AD%E8%AF%84/","text":"今年第一，全体前五 炸弹克星 经过五个小时的战斗，四个人一致认为炸弹克星是非常非常有趣。（以至于本来准备玩的第二个桌游都没玩🤣） 他有一种返璞归真的乐趣。游戏本质是抽对子（就是扑克的那种），但是加入了一定的规则使得抽对子变得有一些逻辑性和复杂度。游戏并不依靠复杂的机制或者精致的模型来吸引玩家，仅仅靠着简单的规则就产生了如此巨大的吸引力。 同时，为了避免规则简单而导致的同质化，游戏还把关卡给分成了若干部分，比如1-8.9-19等等。每一个部分都会给游戏加上独特的规则和机制，让玩家在游玩过程中始终能有新鲜感。例如有的关卡会加上时间限制，有的关卡会让你按顺序进行拆弹等等。 游戏存在一个小小的缺点：依靠玩家的表现。在一场游戏中，如果玩家都是非常认真的只冲着结果去的话，游戏就会显得略微无趣。但如果玩家擅长主动给游戏增加乐趣——也就是所谓的“有活儿”，那么游戏将会出现许多令人捧腹大笑的名场面。 另一个可能算缺点的就是，游戏里自带的板块放置栏有一点轻，导致如果有人手残的话某个动作会把所有的卡片都亮出来导致游戏必须重开（要不然就没有乐趣了）。","content":"<div class=\"note info\"><p>今年第一，全体前五</p></div>\n\n<span id=\"more\"></span>\n\n<div align=\"center\">\n  <img src=\"/images/daily/boardgame/short/zdkx.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/boardgame/short/zdkx.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"炸弹克星\" width=\"70%\">\n  <p style=\"text-align:center;\">炸弹克星</p >\n</div>\n\n<p>经过五个小时的战斗，四个人一致认为炸弹克星是非常非常有趣。（以至于本来准备玩的第二个桌游都没玩🤣）</p>\n<p>他有一种返璞归真的乐趣。游戏本质是抽对子（就是扑克的那种），但是加入了一定的规则使得抽对子变得有一些逻辑性和复杂度。游戏并不依靠复杂的机制或者精致的模型来吸引玩家，仅仅靠着简单的规则就产生了如此巨大的吸引力。</p>\n<p>同时，为了避免规则简单而导致的同质化，游戏还把关卡给分成了若干部分，比如1-8.9-19等等。每一个部分都会给游戏加上独特的规则和机制，让玩家在游玩过程中始终能有新鲜感。例如<psw>有的关卡会加上时间限制，有的关卡会让你按顺序进行拆弹等等</psw>。</p>\n<p>游戏存在一个小小的缺点：依靠玩家的表现。在一场游戏中，如果玩家都是非常认真的只冲着结果去的话，游戏就会显得略微无趣。但如果玩家擅长主动给游戏增加乐趣——也就是所谓的“有活儿”，那么游戏将会出现许多令人捧腹大笑的名场面。</p>\n<p>另一个可能算缺点的就是，游戏里自带的板块放置栏有一点轻，导致如果有人手残的话某个动作会把所有的卡片都亮出来导致游戏必须重开（要不然就没有乐趣了）。</p>\n","categories":[{"name":"daily","slug":"daily","permalink":"https://middlemanz.com/categories/daily/"},{"name":"桌游","slug":"daily/boardgame","permalink":"https://middlemanz.com/categories/daily/boardgame/"}],"tags":[{"name":"桌游短评","slug":"桌游短评","permalink":"https://middlemanz.com/tags/%E6%A1%8C%E6%B8%B8%E7%9F%AD%E8%AF%84/"}]},{"title":"MNIST手写数字识别（从零实现FFN）","date":"2025-11-07T06:50:07.000Z","path":"categories/research/学习笔记/MNIST手写数字识别（从零实现）/","permalink":"https://middlemanz.com/categories/research/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%88%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0%EF%BC%89/","text":"本文是我的技术类第一篇文章，介绍如何在不依赖深度学习框架的情况下，仅使用 NumPy 从零实现一个用于 MNIST 手写数字分类的前馈神经网络（FFN）。本教程保留全部细节，以尽可能清晰的方式呈现深度学习模型的完整训练流程。 本文所有代码都置于个人github仓库 点击跳转 0.序言对于深度学习初学者来说，MNIST手写数字识别（以下用MINST简称）一定是一个绕不开的项目。作为最基础的项目，MNIST能教会初学者基础的： 完整的机器学习流程 神经网络的基本结构 张量思维 模型评估和调参 所以笔者认为掌握这个项目是至关重要的。 在本文中，笔者力求用最基础、简洁的语言，以及不省略任何细节的形式来完整讲述项目的全部流程。如果觉得啰嗦的话请快进哈哈 1.项目概览1.1 MNIST是什么MNIST 是一个手写数字图片数据集，主要用于识别 0–9 这十个数字。它最早由美国国家标准与技术研究院（NIST）制作，后由 Yann LeCun 等人清洗整理成 “Modified” 版本（MNIST）加入了M。 原始的 MNIST 数据通常是四个 .idx 文件，分别为： train-images-idx3-ubyte：训练图像 train-labels-idx1-ubyte：训练标签 t10k-images-idx3-ubyte：测试图像 t10k-labels-idx1-ubyte：测试标签 数据集分为训练集+测试集，每一个集合里又有图像和对应的标签。训练集中一共有60000张，而测试集中一共有10000张图片。在数据集中图片是被打乱放置的，也就是说数据集中随机排列着0-9这十种数字。每张图片的大小为28*28像素，而每一个像素值的范围是0-255（从黑0到白255，灰度值）。 举个例子：数字7的数据是： [0,0,0,...,235,255,...,0,0,...,45,168,159,...,0,0]他的标签就是：[7, 0, 4, 1, 9, 2, 1, 3, …] 1.2 目的本项目旨在不利用任何深度学习框架，只用numpy来构建FFN（Feed-Forward Network）前馈神经网络来实现对MNIST数据集的手写数字分类。 用大白话来讲，就是让模型学会：给他一张图，他就能判断上面写的数字是几这个能力。 1.3 开发环境本项目利用了如下四个库 1234numpygzipstructmatplotlib 其中 gzip,struct是Python标准库所以不用下载，剩余的numpy和matplotlib的下载方式为： 1pip install numpy matplotlib 1.4 数据集下载数据集下载有三种方式： 到我的github仓库里下载 点击跳转 。最省事🤣 利用Python自带的库来下载 下载数据集123456789101112131415import urllib.requesturls = &#123; &quot;train-images&quot;: &quot;https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz&quot;, &quot;train-labels&quot;: &quot;https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz&quot;, &quot;test-images&quot;: &quot;https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz&quot;, &quot;test-labels&quot;: &quot;https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz&quot;,&#125;for name, url in urls.items(): print(&quot;Downloading:&quot;, name) urllib.request.urlretrieve(url, f&quot;&#123;name&#125;.gz&quot;)print(&quot;Done!&quot;) 复制到vscode中可以直接使用3. 使用pytorch下载（唯一用到pytorch的地方） 使用pytorch下载123456789101112131415from torchvision import datasets, transformsmnist_train = datasets.MNIST( root=&#x27;./data&#x27;, train=True, download=True, transform=transforms.ToTensor())mnist_test = datasets.MNIST( root=&#x27;./data&#x27;, train=False, download=True, transform=transforms.ToTensor()) 注意:无论利用哪一种方法下载请务必注意文件路径!如使用本文的代码,请把数据集文件放置在./data/MNIST/raw下面. 12345678MNIST/│├── data/MNIST/raw │ ├── train-images-idx3-ubyte(.gz)│ ├── train-labels-idx1-ubyte(.gz)│ ├── t10k-images-idx3-ubyte(.gz)│ └── t10k-labels-idx1-ubyte(.gz)└── main.ipynb(主程序文件) 2.模型代码2.1 引入库1234import numpy as npimport gzipimport structimport matplotlib.pyplot as plt 这里简单讲一下四个库的用途： numpy：把数据转换为矩阵；做矩阵相关的计算；初始化权重等。 gzip：打开 .gz 压缩文件；解压得到原始二进制数据；读取里面的 idx 格式内容 struct：解析二进制数据，把字节转换成整数&#x2F;浮点数。 matplotlib：Python 的画图工具，负责可视化。 2.2 读取数据首先定义读取数据和读取标签的函数。 123456789101112def load_images(filename): with gzip.open(filename,&#x27;rb&#x27;) as f: magic, num, rows, cols = struct.unpack(&#x27;&gt;IIII&#x27;,f.read(16)) data = np.frombuffer(f.read(),dtype=np.uint8) images = data.reshape(num,rows, cols) return imagesdef load_labels(filename): with gzip.open(filename,&#x27;rb&#x27;)as f: magic, num = struct.unpack(&quot;&gt;II&quot;,f.read(8)) labels = np.frombuffer(f.read(),dtype=np.uint8) return labels 首先使用gzip来打开.gz压缩文件。使用f.read(16)来读取16个字节。为什么是是16个字节呢？因为在标准MNIST图像文件中前十六个字节格式是： 0–3 magic number（文件类型，例如图像文件为2051，标签文件为2049） 4–7 num（图片数量） 8–11 rows（每张图的高度） 12–15 cols（宽度） ‘&gt;IIII’ 是解析格式，一个I表示4字节无符号整数。所以四个I表示四个int(magic, num, rows, cols)。struct.unpack() 把二进制转换成 4 个整数。读取后存放至对应变量。在这一步，我们知道了一共有多少张图片（60000）、每张图片的行像素数（28）、列像素数（28）。 接下来用f.read()和np.frombuffer来读取所有图像像素，并把他们转换成Numpy数组。 最后用.reshape()来把一大长排的像素重塑成我们想要的形状，也就是(num, rows, cols)。转换之后，数据就变成了(60000, 28, 28)的MNIST标准格式（60000张图片，每个图片为28*28）。 接下来使用刚才定义的函数来读取数据： 12train_images = load_images(&#x27;./data/MNIST/raw/train-images-idx3-ubyte.gz&#x27;)train_labels = load_labels(&#x27;./data/MNIST/raw/train-labels-idx1-ubyte.gz&#x27;) 2.3 数据预处理为了使神经网络能够更快、更准确的学习到数据的规律，同时为了避免梯度爆炸和梯度消失，我们把所有像素数据除以255来实现归一化。 1train_images = train_images.astype(np.float32)/255.0 因为神经网络输入层为784个神经元，所以需要把所有向量展平成(60000,784)的格式 title1train_images = train_images.reshape(train_images.shape[0],-1) 接下来给每一个图片制作one hot编码。 One hot One hot编码，也叫独热编码是深度学习中给数据做标签的标准方式。One-Hot 编码就是把一个“类别数字”变成一个“只有一个 1，其它都是 0 的向量”。例如标签是3的话，编码后就变成了[0,0,0,1,0,0,0,0,0,0]（因为第一个是0所以在第4位上） 123456def one_hot(labels, num_classes = 10): result = np.zeros((labels.size, num_classes)) result[np.arange(labels.size),labels] = 1 return resulttrain_labels_oh = one_hot(train_labels) 2.4 设定模型2.4.1 初始化数据本次我们的模型为输入784，中间层128，输出为10的FFN模型。 初始化数据123456789input_size = 784hidden_size = 128output_size = 10np.random.seed(0)W1 = np.random.randn(input_size, hidden_size) * 0.01b1 = np.zeros((1, hidden_size))W2 = np.random.randn(hidden_size, output_size) * 0.01b2 = np.zeros((1, output_size)) 2.4.2 激活函数本次我们利用relu 和 softmax来进行对函数的激活 1234567def relu(x): return np.maximum(0, x)def softmax(x): exp_x = np.exp(x - np.max(x, axis=1, keepdims=True)) return exp_x / np.sum(exp_x, axis=1, keepdims=True) 2.4.3 前向传播接下来进行前向传播（Forward pass）。 前向传播的作用是根据输入x，计算神经网络的输出（预测结果）。 123456def forward(x): z1 = np.dot(x, W1) + b1 a1 = relu(z1) z2 = np.dot(a1, W2) + b2 a2 = softmax(z2) return z1, a1, z2, a2 123456789输入层 (784) ↓全连接层 W1 + b1 ↓ReLU 激活 ↓全连接层 W2 + b2 ↓Softmax（输出 10 类概率） 所以 forward() 的任务就是一层一层计算这些。 2.4.4 损失函数接下来定义损失函数。本次利用交叉熵损失函数(cross-entropy loss) 交叉熵损失交叉熵损失用来衡量“预测概率分布”和“真实分布”之间的差距。也就是差距越小 → 模型越好。$$L &#x3D; -\\frac{1}{N} \\sum_{i&#x3D;1}^{N} \\sum_{c&#x3D;1}^{10} y_{i,c} \\log \\left( p_{i,c} \\right)$$其中：$y_{i,c}$ &#x3D; One hot标签$p_{i,c}$ &#x3D; softmax输出的真实概率 12345def cross_entropy_loss(y_true, y_pred): eps = 1e-12 y_pred = np.clip(y_pred, eps, 1. - eps) N = y_true.shape[0] return -np.sum(y_true * np.log(y_pred)) / N 其中eps = 1e-12和np.clip()的作用是通过设定一个最小值来防止log(0)输出无限而崩溃。 2.4.5 反向传播1234567891011121314151617def backward(x, y_true, z1, a1, z2, a2, lr=0.01): global W1, b1, W2, b2 m = x.shape[0] dz2 = (a2 - y_true) / m dW2 = np.dot(a1.T, dz2) db2 = np.sum(dz2, axis=0, keepdims=True) da1 = np.dot(dz2, W2.T) dz1 = da1 * (z1 &gt; 0) dW1 = np.dot(x.T, dz1) db1 = np.sum(dz1, axis=0, keepdims=True) W2 -= lr * dW2 b2 -= lr * db2 W1 -= lr * dW1 b1 -= lr * db1 反向传播通过链式法则计算每个参数的梯度，包括： 输出层梯度：a2 - y W2、b2 的梯度：来自 a1 隐藏层激活梯度：z1 &gt; 0 W1、b1 的梯度：来自输入 x 这部分的原理详见另一篇文章（尚未更新）。 2.5 模型训练1234567891011121314151617181920212223242526epochs = 60batch_size = 256loss_history = []for epoch in range(epochs): permutation = np.random.permutation(train_images.shape[0]) X_shuffled = train_images[permutation] Y_shuffled = train_labels_oh[permutation] epoch_loss = 0 batches = 0 for i in range(0, X_shuffled.shape[0], batch_size): x_batch = X_shuffled[i:i + batch_size] y_batch = Y_shuffled[i:i + batch_size] z1, a1, z2, a2 = forward(x_batch) loss = cross_entropy_loss(y_batch, a2) backward(x_batch, y_batch, z1, a1, z2, a2) epoch_loss += loss batches += 1 avg_loss = epoch_loss / batches loss_history.append(avg_loss) print(f&quot;Epoch &#123;epoch + 1:02d&#125; | Loss: &#123;avg_loss:.4f&#125;&quot;) 其中： epochs: 训练轮数（epoch = 60意味着把整个数据重复训练60回，遍历60000张图片60回） batch_size: 每一批次放进模型的样本数(batch_size = 60意味着一股放进256个样本来进行前向传播和反向传播，60000&#x2F;256 ≈ 234个batch) np.random.permutation的作用是在每一个epoch中把训练数据随机排列。 接下来进行 前向传播 -&gt; 计算误差 -&gt; 反向传播 然后在每一次epoch结束后打印这个epoch的loss。 2.6 模型评估在训练集上进行评估： 12345678def accuracy(x, y_true): _, _, _, a2 = forward(x) y_pred = np.argmax(a2, axis=1) y_true_labels = np.argmax(y_true, axis=1) return np.mean(y_pred == y_true_labels)print(&quot;Training Accuracy:&quot;, accuracy(train_images[:10000], train_labels_oh[:10000])) 这部分很简单，就是代入最后的参数，通过前向传播去得到输出概率。然后通过np.argmax来获得最大概率的数字下标。y_pred == y_true_labels输出的是一组布尔值[True,False,True,...]而np.mean则会算出这个数组中True&#x2F;all的值，也就是正确率。 2.7 损失曲线可视化这一步我们要看到我们的损失曲线是如何下降的。 123456plt.plot(range(1, epochs + 1), loss_history, marker=&#x27;o&#x27;)plt.title(&#x27;Loss Curve (Training)&#x27;)plt.xlabel(&#x27;Epoch&#x27;)plt.ylabel(&#x27;Average Loss&#x27;)plt.grid(True)plt.show() 损失曲线 2.8 测试模型最后我们要用之前准备的测试集去测试我们的模型 123456789test_images = load_images(&#x27;./data/MNIST/raw/t10k-images-idx3-ubyte.gz&#x27;)test_labels = load_labels(&#x27;./data/MNIST/raw/t10k-labels-idx1-ubyte.gz&#x27;)test_images = test_images.astype(np.float32) / 255.0test_images = test_images.reshape(test_images.shape[0], -1)test_labels_oh = one_hot(test_labels)test_acc = accuracy(test_images, test_labels_oh)print(f&quot;Test Accuracy: &#123;test_acc * 100:.2f&#125;%&quot;) 和之前一样去加载测试集，给测试集的数据做归一化和矩阵形状调整。使用之前计算好的最终参数代入accuracy()这个函数去计算正确率。 3.后记至此MNIST手写数字识别这个项目的讲解就全部结束了。本项目的训练集和测试集正确率皆约为93%左右，如果在多加一个中间层，以及增多epoch的话也许可以提高到97%以上。 以上即为从零实现一个 MNIST FFN 模型的完整流程。如果你对反向传播原理或如何扩展网络结构感兴趣，我会在后续文章中继续展开。","content":"<p>本文是我的技术类第一篇文章，介绍如何在不依赖深度学习框架的情况下，仅使用 NumPy 从零实现一个用于 MNIST 手写数字分类的前馈神经网络（FFN）。本教程保留全部细节，以尽可能清晰的方式呈现深度学习模型的完整训练流程。</p>\n<span id=\"more\"></span>\n\n<div class=\"note warning\"><p>本文所有代码都置于个人github仓库 <a href=\"https://github.com/Midddleman/Middleman-ML-Lab/tree/main/MNIST\">点击跳转</a></p></div>\n\n<h2 id=\"0-序言\"><a href=\"#0-序言\" class=\"headerlink\" title=\"0.序言\"></a>0.序言</h2><p>对于深度学习初学者来说，MNIST手写数字识别（以下用MINST简称）一定是一个绕不开的项目。作为最基础的项目，MNIST能教会初学者基础的：</p>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>完整的机器学习流程</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>神经网络的基本结构</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>张量思维</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>模型评估和调参</p>\n            </div>\n<p>所以笔者认为掌握这个项目是至关重要的。</p>\n<p>在本文中，笔者力求用最基础、简洁的语言，以及不省略任何细节的形式来完整讲述项目的全部流程。<psw>如果觉得啰嗦的话请快进哈哈</psw></p>\n<h2 id=\"1-项目概览\"><a href=\"#1-项目概览\" class=\"headerlink\" title=\"1.项目概览\"></a>1.项目概览</h2><h3 id=\"1-1-MNIST是什么\"><a href=\"#1-1-MNIST是什么\" class=\"headerlink\" title=\"1.1 MNIST是什么\"></a>1.1 MNIST是什么</h3><p>MNIST 是一个手写数字图片数据集，主要用于识别 0–9 这十个数字。它最早由美国国家标准与技术研究院（NIST）制作，后由 Yann LeCun 等人清洗整理成 “<code>Modified</code>” 版本（MNIST）<del>加入了M</del>。</p>\n<p>原始的 MNIST 数据通常是四个 .idx 文件，分别为：</p>\n<ul>\n<li><code>train-images-idx3-ubyte</code>：训练图像</li>\n<li><code>train-labels-idx1-ubyte</code>：训练标签</li>\n<li><code>t10k-images-idx3-ubyte</code>：测试图像</li>\n<li><code>t10k-labels-idx1-ubyte</code>：测试标签</li>\n</ul>\n<p>数据集分为训练集+测试集，每一个集合里又有图像和对应的标签。训练集中一共有60000张，而测试集中一共有10000张图片。在数据集中图片是被打乱放置的，也就是说数据集中随机排列着0-9这十种数字。每张图片的大小为28*28像素，而每一个像素值的范围是0-255（从黑0到白255，灰度值）。</p>\n<p>举个例子：数字7的数据是： <code> [0,0,0,...,235,255,...,0,0,...,45,168,159,...,0,0]</code><br>他的标签就是：[<strong>7</strong>, 0, 4, 1, 9, 2, 1, 3, …]</p>\n<h3 id=\"1-2-目的\"><a href=\"#1-2-目的\" class=\"headerlink\" title=\"1.2 目的\"></a>1.2 目的</h3><p>本项目旨在不利用任何深度学习框架，只用numpy来构建FFN（Feed-Forward Network）前馈神经网络来实现对MNIST数据集的手写数字分类。</p>\n<psw>用大白话来讲，就是让模型学会：给他一张图，他就能判断上面写的数字是几这个能力。</psw>\n\n<h3 id=\"1-3-开发环境\"><a href=\"#1-3-开发环境\" class=\"headerlink\" title=\"1.3 开发环境\"></a>1.3 开发环境</h3><p>本项目利用了如下四个库</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">numpy</span><br><span class=\"line\">gzip</span><br><span class=\"line\">struct</span><br><span class=\"line\">matplotlib</span><br></pre></td></tr></table></figure>\n<p>其中 <code>gzip</code>,<code>struct</code>是Python标准库所以不用下载，剩余的<code>numpy</code>和<code>matplotlib</code>的下载方式为：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install numpy matplotlib</span><br></pre></td></tr></table></figure>\n<h3 id=\"1-4-数据集下载\"><a href=\"#1-4-数据集下载\" class=\"headerlink\" title=\"1.4 数据集下载\"></a>1.4 数据集下载</h3><p>数据集下载有三种方式：</p>\n<ol>\n<li>到我的github仓库里下载 <a href=\"https://github.com/Midddleman/Middleman-ML-Lab/tree/main/MNIST\">点击跳转</a> 。最省事🤣</li>\n<li>利用Python自带的库来下载</li>\n</ol>\n<figure class=\"highlight python\"><figcaption><span>下载数据集</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> urllib.request</span><br><span class=\"line\"></span><br><span class=\"line\">urls = &#123;</span><br><span class=\"line\">    <span class=\"string\">&quot;train-images&quot;</span>: <span class=\"string\">&quot;https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;train-labels&quot;</span>: <span class=\"string\">&quot;https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;test-images&quot;</span>:  <span class=\"string\">&quot;https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz&quot;</span>,</span><br><span class=\"line\">    <span class=\"string\">&quot;test-labels&quot;</span>:  <span class=\"string\">&quot;https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz&quot;</span>,</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> name, url <span class=\"keyword\">in</span> urls.items():</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&quot;Downloading:&quot;</span>, name)</span><br><span class=\"line\">    urllib.request.urlretrieve(url, <span class=\"string\">f&quot;<span class=\"subst\">&#123;name&#125;</span>.gz&quot;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Done!&quot;</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n<p>复制到vscode中可以直接使用<br>3. 使用pytorch下载（唯一用到pytorch的地方）</p>\n<figure class=\"highlight python\"><figcaption><span>使用pytorch下载</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> torchvision <span class=\"keyword\">import</span> datasets, transforms</span><br><span class=\"line\"></span><br><span class=\"line\">mnist_train = datasets.MNIST(</span><br><span class=\"line\">    root=<span class=\"string\">&#x27;./data&#x27;</span>,</span><br><span class=\"line\">    train=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    download=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    transform=transforms.ToTensor()</span><br><span class=\"line\">)</span><br><span class=\"line\"></span><br><span class=\"line\">mnist_test = datasets.MNIST(</span><br><span class=\"line\">    root=<span class=\"string\">&#x27;./data&#x27;</span>,</span><br><span class=\"line\">    train=<span class=\"literal\">False</span>,</span><br><span class=\"line\">    download=<span class=\"literal\">True</span>,</span><br><span class=\"line\">    transform=transforms.ToTensor()</span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n<p>注意:无论利用哪一种方法下载请务必注意文件路径!如使用本文的代码,请把数据集文件放置在<code>./data/MNIST/raw</code>下面.</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">MNIST/</span><br><span class=\"line\">│</span><br><span class=\"line\">├── data/MNIST/raw     </span><br><span class=\"line\">│ ├── train-images-idx3-ubyte(.gz)</span><br><span class=\"line\">│ ├── train-labels-idx1-ubyte(.gz)</span><br><span class=\"line\">│ ├── t10k-images-idx3-ubyte(.gz)</span><br><span class=\"line\">│ └── t10k-labels-idx1-ubyte(.gz)</span><br><span class=\"line\">└── main.ipynb(主程序文件)</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-模型代码\"><a href=\"#2-模型代码\" class=\"headerlink\" title=\"2.模型代码\"></a>2.模型代码</h2><h3 id=\"2-1-引入库\"><a href=\"#2-1-引入库\" class=\"headerlink\" title=\"2.1 引入库\"></a>2.1 引入库</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> gzip</span><br><span class=\"line\"><span class=\"keyword\">import</span> struct</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br></pre></td></tr></table></figure>\n<p>这里简单讲一下四个库的用途：</p>\n<ul>\n<li>numpy：把数据转换为矩阵；做矩阵相关的计算；初始化权重等。</li>\n<li>gzip：打开 .gz 压缩文件；解压得到原始二进制数据；读取里面的 idx 格式内容</li>\n<li>struct：解析二进制数据，把字节转换成整数&#x2F;浮点数。</li>\n<li>matplotlib：Python 的画图工具，负责可视化。</li>\n</ul>\n<h3 id=\"2-2-读取数据\"><a href=\"#2-2-读取数据\" class=\"headerlink\" title=\"2.2 读取数据\"></a>2.2 读取数据</h3><p>首先定义读取数据和读取标签的函数。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_images</span>(<span class=\"params\">filename</span>):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> gzip.<span class=\"built_in\">open</span>(filename,<span class=\"string\">&#x27;rb&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        magic, num, rows, cols = struct.unpack(<span class=\"string\">&#x27;&gt;IIII&#x27;</span>,f.read(<span class=\"number\">16</span>)) </span><br><span class=\"line\">        data = np.frombuffer(f.read(),dtype=np.uint8)</span><br><span class=\"line\">        images = data.reshape(num,rows, cols)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> images</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">load_labels</span>(<span class=\"params\">filename</span>):</span><br><span class=\"line\">    <span class=\"keyword\">with</span> gzip.<span class=\"built_in\">open</span>(filename,<span class=\"string\">&#x27;rb&#x27;</span>)<span class=\"keyword\">as</span> f:</span><br><span class=\"line\">        magic, num = struct.unpack(<span class=\"string\">&quot;&gt;II&quot;</span>,f.read(<span class=\"number\">8</span>))</span><br><span class=\"line\">        labels = np.frombuffer(f.read(),dtype=np.uint8)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> labels</span><br></pre></td></tr></table></figure>\n\n<ol>\n<li>首先使用gzip来打开<code>.gz</code>压缩文件。使用<code>f.read(16)</code>来读取16个字节。<br>为什么是是16个字节呢？因为在标准MNIST图像文件中前十六个字节格式是：</li>\n</ol>\n<ul>\n<li>0–3\tmagic number（文件类型，例如图像文件为2051，标签文件为2049）</li>\n<li>4–7\tnum（图片数量）</li>\n<li>8–11\trows（每张图的高度）</li>\n<li>12–15\tcols（宽度）</li>\n</ul>\n<ol start=\"2\">\n<li>‘&gt;IIII’ 是解析格式，一个<code>I</code>表示4字节无符号整数。所以四个<code>I</code>表示四个int(magic, num, rows, cols)。<code>struct.unpack()</code> 把二进制转换成 4 个整数。读取后存放至对应变量。在这一步，我们知道了一共有多少张图片（60000）、每张图片的行像素数（28）、列像素数（28）。</li>\n<li>接下来用<code>f.read()</code>和<code>np.frombuffer</code>来读取所有图像像素，并把他们转换成Numpy数组。</li>\n<li>最后用<code>.reshape()</code>来把一大长排的像素重塑成我们想要的形状，也就是(num, rows, cols)。转换之后，数据就变成了(60000, 28, 28)的MNIST标准格式（60000张图片，每个图片为28*28）。</li>\n</ol>\n<p>接下来使用刚才定义的函数来读取数据：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_images = load_images(<span class=\"string\">&#x27;./data/MNIST/raw/train-images-idx3-ubyte.gz&#x27;</span>)</span><br><span class=\"line\">train_labels = load_labels(<span class=\"string\">&#x27;./data/MNIST/raw/train-labels-idx1-ubyte.gz&#x27;</span>)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-3-数据预处理\"><a href=\"#2-3-数据预处理\" class=\"headerlink\" title=\"2.3 数据预处理\"></a>2.3 数据预处理</h3><p>为了使神经网络能够更快、更准确的学习到数据的规律，同时为了避免梯度爆炸和梯度消失，我们把所有像素数据除以255来实现归一化。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_images = train_images.astype(np.float32)/<span class=\"number\">255.0</span></span><br></pre></td></tr></table></figure>\n<p>因为神经网络输入层为784个神经元，所以需要把所有向量展平成(60000,784)的格式</p>\n<figure class=\"highlight python\"><figcaption><span>title</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train_images = train_images.reshape(train_images.shape[<span class=\"number\">0</span>],-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<p>接下来给每一个图片制作one hot编码。</p>\n<div class=\"note info\"><p><b><i>One hot</i></b><br/> One hot编码，也叫独热编码是深度学习中给数据做标签的标准方式。<br>One-Hot 编码就是把一个“类别数字”变成一个“只有一个 1，其它都是 0 的向量”。例如标签是3的话，编码后就变成了[0,0,0,1,0,0,0,0,0,0]（因为第一个是0所以在第4位上）</p></div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">one_hot</span>(<span class=\"params\">labels, num_classes = <span class=\"number\">10</span></span>):</span><br><span class=\"line\">    result = np.zeros((labels.size, num_classes))</span><br><span class=\"line\">    result[np.arange(labels.size),labels] = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> result</span><br><span class=\"line\"></span><br><span class=\"line\">train_labels_oh = one_hot(train_labels)</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"2-4-设定模型\"><a href=\"#2-4-设定模型\" class=\"headerlink\" title=\"2.4 设定模型\"></a>2.4 设定模型</h3><h4 id=\"2-4-1-初始化数据\"><a href=\"#2-4-1-初始化数据\" class=\"headerlink\" title=\"2.4.1 初始化数据\"></a>2.4.1 初始化数据</h4><p>本次我们的模型为输入784，中间层128，输出为10的FFN模型。</p>\n<figure class=\"highlight python\"><figcaption><span>初始化数据</span></figcaption><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">input_size = <span class=\"number\">784</span></span><br><span class=\"line\">hidden_size = <span class=\"number\">128</span></span><br><span class=\"line\">output_size = <span class=\"number\">10</span></span><br><span class=\"line\"></span><br><span class=\"line\">np.random.seed(<span class=\"number\">0</span>)</span><br><span class=\"line\">W1 = np.random.randn(input_size, hidden_size) * <span class=\"number\">0.01</span></span><br><span class=\"line\">b1 = np.zeros((<span class=\"number\">1</span>, hidden_size))</span><br><span class=\"line\">W2 = np.random.randn(hidden_size, output_size) * <span class=\"number\">0.01</span></span><br><span class=\"line\">b2 = np.zeros((<span class=\"number\">1</span>, output_size))</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"2-4-2-激活函数\"><a href=\"#2-4-2-激活函数\" class=\"headerlink\" title=\"2.4.2 激活函数\"></a>2.4.2 激活函数</h4><p>本次我们利用relu 和 softmax来进行对函数的激活</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">relu</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.maximum(<span class=\"number\">0</span>, x)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">softmax</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    exp_x = np.exp(x - np.<span class=\"built_in\">max</span>(x, axis=<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>))</span><br><span class=\"line\">    <span class=\"keyword\">return</span> exp_x / np.<span class=\"built_in\">sum</span>(exp_x, axis=<span class=\"number\">1</span>, keepdims=<span class=\"literal\">True</span>)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"2-4-3-前向传播\"><a href=\"#2-4-3-前向传播\" class=\"headerlink\" title=\"2.4.3 前向传播\"></a>2.4.3 前向传播</h4><p>接下来进行前向传播（Forward pass）。</p>\n<p>前向传播的作用是根据输入x，计算神经网络的输出（预测结果）。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">x</span>):</span><br><span class=\"line\">    z1 = np.dot(x, W1) + b1</span><br><span class=\"line\">    a1 = relu(z1)</span><br><span class=\"line\">    z2 = np.dot(a1, W2) + b2</span><br><span class=\"line\">    a2 = softmax(z2)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> z1, a1, z2, a2</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">输入层 (784)</span><br><span class=\"line\">   ↓</span><br><span class=\"line\">全连接层 W1 + b1</span><br><span class=\"line\">   ↓</span><br><span class=\"line\">ReLU 激活</span><br><span class=\"line\">   ↓</span><br><span class=\"line\">全连接层 W2 + b2</span><br><span class=\"line\">   ↓</span><br><span class=\"line\">Softmax（输出 10 类概率）</span><br></pre></td></tr></table></figure>\n<p>所以 forward() 的任务就是一层一层计算这些。</p>\n<h4 id=\"2-4-4-损失函数\"><a href=\"#2-4-4-损失函数\" class=\"headerlink\" title=\"2.4.4 损失函数\"></a>2.4.4 损失函数</h4><p>接下来定义损失函数。本次利用交叉熵损失函数(cross-entropy loss)</p>\n<div class=\"note \"><p><strong>交叉熵损失</strong></p><p>交叉熵损失用来衡量“预测概率分布”和“真实分布”之间的差距。<br/>也就是差距越小 → 模型越好。<br><br>$$<br>L &#x3D; -\\frac{1}{N} \\sum_{i&#x3D;1}^{N} \\sum_{c&#x3D;1}^{10} y_{i,c} \\log \\left( p_{i,c} \\right)<br>$$<br>其中：<br><br>$y_{i,c}$ &#x3D; One hot标签<br><br>$p_{i,c}$ &#x3D; softmax输出的真实概率<br></p></div>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">cross_entropy_loss</span>(<span class=\"params\">y_true, y_pred</span>):</span><br><span class=\"line\">    eps = <span class=\"number\">1e-12</span></span><br><span class=\"line\">    y_pred = np.clip(y_pred, eps, <span class=\"number\">1.</span> - eps)</span><br><span class=\"line\">    N = y_true.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    <span class=\"keyword\">return</span> -np.<span class=\"built_in\">sum</span>(y_true * np.log(y_pred)) / N</span><br></pre></td></tr></table></figure>\n<p>其中<code>eps = 1e-12</code>和<code>np.clip()</code>的作用是通过设定一个最小值来防止log(0)输出无限而崩溃。</p>\n<h4 id=\"2-4-5-反向传播\"><a href=\"#2-4-5-反向传播\" class=\"headerlink\" title=\"2.4.5 反向传播\"></a>2.4.5 反向传播</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">backward</span>(<span class=\"params\">x, y_true, z1, a1, z2, a2, lr=<span class=\"number\">0.01</span></span>):</span><br><span class=\"line\">    <span class=\"keyword\">global</span> W1, b1, W2, b2</span><br><span class=\"line\">    m = x.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">    dz2 = (a2 - y_true) / m</span><br><span class=\"line\">    dW2 = np.dot(a1.T, dz2)</span><br><span class=\"line\">    db2 = np.<span class=\"built_in\">sum</span>(dz2, axis=<span class=\"number\">0</span>, keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    da1 = np.dot(dz2, W2.T)</span><br><span class=\"line\">    dz1 = da1 * (z1 &gt; <span class=\"number\">0</span>)</span><br><span class=\"line\">    dW1 = np.dot(x.T, dz1)</span><br><span class=\"line\">    db1 = np.<span class=\"built_in\">sum</span>(dz1, axis=<span class=\"number\">0</span>, keepdims=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    W2 -= lr * dW2</span><br><span class=\"line\">    b2 -= lr * db2</span><br><span class=\"line\">    W1 -= lr * dW1</span><br><span class=\"line\">    b1 -= lr * db1</span><br></pre></td></tr></table></figure>\n<p>反向传播通过链式法则计算每个参数的梯度，包括：</p>\n<ul>\n<li>输出层梯度：a2 - y</li>\n<li>W2、b2 的梯度：来自 a1</li>\n<li>隐藏层激活梯度：z1 &gt; 0</li>\n<li>W1、b1 的梯度：来自输入 x</li>\n</ul>\n<p>这部分的原理详见另一篇文章（尚未更新）。</p>\n<h3 id=\"2-5-模型训练\"><a href=\"#2-5-模型训练\" class=\"headerlink\" title=\"2.5 模型训练\"></a>2.5 模型训练</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">epochs = <span class=\"number\">60</span></span><br><span class=\"line\">batch_size = <span class=\"number\">256</span></span><br><span class=\"line\">loss_history = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(epochs):</span><br><span class=\"line\">    permutation = np.random.permutation(train_images.shape[<span class=\"number\">0</span>])</span><br><span class=\"line\">    X_shuffled = train_images[permutation]</span><br><span class=\"line\">    Y_shuffled = train_labels_oh[permutation]</span><br><span class=\"line\"></span><br><span class=\"line\">    epoch_loss = <span class=\"number\">0</span></span><br><span class=\"line\">    batches = <span class=\"number\">0</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, X_shuffled.shape[<span class=\"number\">0</span>], batch_size):</span><br><span class=\"line\">        x_batch = X_shuffled[i:i + batch_size]</span><br><span class=\"line\">        y_batch = Y_shuffled[i:i + batch_size]</span><br><span class=\"line\"></span><br><span class=\"line\">        z1, a1, z2, a2 = forward(x_batch)</span><br><span class=\"line\">        loss = cross_entropy_loss(y_batch, a2)</span><br><span class=\"line\">        backward(x_batch, y_batch, z1, a1, z2, a2)</span><br><span class=\"line\"></span><br><span class=\"line\">        epoch_loss += loss</span><br><span class=\"line\">        batches += <span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\">    avg_loss = epoch_loss / batches</span><br><span class=\"line\">    loss_history.append(avg_loss)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Epoch <span class=\"subst\">&#123;epoch + <span class=\"number\">1</span>:02d&#125;</span> | Loss: <span class=\"subst\">&#123;avg_loss:<span class=\"number\">.4</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>\n<p>其中：</p>\n<ol>\n<li>epochs: 训练轮数（<code>epoch = 60</code>意味着把整个数据重复训练60回，遍历60000张图片60回）</li>\n<li>batch_size: 每一批次放进模型的样本数(<code>batch_size = 60</code>意味着一股放进256个样本来进行前向传播和反向传播，60000&#x2F;256 ≈ 234个batch)</li>\n<li><code>np.random.permutation</code>的作用是在每一个epoch中把训练数据随机排列。</li>\n<li>接下来进行 前向传播 -&gt; 计算误差 -&gt; 反向传播 然后在每一次epoch结束后打印这个epoch的loss。</li>\n</ol>\n<h3 id=\"2-6-模型评估\"><a href=\"#2-6-模型评估\" class=\"headerlink\" title=\"2.6 模型评估\"></a>2.6 模型评估</h3><p>在训练集上进行评估：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">accuracy</span>(<span class=\"params\">x, y_true</span>):</span><br><span class=\"line\">    _, _, _, a2 = forward(x)</span><br><span class=\"line\">    y_pred = np.argmax(a2, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    y_true_labels = np.argmax(y_true, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> np.mean(y_pred == y_true_labels)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">&quot;Training Accuracy:&quot;</span>, accuracy(train_images[:<span class=\"number\">10000</span>], train_labels_oh[:<span class=\"number\">10000</span>]))</span><br></pre></td></tr></table></figure>\n<p>这部分很简单，就是代入最后的参数，通过前向传播去得到输出概率。然后通过<code>np.argmax</code>来获得最大概率的数字下标。<br><code>y_pred == y_true_labels</code>输出的是一组布尔值<code>[True,False,True,...]</code>而<code>np.mean</code>则会算出这个数组中True&#x2F;all的值，也就是正确率。</p>\n<h3 id=\"2-7-损失曲线可视化\"><a href=\"#2-7-损失曲线可视化\" class=\"headerlink\" title=\"2.7 损失曲线可视化\"></a>2.7 损失曲线可视化</h3><p>这一步我们要看到我们的损失曲线是如何下降的。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.plot(<span class=\"built_in\">range</span>(<span class=\"number\">1</span>, epochs + <span class=\"number\">1</span>), loss_history, marker=<span class=\"string\">&#x27;o&#x27;</span>)</span><br><span class=\"line\">plt.title(<span class=\"string\">&#x27;Loss Curve (Training)&#x27;</span>)</span><br><span class=\"line\">plt.xlabel(<span class=\"string\">&#x27;Epoch&#x27;</span>)</span><br><span class=\"line\">plt.ylabel(<span class=\"string\">&#x27;Average Loss&#x27;</span>)</span><br><span class=\"line\">plt.grid(<span class=\"literal\">True</span>)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<div align=\"center\">\n  <img src=\"/images/research/notes/mnist/Loss.png\" class=\"lazyload\" data-srcset=\"/images/research/notes/mnist/Loss.png\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"损失曲线\" width=\"70%\">\n  <p style=\"text-align:center;\">损失曲线</p >\n</div>\n\n<h3 id=\"2-8-测试模型\"><a href=\"#2-8-测试模型\" class=\"headerlink\" title=\"2.8 测试模型\"></a>2.8 测试模型</h3><p>最后我们要用之前准备的测试集去测试我们的模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">test_images = load_images(<span class=\"string\">&#x27;./data/MNIST/raw/t10k-images-idx3-ubyte.gz&#x27;</span>)</span><br><span class=\"line\">test_labels = load_labels(<span class=\"string\">&#x27;./data/MNIST/raw/t10k-labels-idx1-ubyte.gz&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">test_images = test_images.astype(np.float32) / <span class=\"number\">255.0</span></span><br><span class=\"line\">test_images = test_images.reshape(test_images.shape[<span class=\"number\">0</span>], -<span class=\"number\">1</span>)</span><br><span class=\"line\">test_labels_oh = one_hot(test_labels)</span><br><span class=\"line\"></span><br><span class=\"line\">test_acc = accuracy(test_images, test_labels_oh)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&quot;Test Accuracy: <span class=\"subst\">&#123;test_acc * <span class=\"number\">100</span>:<span class=\"number\">.2</span>f&#125;</span>%&quot;</span>)</span><br></pre></td></tr></table></figure>\n<p>和之前一样去加载测试集，给测试集的数据做归一化和矩阵形状调整。使用之前计算好的最终参数代入<code>accuracy()</code>这个函数去计算正确率。</p>\n<h2 id=\"3-后记\"><a href=\"#3-后记\" class=\"headerlink\" title=\"3.后记\"></a>3.后记</h2><p>至此MNIST手写数字识别这个项目的讲解就全部结束了。本项目的训练集和测试集正确率皆约为93%左右，如果在多加一个中间层，以及增多epoch的话也许可以提高到97%以上。</p>\n<p>以上即为从零实现一个 MNIST FFN 模型的完整流程。如果你对反向传播原理或如何扩展网络结构感兴趣，我会在后续文章中继续展开。</p>\n","categories":[{"name":"research","slug":"research","permalink":"https://middlemanz.com/categories/research/"},{"name":"学习笔记","slug":"research/notes","permalink":"https://middlemanz.com/categories/research/notes/"}],"tags":[{"name":"从零实现","slug":"从零实现","permalink":"https://middlemanz.com/tags/%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0/"},{"name":"机器学习","slug":"机器学习","permalink":"https://middlemanz.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"深度学习","slug":"深度学习","permalink":"https://middlemanz.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"}]},{"title":"橄榄菜","date":"2025-10-31T09:48:07.000Z","path":"categories/short/橄榄菜/","permalink":"https://middlemanz.com/categories/short/%E6%A9%84%E6%A6%84%E8%8F%9C/","text":"每一个东北人都应该吃过的，来自南方的神秘馈赠 ::quote是我自己编的 昨天做米饭的时候放水放少了，同样的米饭这次做完只有之前的二分之一大小。比较硬，吃不太下去。 第二天中午不知道吃什么，看着梆硬的米饭，毫无食欲。 转念一想，干脆煮成粥吧。 来到日本三年半，做粥的次数还是寥寥无几。其中缘由大多数每次做饭都只做正正好好的量，这样就不会剩饭（因为剩饭了也不会吃）。但是这次剩的饭还是太多了，就选择了粥。 粥一冒泡，屋里飘出熟悉的香气。对我来说，粥从来不只是食物。每当它出现在餐桌上，旁边几乎总有一小碟橄榄菜。 吃了十几年橄榄菜了，今天看到橄榄菜上的“广州橄榄菜”的时候，第一次开始思考：为什么广州的咸菜会在沈阳流行。 百思不得其解，感觉最有可能的原因还是橄榄菜的“咸”“香”“油大”这些特点完美符合东北人的饮食偏好吧。 在寒冷的地方总是需要香气浓烈的食物来抵御冬天，于是橄榄菜也成为了东北人饭桌上不可或缺的食物。对于我而言，橄榄菜也是在异国他乡抵御寒冬的最好的良药。","content":"<div class=\"note quote\"><p>每一个东北人都应该吃过的，来自南方的神秘馈赠</p></div>\n\n<span id=\"more\"></span>\n\n<psw>::quote是我自己编的</psw>\n<p>昨天做米饭的时候放水放少了，同样的米饭这次做完只有之前的二分之一大小。比较硬，吃不太下去。</p>\n<p>第二天中午不知道吃什么，看着梆硬的米饭，毫无食欲。</p>\n<p>转念一想，干脆煮成粥吧。</p>\n<p>来到日本三年半，做粥的次数还是寥寥无几。其中缘由大多数每次做饭都只做正正好好的量，这样就不会剩饭（因为剩饭了也不会吃）。但是这次剩的饭还是太多了，就选择了粥。</p>\n<p>粥一冒泡，屋里飘出熟悉的香气。对我来说，粥从来不只是食物。每当它出现在餐桌上，旁边几乎总有一小碟橄榄菜。</p>\n<p>吃了十几年橄榄菜了，今天看到橄榄菜上的“广州橄榄菜”的时候，第一次开始思考：为什么广州的咸菜会在沈阳流行。</p>\n<p>百思不得其解，感觉最有可能的原因还是橄榄菜的“咸”“香”“油大”这些特点完美符合东北人的饮食偏好吧。</p>\n<p>在寒冷的地方总是需要香气浓烈的食物来抵御冬天，于是橄榄菜也成为了东北人饭桌上不可或缺的食物。对于我而言，橄榄菜也是在异国他乡抵御寒冬的最好的良药。</p>\n","categories":[{"name":"随笔","slug":"short","permalink":"https://middlemanz.com/categories/short/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://middlemanz.com/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"财团旅游2025——日本秋田和岩手县","date":"2025-10-23T03:52:43.000Z","path":"categories/daily/旅行/scholarship-trip2025/","permalink":"https://middlemanz.com/categories/daily/%E6%97%85%E8%A1%8C/scholarship-trip2025/","text":"这是我参加财团旅游的第四年了，目的地是日本东北部的秋田和盛岡县。 这次旅游的目的地是秋田和岩手县，二者都位于日本的东北部。10月8日早乘坐6点的东海道新干线，从京都出发，在东京乘换东日本新干线后，在中午11:30点便到达了盛岡。 财团组织的旅游是托管式的，所谓托管式，就是财团把一切——从交通、酒店到景点、三餐全部安排妥当。在旅游之前，财团会把行程安排，奖学生介绍等印刷成册，随新干线的车票一起邮寄到家。到了旅游那天只需要拿着这些资料即可。统筹安排的过程对于财团而言必然是繁琐的，但对于奖学生们来说，旅游就是完全的放松之旅。只要扔掉脑子，听从安排既可。 2025&#x2F;10&#x2F;8 11:00 盛岡駅到着 岩手县以全国第2位的面积（1.52万平方公里）而自豪，这个面积比东京都、千叶县、埼玉县、神奈川县四县合计（1.35万平方公里）还要大。 县政府所在地盛冈市，在江户时代因北上川的水运而繁荣，同时位于向南延伸的奥州街道上，是西通秋田街道、东通野田・宫古・远野街道交汇的交通要地，作为城下町而兴盛。 市内保留着明治时期的洋风建筑和古老的街区风貌，可以感受到历史与文化的气息。 于盛岡站出来后，我们先去了ホテルメトロポリタン盛岡吃了午饭。午饭是日式中华——食之无味，弃之可惜。不过因为晚上的宴席是19点，也只能耐心的把食物吃完。 财团对于时间一向是不吝啬的，从8日中午到达到10日中午解散，两天整的行程满打满算也只有四个景点，也就是每个上午和下午只有一个。日本的景点大多都不大，不是很需要时间参观。所以财团会把每一个步骤的时间安排的很长。比如吃饭，第一天的午餐从十一点半开始，足足吃了一个半小时，下午1点才正式出发。而饭本身很简单，我一般二十分钟就能吃完，剩下的时间就是和其他奖学生交谈。可能对于财团而言，组织修学旅行的目的并不是观光本身，而是给奖学生提供交流的机会吧。 2025&#x2F;10&#x2F;8 13:00~16:00 田沢湖 直径约6公里，呈圆形的神秘湖泊。最大水深达423米，是日本最深的湖泊，也以此著称为“日本的贝加尔湖”，同时在世界上也是最深的湖泊之一。 湖面呈现出神秘的钴蓝色，以辰子姬（たつこひめ）的传说而闻名。这里可以乘坐游览船或骑行，尽享美丽风景。周边有辰子姬像、御座石神社、温泉、珍稀的水生植物群落等，观光景点十分丰富。 辰子姬的传说 据传，辰子是一位拥有绝世美貌的年轻女子，她强烈地渴望永远保持自己的美丽与青春。 于是她每天夜里向观音菩萨祈祷。几度祈祷之后，观音对她说：“若饮靠近观音的泉水，你的愿望就能实现。” 辰子口渴难耐，便饮下泉水。结果，在泉水干涸之前，辰子的身体便变成了龙的模样。 此后，辰子成为湖的守护神，永远沉睡在湖底，守护着这片深邃的湖水。 阴天的田沢湖 略微出了太阳的田沢湖，波光粼粼 我每次旅游的景点只要有湖，我必然想起《岳阳楼记》： 若夫霪雨霏霏，连月不开；阴风怒号，浊浪排空；日星隐耀，山岳潜形；商旅不行，樯倾楫摧；薄暮冥冥，虎啸猿啼。 ……至若春和景明，波澜不惊；上下天光，一碧万顷；沙鸥翔集，锦鳞游泳；岸芷汀兰，郁郁青青。而或长烟一空，皓月千里，浮光跃金，静影沉璧，渔歌互答，此乐何极！ 这两个照片就完美展现了岳阳楼记中的景象，虽然阴天的时候没有那么阴郁，但是仍有薄暮冥冥之感。反观晴天之时，真是上下天光，一碧万顷！当然日本的这个小湖肯定定不能和洞庭湖比较的，只是笔者游至此地，略有所感罢了。 辰子姬像 2025&#x2F;10&#x2F;8 17:30 ホテル森の風 鶯宿很经典也很传统的日式温泉酒店。也是财团选择酒店种类的首选。三个人住一屋。睡觉前在你吃饭的时候会有服务员来给你铺床，不过不用担心财物丢失，日本这方面还是很令人放心的 一张酒店的网图 2025&#x2F;10&#x2F;9 9:30~11:30 小岩井農場 小岩井农场建于明治24年（1891年），由日本铁道公司的小野义真、三菱的岩崎弥之助，以及铁道厅官员井上胜三人共同创立。 名称“小岩井”取自三人姓氏的首字：小野（小）、岩崎（岩）、井上（井）。 当时这片土地是一片荒原，土壤强酸性，几乎无法种植作物。经过改良后，牧草与牛乳的生产得到发展，最终建成了日本近代畜牧业的基础。通过黄油与奶酪的生产，小岩井农场奠定了日本乳业的根基。 农场面积约3000公顷，其中1000公顷为牧草地，另外2000公顷是人工种植的森林。农场还设有职工家庭的保育园和学校等设施。 自20世纪60年代起，农场的一部分对游客开放，提供骑马、制作黄油、品尝冰淇淋等体验活动，让人们能亲身感受农业与自然的乐趣。 小岩井农场的羊羊 相对于农场本身而言，农产品才是更吸引我的。在农场里我的唯一目标就是吃到农场里的牛直接产出制成的牛奶和冰淇淋。幸好如愿以偿了。 农场牛奶直产冰淇淋 必须吐槽一下这一天的午饭，我得说这是旅行中的比较令人不满意的一顿午饭——我愿称之为韩国国宴。放眼望去，除了三片鸡胸肉，目光所及之处仅是蔬菜的尸体，还被残忍腌制分尸了。咸菜种类倒是挺多，一共七八种，嗯，倒不难吃。但是对于中国人来说，还是太超前了。 韩国国宴午餐 2025&#x2F;10&#x2F;9 13:30-16:30 宮沢賢治記念館・花巻新渡戸記念館 宫泽贤治纪念馆（みやざわけんじきねんかん） 宫泽贤治生于明治29年（1896年）岩手县花卷市，37岁时早逝。在短暂的一生中，他创作了大量作品。代表作包括《银河铁道之夜》《要求太多的餐馆》等童话与诗歌，被收入日本的国语教材中。 纪念馆中介绍了宫泽贤治作为农学校教师、科学家、艺术家、宗教信仰者等多方面的活动，还展示了影片与原稿手迹等资料。 此外，在纪念馆旁的“波兰广场”上，建有以贤治设计理念为基础的南斜花坛与日晷花坛，象征他对自然与宇宙的热爱。 花卷新渡户纪念馆（はなまきにとべきねんかん） 新渡户家族自庆长3年（1598年）起约230年间居住在花卷，是指导花卷城主及武士的名族。 2代前的新渡户稻造（にとべいなおぞう）以其肖像被印在旧5000日元纸币上而广为人知。 他生于文久2年（1862年）盛冈。著有《武士道》，以此向世界介绍日本精神。作为国际联盟（国联）事务次长，他为国际和平与合作作出贡献。纪念馆介绍了他的生平与思想，展示了他致力于教育与国际理解的足迹。 这两个纪念馆倒是没有什么特别好说的，第一个是类似于郭沫若+冰心之类的人是诗人、童话家、教育者、宗教哲学家和科学家。但是有一点需要狠狠差评：在介绍宫泽的生平大事记的时候。当写至918事变时，居然写的是中华民国北大营军队炸毁南满铁路导致事件爆发。作为沈阳人，真的不能容忍这种明目张胆的历史虚无主义！ 第二个纪念馆有一些点还是比较吸引我的，其中以新渡户稻造的生平为最。我很喜欢在逛纪念馆的时候细致的看人物的生平，这样颇有一些自己在咀嚼历史的感觉——把一个人的一生反复品味透彻。印象最深的是稻造及其妻子玛丽的历史：新渡户稻造1884年赴美国留学，就读于约翰·霍普金斯大学主修农业经济。期间结识了玛丽·埃尔金森，两人因共同的理想（教育与和平）而相知相爱。1889年，他们在美国结婚，这在当时的日本社会是非常罕见的“国际婚姻”。他们的婚姻融合了日本的儒家伦理与西方的贵格精神，彼此平等、互相尊重，被视为“跨文化理解的象征”。在看完历史后我特意去查了一下贵格精神是什么，chatgpt给我的解释是： 贵格精神（Quaker Spirit）是指**贵格会（Society of Friends）**的核心信仰与行为准则 贵格会认为，每个人心中都有“上帝之光”——一种来自神的良知与真理。因此，每个人都是平等的，都能直接感受到神的启示。这种思想反对教会的等级制度和形式化仪式，强调“信仰不在教堂，而在心中”。 贵格会以“非暴力主义”著称。他们拒绝参军、拒绝战争，也反对死刑与任何形式的暴力。 贵格徒相信所有人（无论性别、种族、阶级）在上帝面前都是平等的。他们是最早倡导女性教育、反奴隶制度、以及人权平等的群体之一。 放到中国来讲的话大概就是性本善论+兼爱非攻+仁者爱人的结合体。中华的老祖宗们的思想还是太先进和超前了。 2025&#x2F;10&#x2F;10 10:00~13:00 中尊寺 中尊寺创立于嘉祥3年（850年），由比叡山延历寺的高僧慈觉大师圆仁开创。 12世纪初，藤原清衡在经历“后三年之战”后，为了追悼在战乱中死去的灵魂，重建并扩建了中尊寺。 他希望通过建立宏伟的寺院与佛像，宣扬“以佛之教化使国土安宁”的理念。 金色堂建于天治元年（1124年），外内全部贴金，堂内供奉着藤原三代的遗骸，是日本现存唯一完整保留平安时代后期佛教艺术的建筑。 内部装饰使用了螺钿、象牙、漆绘、金银丝等工艺，金光闪耀，被称为“平安美的极致”。 1950年（昭和25年）被指定为日本国宝，并被列入世界文化遗产名录。 是一座由金箔包裹着的寺庙，不是很大但是很有历史的重量感。 金色堂内部 中尊寺坐落于山上，从一处景点走到另一处需要走一段时间的山路，好在秋高气爽，景色宜人。从山上望去能看到一马平川的平原和在上面宛如“蜘蛛网”般的东北新干线。之所以是带双引号是因为只有一两条大线，很像蜘蛛网刚开始建的样子。 从山上望去 2025&#x2F;10&#x2F;10 13:30 一の関駅解散解散之后，就乘坐新干线原路返回京都了。 后记在这里放一些财团晚上提供的晚餐，晚饭是非常精致的日式会席，除了吃不饱剩下都很完美。 晚饭1 晚饭2","content":"<p>这是我参加财团旅游的第四年了，目的地是日本东北部的秋田和盛岡县。</p>\n<span id=\"more\"></span>\n\n<p>这次旅游的目的地是秋田和岩手县，二者都位于日本的东北部。10月8日早乘坐6点的东海道新干线，从京都出发，在东京乘换东日本新干线后，在中午11:30点便到达了盛岡。</p>\n<p>财团组织的旅游是托管式的，所谓托管式，就是财团把一切——从交通、酒店到景点、三餐全部安排妥当。在旅游之前，财团会把行程安排，奖学生介绍等印刷成册，随新干线的车票一起邮寄到家。到了旅游那天只需要拿着这些资料即可。统筹安排的过程对于财团而言必然是繁琐的，但对于奖学生们来说，旅游就是完全的放松之旅。只要扔掉脑子，听从安排既可。</p>\n<h2 id=\"2025-10-8-11-00-盛岡駅到着\"><a href=\"#2025-10-8-11-00-盛岡駅到着\" class=\"headerlink\" title=\"2025&#x2F;10&#x2F;8 11:00 盛岡駅到着\"></a>2025&#x2F;10&#x2F;8 11:00 盛岡駅到着</h2></h2><blockquote>\n<ul>\n<li>岩手县以全国第2位的面积（1.52万平方公里）而自豪，这个面积比东京都、千叶县、埼玉县、神奈川县四县合计（1.35万平方公里）还要大。</li>\n<li>县政府所在地盛冈市，在江户时代因北上川的水运而繁荣，同时位于向南延伸的奥州街道上，是西通秋田街道、东通野田・宫古・远野街道交汇的交通要地，作为城下町而兴盛。</li>\n<li>市内保留着明治时期的洋风建筑和古老的街区风貌，可以感受到历史与文化的气息。</li>\n</ul>\n</blockquote>\n<p>于盛岡站出来后，我们先去了ホテルメトロポリタン盛岡吃了午饭。午饭是日式中华——食之无味，弃之可惜。不过因为晚上的宴席是19点，也只能耐心的把食物吃完。</p>\n<p>财团对于时间一向是不吝啬的，从8日中午到达到10日中午解散，两天整的行程满打满算也只有四个景点，也就是每个上午和下午只有一个。日本的景点大多都不大，不是很需要时间参观。所以财团会把每一个步骤的时间安排的很长。比如吃饭，第一天的午餐从十一点半开始，足足吃了一个半小时，下午1点才正式出发。而饭本身很简单，我一般二十分钟就能吃完，剩下的时间就是和其他奖学生交谈。可能对于财团而言，组织修学旅行的目的并不是观光本身，而是给奖学生提供交流的机会吧。</p>\n<h2 id=\"2025-10-8-13-00-16-00-田沢湖\"><a href=\"#2025-10-8-13-00-16-00-田沢湖\" class=\"headerlink\" title=\"2025&#x2F;10&#x2F;8 13:00~16:00 田沢湖\"></a>2025&#x2F;10&#x2F;8 13:00~16:00 田沢湖</h2></h2><blockquote>\n<ul>\n<li>直径约6公里，呈圆形的神秘湖泊。最大水深达423米，是日本最深的湖泊，也以此著称为“<em><strong>日本的贝加尔湖</strong></em>”，同时在世界上也是最深的湖泊之一。</li>\n<li>湖面呈现出神秘的钴蓝色，以辰子姬（たつこひめ）的传说而闻名。这里可以乘坐游览船或骑行，尽享美丽风景。周边有辰子姬像、御座石神社、温泉、珍稀的水生植物群落等，观光景点十分丰富。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p><strong>辰子姬的传说</strong></p>\n<ul>\n<li>据传，辰子是一位拥有绝世美貌的年轻女子，她强烈地渴望永远保持自己的美丽与青春。</li>\n<li>于是她每天夜里向观音菩萨祈祷。几度祈祷之后，观音对她说：“若饮靠近观音的泉水，你的愿望就能实现。”</li>\n<li>辰子口渴难耐，便饮下泉水。结果，在泉水干涸之前，辰子的身体便变成了龙的模样。</li>\n<li>此后，辰子成为湖的守护神，永远沉睡在湖底，守护着这片深邃的湖水。</li>\n</ul>\n</blockquote>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/tzk1.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/tzk1.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"\" width=\"70%\">\n  <p style=\"text-align:center;\">阴天的田沢湖</p>\n</div>\n\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/tzk2.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/tzk2.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"\" width=\"70%\">\n  <p style=\"text-align:center;\">略微出了太阳的田沢湖，波光粼粼</p>\n</div>\n\n<p>我每次旅游的景点只要有湖，我必然想起《岳阳楼记》：</p>\n<blockquote>\n<p>若夫霪雨霏霏，连月不开；阴风怒号，浊浪排空；日星隐耀，山岳潜形；商旅不行，樯倾楫摧；薄暮冥冥，虎啸猿啼。 ……<br>至若春和景明，波澜不惊；上下天光，一碧万顷；沙鸥翔集，锦鳞游泳；岸芷汀兰，郁郁青青。而或长烟一空，皓月千里，浮光跃金，静影沉璧，渔歌互答，此乐何极！</p>\n</blockquote>\n<p>这两个照片就完美展现了岳阳楼记中的景象，虽然阴天的时候没有那么阴郁，但是仍有薄暮冥冥之感。反观晴天之时，真是上下天光，一碧万顷！<br>当然日本的这个小湖肯定定不能和洞庭湖比较的，只是笔者游至此地，略有所感罢了。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/tzk3.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/tzk3.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"\" width=\"50%\">\n  <p style=\"text-align:center;\">辰子姬像</p>\n</div>\n\n<h2 id=\"2025-10-8-17-30-ホテル森の風-鶯宿\"><a href=\"#2025-10-8-17-30-ホテル森の風-鶯宿\" class=\"headerlink\" title=\"2025&#x2F;10&#x2F;8 17:30 ホテル森の風　鶯宿\"></a>2025&#x2F;10&#x2F;8 17:30 ホテル森の風　鶯宿</h2></h2><p>很经典也很传统的日式温泉酒店。也是财团选择酒店种类的首选。三个人住一屋。睡觉前在你吃饭的时候会有服务员来给你铺床，不过不用担心财物丢失，日本这方面还是很令人放心的</p>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/hotel1.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/hotel1.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"描述文字\" width=\"70%\">\n  <p style=\"text-align:center;\">一张酒店的网图</p>\n</div>\n\n<h2 id=\"2025-10-9-9-30-11-30-小岩井農場\"><a href=\"#2025-10-9-9-30-11-30-小岩井農場\" class=\"headerlink\" title=\"2025&#x2F;10&#x2F;9 9:30~11:30 小岩井農場\"></a>2025&#x2F;10&#x2F;9 9:30~11:30 小岩井農場</h2></h2><blockquote>\n<ul>\n<li>小岩井农场建于明治24年（1891年），由日本铁道公司的小野义真、三菱的岩崎弥之助，以及铁道厅官员井上胜三人共同创立。</li>\n<li>名称“小岩井”取自三人姓氏的首字：小野（小）、岩崎（岩）、井上（井）。</li>\n</ul>\n</blockquote>\n<blockquote>\n<ul>\n<li>当时这片土地是一片荒原，土壤强酸性，几乎无法种植作物。经过改良后，牧草与牛乳的生产得到发展，最终建成了日本近代畜牧业的基础。通过黄油与奶酪的生产，小岩井农场奠定了日本乳业的根基。</li>\n<li>农场面积约3000公顷，其中1000公顷为牧草地，另外2000公顷是人工种植的森林。农场还设有职工家庭的保育园和学校等设施。</li>\n<li>自20世纪60年代起，农场的一部分对游客开放，提供骑马、制作黄油、品尝冰淇淋等体验活动，让人们能亲身感受农业与自然的乐趣。</li>\n</ul>\n</blockquote>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/xyj1.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/xyj1.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"\" width=\"50%\">\n  <p style=\"text-align:center;\">小岩井农场的羊羊</p>\n</div>\n\n<p>相对于农场本身而言，农产品才是更吸引我的。在农场里我的唯一目标就是吃到农场里的牛直接产出制成的牛奶和冰淇淋。幸好如愿以偿了。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/xyj2.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/xyj2.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"\" width=\"30%\">\n  <p style=\"text-align:center;\">农场牛奶直产冰淇淋</p>\n</div>\n\n<p>必须吐槽一下这一天的午饭，我得说这是旅行中的比较令人不满意的一顿午饭——我愿称之为韩国国宴。<br>放眼望去，除了三片鸡胸肉，目光所及之处仅是蔬菜的尸体，还被残忍腌制分尸了。咸菜种类倒是挺多，一共七八种，嗯，倒不难吃。但是对于中国人来说，还是太超前了。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/xyj3.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/xyj3.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"\" width=\"70%\">\n  <p style=\"text-align:center;\">韩国国宴午餐</p>\n</div>\n\n<h2 id=\"2025-10-9-13-30-16-30-宮沢賢治記念館・花巻新渡戸記念館\"><a href=\"#2025-10-9-13-30-16-30-宮沢賢治記念館・花巻新渡戸記念館\" class=\"headerlink\" title=\"2025&#x2F;10&#x2F;9 13:30-16:30 宮沢賢治記念館・花巻新渡戸記念館\"></a>2025&#x2F;10&#x2F;9 13:30-16:30 宮沢賢治記念館・花巻新渡戸記念館</h2><blockquote>\n<p><strong>宫泽贤治纪念馆（みやざわけんじきねんかん）</strong></p>\n<ul>\n<li>宫泽贤治生于明治29年（1896年）岩手县花卷市，37岁时早逝。在短暂的一生中，他创作了大量作品。代表作包括《银河铁道之夜》《要求太多的餐馆》等童话与诗歌，被收入日本的国语教材中。</li>\n<li>纪念馆中介绍了宫泽贤治作为农学校教师、科学家、艺术家、宗教信仰者等多方面的活动，还展示了影片与原稿手迹等资料。</li>\n<li>此外，在纪念馆旁的“波兰广场”上，建有以贤治设计理念为基础的南斜花坛与日晷花坛，象征他对自然与宇宙的热爱。</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>花卷新渡户纪念馆（はなまきにとべきねんかん）</p>\n<ul>\n<li>新渡户家族自庆长3年（1598年）起约230年间居住在花卷，是指导花卷城主及武士的名族。</li>\n<li>2代前的新渡户稻造（にとべいなおぞう）以其肖像被印在<strong>旧5000日元纸币上</strong>而广为人知。</li>\n<li>他生于文久2年（1862年）盛冈。著有《武士道》，以此向世界介绍日本精神。作为国际联盟（国联）事务次长，他为国际和平与合作作出贡献。纪念馆介绍了他的生平与思想，展示了他致力于教育与国际理解的足迹。</li>\n</ul>\n</blockquote>\n<p>这两个纪念馆倒是没有什么特别好说的，第一个是类似于郭沫若+冰心之类的人是诗人、童话家、教育者、宗教哲学家和科学家。但是有一点需要狠狠差评：在介绍宫泽的生平大事记的时候。<strong>当写至918事变时，居然写的是中华民国北大营军队炸毁南满铁路导致事件爆发。</strong>作为沈阳人，真的不能容忍这种明目张胆的历史虚无主义！</p>\n<p>第二个纪念馆有一些点还是比较吸引我的，其中以新渡户稻造的生平为最。我很喜欢在逛纪念馆的时候细致的看人物的生平，这样颇有一些自己在咀嚼历史的感觉——把一个人的一生反复品味透彻。印象最深的是稻造及其妻子玛丽的历史：新渡户稻造1884年赴美国留学，就读于约翰·霍普金斯大学主修农业经济。期间结识了玛丽·埃尔金森，两人因共同的理想（教育与和平）而相知相爱。1889年，他们在美国结婚，这在当时的日本社会是非常罕见的“国际婚姻”。他们的婚姻融合了日本的儒家伦理与西方的贵格精神，彼此平等、互相尊重，被视为“跨文化理解的象征”。<br>在看完历史后我特意去查了一下贵格精神是什么，chatgpt给我的解释是：</p>\n<blockquote>\n<p>贵格精神（Quaker Spirit）是指**贵格会（Society of Friends）**的核心信仰与行为准则</p>\n<ul>\n<li>贵格会认为，每个人心中都有“上帝之光”——一种来自神的良知与真理。因此，每个人都是平等的，都能直接感受到神的启示。这种思想反对教会的等级制度和形式化仪式，强调“信仰不在教堂，而在心中”。</li>\n<li>贵格会以“非暴力主义”著称。他们拒绝参军、拒绝战争，也反对死刑与任何形式的暴力。</li>\n<li>贵格徒相信所有人（无论性别、种族、阶级）在上帝面前都是平等的。他们是最早倡导女性教育、反奴隶制度、以及人权平等的群体之一。</li>\n</ul>\n</blockquote>\n<p>放到中国来讲的话大概就是性本善论+兼爱非攻+仁者爱人的结合体。中华的老祖宗们的思想还是太先进和超前了。</p>\n<h2 id=\"2025-10-10-10-00-13-00-中尊寺\"><a href=\"#2025-10-10-10-00-13-00-中尊寺\" class=\"headerlink\" title=\"2025&#x2F;10&#x2F;10 10:00~13:00 中尊寺\"></a>2025&#x2F;10&#x2F;10 10:00~13:00 中尊寺</h2></h2><blockquote>\n<ul>\n<li>中尊寺创立于嘉祥3年（850年），由比叡山延历寺的高僧慈觉大师圆仁开创。</li>\n<li>12世纪初，藤原清衡在经历“后三年之战”后，为了追悼在战乱中死去的灵魂，重建并扩建了中尊寺。</li>\n<li>他希望通过建立宏伟的寺院与佛像，宣扬“以佛之教化使国土安宁”的理念。</li>\n<li>金色堂建于天治元年（1124年），外内全部贴金，堂内供奉着藤原三代的遗骸，是日本现存唯一完整保留平安时代后期佛教艺术的建筑。</li>\n<li>内部装饰使用了螺钿、象牙、漆绘、金银丝等工艺，金光闪耀，被称为“平安美的极致”。</li>\n<li>1950年（昭和25年）被指定为日本国宝，并被列入世界文化遗产名录。</li>\n</ul>\n</blockquote>\n<p>是一座由金箔包裹着的寺庙，不是很大但是很有历史的重量感。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/zzs1.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/zzs1.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"\" width=\"70%\">\n  <p style=\"text-align:center;\">金色堂内部</p>\n</div>\n\n<p>中尊寺坐落于山上，从一处景点走到另一处需要走一段时间的山路，好在秋高气爽，景色宜人。从山上望去能看到一马平川的平原和在上面宛如“蜘蛛网”般的东北新干线。之所以是带双引号是因为只有一两条大线，很像蜘蛛网刚开始建的样子。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/zzs2.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/zzs2.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"描述文字\" width=\"70%\">\n  <p style=\"text-align:center;\">从山上望去</p>\n</div>\n\n<h2 id=\"2025-10-10-13-30-一の関駅解散\"><a href=\"#2025-10-10-13-30-一の関駅解散\" class=\"headerlink\" title=\"2025&#x2F;10&#x2F;10 13:30 一の関駅解散\"></a>2025&#x2F;10&#x2F;10 13:30 一の関駅解散</h2></h2><p>解散之后，就乘坐新干线原路返回京都了。</p>\n<h2 id=\"后记\"><a href=\"#后记\" class=\"headerlink\" title=\"后记\"></a>后记</h2></h2><p>在这里放一些财团晚上提供的晚餐，晚饭是非常精致的日式会席，除了吃不饱剩下都很完美。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/hj1.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/hj1.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"描述文字\" width=\"70%\">\n  <p style=\"text-align:center;\">晚饭1</p>\n</div>\n\n<div align=\"center\">\n  <img src=\"/images/daily/travel/sctrip25/hj2.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/travel/sctrip25/hj2.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"描述文字\" width=\"70%\">\n  <p style=\"text-align:center;\">晚饭2</p>\n</div>","categories":[{"name":"daily","slug":"daily","permalink":"https://middlemanz.com/categories/daily/"},{"name":"旅行","slug":"daily/travel","permalink":"https://middlemanz.com/categories/daily/travel/"}],"tags":[{"name":"旅行","slug":"旅行","permalink":"https://middlemanz.com/tags/%E6%97%85%E8%A1%8C/"},{"name":"奖学金","slug":"奖学金","permalink":"https://middlemanz.com/tags/%E5%A5%96%E5%AD%A6%E9%87%91/"}]},{"title":"研究记录","date":"2025-10-16T07:19:07.000Z","path":"categories/research/日常/研究日常/","permalink":"https://middlemanz.com/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/","text":"这是我记录研究进展与思考轨迹的地方，若你对这一领域感兴趣，不妨读一读。 2026年01月 2026/01/30 周五 这一周分成了两大部分：无穷无尽的修正论文中的日语表达；检查为什么AIM-PLUM不能很好的反应AIM-ALPHA的结果（理论上来说比如说AIM-ALPHA计算美国的2100年耕作地面积为1000kha，那么在AIM-PLUM的下推中，把数据分布到格点中时，美国的所有格点值加一起一定等于1000kha,也就是数据是饱和且对应的） 关于修正论文表达： 这里我是真的要感谢我的学长，不厌其烦的一遍一遍帮我修正各种地方。这里不说名字，但是我是真心的感谢🙏🙏🙏。 经历了修改后，我意识到了两件事：1.我的日语写作是真的差；2.上课学的日语和学术日语是截然不同的。 希望修士的时候能有所改进。 而第二部分： 不管的region mode 还是 basin mode，AIM-PLUM的推计结果都是和AIM-ALPHA的结果不一致的。 这里的不一致是 PLUM的话推计结果一定比ALPHA小，但是正常应该是相等的。 作为原因有以下可能： 各个计算没有成功满足制约条件 如果满足了的话，模型输入的某一个parameter可能有bug 模型本身就是有问题的 这部分的话我估计大概率是得在离开研究室之前完成的。 2026/01/24 周六 这两周里主要干的事情有： 写完了GTAP的论文并修改上交 准备了全体组会的发表资料，并相应做了一部分数据的修改和计算 进行了组会的发表，这次发表是毕业答辩的排练 和教授汇报了关于AIM-PLUM的问题，并和两位学长+教授一起进行了长达两个小时的探讨 编写了毕业论文的摘要并修改 简单修改了毕业论文的前三章节：背景、既往研究 手法 未来一周要干的事情： 补全毕业论文的结果和考察部分 细致修改毕业论文的全部内容 到现在为止研究的目的就比较明确了，第一点是【输入分辨率高会使土地利用下推结果更准确】，第二点是【输入分辨率高可以让下游的下推模型更好的传达上游模型的信息至格点数据】。 不过在发表后教授提出了两点问题： 利用基准年2005年的数据来比较是否逻辑上可行，因为模型本身就是基于2005年的数据来进行推算的。如果可行的话，把单一的和2005年的数据比较换成和2050-2005的差值比较——也就是比较变化趋势可能逻辑上会更通顺一些。 在basin mode中，正常状态下经过AIM-PLUM下推后各流域数据应该和下推前保持完全一致。但是我的结果显示虽然整体上是线性一致的，但是并不是完全相同。所以教授觉得可能是模型出了一些问题。 目前我还不知道怎么解决问题，有点不打算解决了哈哈哈 发表后和教授探讨了一下AIM-PLUM的格点计算问题。洋洋洒洒讨论了前三十分钟后，发现教授印象中的和实际的数据完全不一样，给我的信息也是错的。 后面进入探讨接下来怎么做的环节。改了一下我的分析方法。我已经做完了分析得到了数据，但是这个的优先度要放在毕业论文后面了。（和教授说明了一下情况，教授允许我不大改目前的论文，这部分分析就是做着但是不用加入论文。万幸了） 2025/01/07 周三 2025&#x2F;12&#x2F;27-2026&#x2F;01&#x2F;04是日本的新年假期，因为研究已经完成了绝大部分，时间以及比较宽裕，所以这段时间基本就纯玩了（就是没学习）。 从01&#x2F;05开始按照新的研究计划一步一步进行： 更改最终报告（已完成） 写GTAP英文论文的abstract 进行追加项目的分析： 确认数据分布的变化速度：变化量集中程度等 对变化量去做 Moran’s I 对数据计算尖度（Kurtosis） 2025年12月 2025/12/26 周五 居然有一个月都没有记录研究进展了，今天给补齐。这一个月发生了很多事情，计划变化了很多，产出也有很多。我按时间一点一点来。 ··· 2025&#x2F;12&#x2F;08-2025&#x2F;12&#x2F;16 最终报告执笔论文的最终目的是 判断region 和 basin 模式下土地利用的推计哪一个在基准年更准确。 判断在基准年以后的两个模式的分布模式：分布差别，数据集中程度，等等。 所以基于以上目的做了如下分析 计算各年份的两个模式的输出差值的四分位数以此判断差值的分布情况 计算了在基准年下两个模式和LUH3的Kappa系数 计算了耕作地、牧草地、森林各自的变化最大的流域并作图 从流域分辨率聚合地域分辨率，计算两个模式的收量 计算了两个模式对于基准年的Kappa系数的变化（2010 vs 2005; 2020 vs 2005） 计算了两个模式之间的Kappa系数（判断两个模式间的输出差异） 计算了两个模式以及三个土地利用分类下的Global Moran’s I的值（全世界+各地域） 利用PREDICTS模型计算了两个模式下的生物多样性指标BII的值 并总结成了论文。第一稿的话算上参考文献一共50页，20000+字。上述计算大多使用python的numpy、pandas和matplotlib库。为了计算一些特定系数（比如Kappa）和更改文件格式也用了一些特殊的库。 在这途中有一些感悟： 对于数据分析来说numpy和pandas真的是重中之重。 不管对于什么而言，只要是科研，画图就是必须要掌握的。 把功能用函数封装，目前来讲还用不到类 每写完一个函数都要调试，所以用ipynb &gt;&gt;&gt; py 文件 多用版本控制git 文件夹的分类一定要细分，否则一堆文件在一个文件夹里分不清哪个是哪个的。 ··· 2025&#x2F;12&#x2F;16-2025&#x2F;12&#x2F;22 最终报告发表准备 这段时间就是把论文准备成PPT。没什么太多可说的。 有几点有些许变化： 并不是收量变化会导致分布会变的分散或者集中。整体的机制是这样的：AgLU模型会考虑各个国家和流域的需要、生产力、出口进口贸易等等来确认该国家、地域的农作物产出面积。随后AgLU模型会输出400个地域的粮食生产面积，能力等，我们把这个数据输入到AIM-PLUM里，AIM-PLUM会去在考虑费用等情况下去吧耕作地面积给分配到各个各自里。所以说收量增长和土地利用面积增加会有相关关系但不是因果关系。 从上面的解释就能看出来两个模式的区别，在basin模式中，因为输入数据完整的保留了各个流域的计算结果，所以下推后的地图包含了很多情报和细节。在region模式中，因为吧数据直接聚集到了大洲分辨率，所以所有情报就被消除掉了。 结合1,2，进行了一个新的计算，就是对于特定的一年，把每一个地域的basin模式、region模式、AgLU的农作物输出面积做成两个散点图。（basin,Aglu）和（region,AgLU），实际结果来看，basin,AgLU的结果线性相关更大一些——basin模型会更加随着上游模型的输出变化而变化。 ··· 2025&#x2F;12&#x2F;23-2025&#x2F;12&#x2F;26 最终报告反馈及题目决定 从反馈来看，研究整体已经满足了毕业论文的要求。但是很令我无语的一点是，在反馈和comment的环节，老师说：“你现在的指标不能反应我想看的东西。”意思就是说，其实我想看的是另外一个事情，你做的东西看不出来。后来经我了解，本来aimhub的17地域下推结果存在一个问题就是，经过线性规划之后，模型输出在有的地方会突然蹦到最大值然后锁死——这明显不符合规律因为作物面积的增长都是随时间线性增加的，不会出现突然一大片从无到有的情况。所以开发了用AgLU的Basin和Region模式，目的是通过使输入变得更加精细，避免上述问题。 然而老师再给我传达研究目的的时候简单的把这个问题称为了：“我们想看哪个模式更好。” 能排除我最开始没听清楚的可能，因为我问了所有学长，所有人都表示他们也不清楚，不过他们也习惯了:「この研究室はそんなもんだ」。这么说的话我就释然了，不过依旧不能苟同这种做事方法。 为了进一步的展现模型的问题到底有没有解决，准备做以下新的指标： 不直接对数据做Moran’s I，对每相邻两年的差值做Moran’s I，这样应该能反映出变化是逐渐，均匀的还是突然、激烈的。 对数据做尖度的计算，判断数据是否存在剑锋（就是突然增加） 以及对于差值计算 比如说 最大的百分之五的格子的面积增加占了全体的百分之多少这样，来判断是不是增加全都被分配给了少数格子。 然后还有一件事：正常来说我的研究是要去参加明年六月份在京都召开的GTAP会议的发表的。但是因为我明年不在研究室了，所以老师想让学长拿我的结果去发表（一作还是我的名字）。为了参加这个会议，我需要在一月份先交一个3页的英文abstract，如果合格了的话就在四月前再交一个完全版。 我目前有点犹豫，在犹豫收货和付出是否成正比，因为写论文需要花时间，但是就算去发表了我也收获不到什么，因为可能不会读博。唉，再考虑考虑。 ··· 2025年11月 2025/11/27 周四 周二一直都在尝试debug 流域和格点的mapping程序。但是遇到了很多问题： 程序的依赖packages在hpc上很难实装，而在本地电脑上因为计算量太大而不现实。 程序的输出需要调用gams的api接口来输出gdxfiles 但是貌似我的gams版本不够没法调用（最新的因为要花钱不能装） 因为没有办法运行所以也不知道怎么debug，单看代码又太抽象 尝试解决： 配置一个conda环境，在里面安装所有依赖 第二个问题至今没有解决——学长和我说这种debug本来不应该是B4的学生做的，但是没办法老师就让了。 他说最好的方法就是先放置一下，不管他。 周三进行了发表，发表整体还是比较顺利，但是在答疑的过程中对自己表现不是很满意，学姐用英文问我然后我也是好久没练了，也有点紧张，回答的没有什么逻辑。还是得多练练口语才行。 发表结束后就正式的进入考察分析环节，接下来就是对数据进行各种计算了。最终报告的deadline是12.16，希望在这之前能顺利的写完。 2025/11/23 周日 才有时间更新一下周五的结果 （水一天） 老师貌似对于我的成果还是比较满意的，整体的组会下来整理几点： 需要再去看一下mapping的程序，看看对于格子的分配有没有遗漏或者重叠。 对于结果的考察增加以下内容：1、利用kappa系数观察不同地图的相似度。2、计算对于基准年的各年份的土地利用变化。3、继续修改predicts直到出结果。 下周全体发表，发表完之后进入接下来的结果分析环节。 2025/11/21 周五 今天是sustainability的组会，趁着孔隙写一下总结。 周一成功的跑出了结果，在master branch下region mode 和basin mode输出了看起来正确的数值。 周二：为了验证数值的准确性，把400流域下的数值进行了聚类——合并成了17地域的类型。和region mode进行了比较后发现几乎在所有项目两者都有近10%的误差于是开始请教学长、查代码、问老师等等等。 周三大组会，开完之后问了老师如何判断，小老板说了一大堆，我挑重点的回去试了试，但是也没太整明白。只查到了在data prep下有一些格子看起来有一些奇怪。等待今天组会问老师。 周五小组组会，目前还没到我，我问完老师后更新。 2025/11/17 周一 今天又是收获满满的一天。 到达研究室开始一直在debug：master branch 的 basin mode 的输出非常奇怪，所以一步步溯源往回找各个值是怎么算出来的。 其实这是一个非常痛苦的过程，因为对于刚进研究室没怎么用过模型的人来说，是这样的： Z的数值有问题，需要看Z的数值是怎么计算来的 Z由X+Y组成，看X+Y是怎么来的 X由U+V+W组成，还分情况讨论 Y由U+T+S组成，也分情况 然后无限套娃 重点是每一个变量的名字比我的例子里的复杂多了，比如 123456789101112131415161718192021Y_pre(&quot;OL&quot;,G)$(landshare(G))=Y_pre(&quot;OL&quot;,G)*landshare(G)+(1-landshare(G));Y_pre(&quot;SL&quot;,G)$(Y_pre(&quot;SL&quot;,G) and landshare(G))=Y_pre(&quot;SL&quot;,G)*landshare(G);$else.baseyear$ifthen.fileex exist &#x27;../output/gdx/%SceName%/%Sr%/%pre_year%.gdx&#x27;$ gdxin &#x27;../output/gdx/%SceName%/%Sr%/%pre_year%.gdx&#x27;$ load VY_load=VYL VZ_load=VZL$ load PLDM_load=PLDM PCDM_load=PCDM$gdxin &#x27;../output/gdx/base/%Sr%/basedata.gdx&#x27;$load GATwoOL$else.fileex VY_load(L,G)=0;$endif.fileex*Y_pre(L,G)$(VY_load(L,G))=VY_load(L,G);Y_pre(L,G)$(VY_load(L,G) and not sameas(L,&quot;SL&quot;))=VY_load(L,G);*---load SL data for every year excl. base yrY_pre(&quot;SL&quot;,G)$(sum(R17,SSP_frac(&quot;SL&quot;,&quot;%Sy%&quot;,R17,G))*landshare(G)) = sum(R17,SSP_frac(&quot;SL&quot;,&quot;%Sy%&quot;,R17,G))*landshare(G); 寻找了一大通之后发现进入了纯nlp环节，代码不是我能看得懂的，遂打算求助于老师。这时候发现，模型的输入数据是错误的，所有作物面积都相等，学长之前虽然改正了但是没有给我发正确的。 现在在重新跑模型尝试。 2025/11/10 周一 今天干的事情有亿点点多： 小老板说模型做完了，于是我就试着跑了一下 master branch 的 region mode 和 basin mode。 上来直接是一个大失败D1/D20，仔细看了一会log之后发现是模型在映射scenario（情景）名字的时候，错误映射了一个已经被淘汰的情景名称。 修改了这个问题之后分开来讲 basin mode: base year 和 future year 的simulation 都生成了，现在卡在scenario merge这一块，也就是把输出给合并起来的这一部分。截至写文时还在跑。 region mode: 所有地域的base year simulation全部失败。输出： Model has been proven infeasible 。看了看原因发现是 Reduced gradient less than tolerance ,也就是梯度下降小于阈值（用人话说是计算不收敛，无效）。 给老板们发了slack说明问题，目前还在等回复。 看起来事情不多但是寻找哪里出现了问题占用了相当长的时间。精疲力尽。 2025/11/05 周三 几乎毫无进展的一周：小老板还没有联系我她做没做完模型，她不进展我就没法继续。今天给她发了邮件询问，希望能有结果。 非要说干了什么的话，用develop_basin_mode跑通了predict,输出了生物多样性指标（BII）。不过貌似有点bug：有一些地域的值异常的高或者低，能到达10的30次方左右笑（BII应该在0-1之间）。 2025年10月 2025/10/30 周四 周一跑的两个模型都没有跑通，于是准备用之前的develop_basin_mode分支来跑AgLU/AIM-PLUM的basinmode + predict。 但是之前merge了老师上传的PR之后 这个分支就充斥着bug，根本无法运行。于是只能一遍一遍退回commit来找到一个可以运行的版本。 回退了两次之后终于找到了一个似乎能用的，截止写文模型还在运行。 （晚上八点多模型终于跑完了，这次比上次还多用了2个小时，模型模拟的时间已经来到了8小时） 2025/10/27 周一 今天主要内容就是和学长确认了一下整个模型的进度以及接下来的やること。 用master分支跑一下AgLU&#x2F;AIM-PLUM的basinmode + predict 用master分支测试一下AgLU&#x2F;AIM-PLUM的regionmode 截止本文时间，模型已经跑完了但是结果确认需要等到周三去研究室才能进行 2025/10/20 周一 本来以为上周进展挺顺利，这周任务应该不重。但是今天又和老师来回mail了无数轮来确认模型运转时间长的原因，导致也没能早回家。 和老师交流后目前确认到的内容如下： 之前downscale AIMHUB的时候，模型输出的是17地域数据，也就是把世界分成17份。downscale一共用时90分钟。现在AgLU模型把全世界分成400份（虽然不均匀）但是其中有一些区域的用时反而比之前多了。也就是说模型下推小的面积比大的面积用时还要长。老师怀疑模型根本没有输出确定解但是没有证据。 模型一共用32个CPU线程；整个模型里一共400个流域，每一个流域要按时间计算10次（2010，2020，…，2100），所以一共是4000次计算。这四千个计算是随机分配到32个CPU线程里的！（当然对于每一个流域而言，靠后的年份肯定是在所有的前置年份计算完成后再计算的（因为后面的需要前面的数据））我之前以为是把400个流域随机分给32个线程，没想到是完全随机分的。 两个很有经验的学长以及老师们对原因毫无头绪😅 接下来是等待小老板把需要改动的regionmode做完。 2025/10/17 周五 今天小老板给了我新版的AgLU模型，好像解决了昨天说的问题。截止写文模型还在跑。 AgLU400流域的下推至此就小告一段落，接下来的是把400流域的数据重置为17地域的数据并让AIM-PLUM跑通，这涉及如下几个小问题： 如何把数据从细分的400地域映射到17地域 如何让AIM-PLUM识别这些数据 更改AIM-PLUM的数据输入部分使其能直接对应AgLU的最新标准输出 接下来就是一点一点做了。 2025/10/16 周四 模型运行结束了，虽然中间过程数据已生成，但最终的 nc 文件未出现预期更新，还是之前的零星几个国家的程度。 于是开始从头看代码，运行文件，报错文件。最后定位到 base year simulation那里，有20个流域（多为热带岛国，可能由于这些流域在地理或数据特征上的共性所致）在进行基准年计算的时候显示 Equation infeasible due to rhs value （约束条件右端值设置不当导致方程不可行） 所以导致该流域的base.gdx, 2005.gdx无法生成。后续也就无法继续根据基准年数据来模拟未来的结果（2010…2100.gdx）。因为没有后续数据，所以在整合gdx的时候，形成了一个空文件，导致在进行计算的时候报错，无法形成base_SSP2_BaU_NoCC.gdx导致后续所有都生成失败。 作为解决方法，我在第一次生成数据之后手动修改Plum_exe.sh；执行脚本文件，阻止其粘贴空文件到下一个执行文件夹。这样的话虽然少了20个流域，但是模型可以执行到最后并输出数据。后续计划加入在执行脚本中添加条件判断，避免空文件被复制至下一阶段目录。 下面这张图是本次进展的结果之一：这张是模型预测的2100年全球农作物分布图。图片下方的scale的caption有一个小错误——并不是%百分率而是占比，也就是说深红的那个格子百分之百都是农作物，而深蓝格子没有农作物出现。 AgLU模型400流域集约结果下推图 更加详尽的研究介绍参见分类-研究-本科研究 2025/10/15 周三 写模型的老师告诉了我把 AIMPLUM的Aglu版 的设定更改为 global: on之后应该对应修改Plum.sh 。至此，困扰了我和前辈一个月的模型bug终于被解决了。其实这不是bug，而是沟通问题，如果老师能在递交模型的时候告诉我们参数设定对应的改动，就不会有后续的麻烦了（因为模型本身并没有readme或者说明doc）。 截止写总结，模型已经运行了3.5小时了，仍然没有结束。对于俄罗斯和加拿大的每个流域，每计算10年大概需要花40分钟，所以从2005年计算到2100就大致需要6个小时。大概是对比其他国家而言，上述的流域本身的面积非常大。","content":"<div class=\"note info\"><p>这是我记录研究进展与思考轨迹的地方，若你对这一领域感兴趣，不妨读一读。</p></div>\n\n<span id=\"more\"></span>\n\n<h3 style=\"text-align:center; font-weight:bold;\">2026年01月</h3>\n<hr style=\"border: 2px solid #888; width: 100%; margin-top: 5px; margin-bottom: 15px;\">\n\n<h4 id=\"20260130\" style=\"text-align:center; font-weight:bold;\">2026/01/30 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>这一周分成了两大部分：无穷无尽的修正论文中的日语表达；检查为什么AIM-PLUM不能很好的反应AIM-ALPHA的结果（理论上来说比如说AIM-ALPHA计算美国的2100年耕作地面积为1000kha，那么在AIM-PLUM的下推中，把数据分布到格点中时，美国的所有格点值加一起一定等于1000kha,也就是数据是饱和且对应的）</p>\n<p>关于修正论文表达： 这里我是真的要感谢我的学长，不厌其烦的一遍一遍帮我修正各种地方。这里不说名字，但是我是真心的感谢🙏🙏🙏。 经历了修改后，我意识到了两件事：1.我的日语写作是真的差；2.上课学的日语和学术日语是截然不同的。</p>\n<p>希望修士的时候能有所改进。</p>\n<p>而第二部分：</p>\n<ul>\n<li>不管的region mode 还是 basin mode，AIM-PLUM的推计结果都是和AIM-ALPHA的结果不一致的。</li>\n<li>这里的不一致是 PLUM的话推计结果一定比ALPHA小，但是正常应该是相等的。</li>\n<li>作为原因有以下可能：<ul>\n<li>各个计算没有成功满足制约条件</li>\n<li>如果满足了的话，模型输入的某一个parameter可能有bug</li>\n<li>模型本身就是有问题的</li>\n</ul>\n</li>\n</ul>\n<p>这部分的话我估计大概率是得在离开研究室之前完成的。</p>\n<h4 id=\"20260124\" style=\"text-align:center; font-weight:bold;\">2026/01/24 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n这两周里主要干的事情有：\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>写完了GTAP的论文并修改上交</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>准备了全体组会的发表资料，并相应做了一部分数据的修改和计算</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>进行了组会的发表，这次发表是毕业答辩的排练</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>和教授汇报了关于AIM-PLUM的问题，并和两位学长+教授一起进行了长达两个小时的探讨</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>编写了毕业论文的摘要并修改</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>简单修改了毕业论文的前三章节：背景、既往研究 手法</p>\n            </div>\n\n<p>未来一周要干的事情：</p>\n<div class='checkbox red'><input type=\"checkbox\" />\n            <p>补全毕业论文的结果和考察部分</p>\n            </div>\n<div class='checkbox red'><input type=\"checkbox\" />\n            <p>细致修改毕业论文的全部内容</p>\n            </div>\n\n<p>到现在为止研究的目的就比较明确了，第一点是【输入分辨率高会使土地利用下推结果更准确】，第二点是【输入分辨率高可以让下游的下推模型更好的传达上游模型的信息至格点数据】。</p>\n<p>不过在发表后教授提出了两点问题：</p>\n<ul>\n<li>利用基准年2005年的数据来比较是否逻辑上可行，因为模型本身就是基于2005年的数据来进行推算的。如果可行的话，把单一的和2005年的数据比较换成和2050-2005的差值比较——也就是比较变化趋势可能逻辑上会更通顺一些。</li>\n<li>在basin mode中，正常状态下经过AIM-PLUM下推后各流域数据应该和下推前保持完全一致。但是我的结果显示虽然整体上是线性一致的，但是并不是完全相同。所以教授觉得可能是模型出了一些问题。</li>\n</ul>\n<psw>目前我还不知道怎么解决问题，有点不打算解决了哈哈哈</psw>\n\n<p>发表后和教授探讨了一下AIM-PLUM的格点计算问题。洋洋洒洒讨论了前三十分钟后，发现教授印象中的和实际的数据完全不一样，给我的信息也是错的。</p>\n<p>后面进入探讨接下来怎么做的环节。改了一下我的分析方法。我已经做完了分析得到了数据，但是这个的优先度要放在毕业论文后面了。（和教授说明了一下情况，教授允许我不大改目前的论文，这部分分析就是做着但是不用加入论文。万幸了）</p>\n<h4 id=\"20250107\" style=\"text-align:center; font-weight:bold;\">2025/01/07 周三</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>2025&#x2F;12&#x2F;27-2026&#x2F;01&#x2F;04是日本的新年假期，因为研究已经完成了绝大部分，时间以及比较宽裕，所以这段时间基本就纯玩了（就是没学习）。</p>\n<p>从01&#x2F;05开始按照新的研究计划一步一步进行：</p>\n<ul>\n<li>更改最终报告（已完成）</li>\n<li>写GTAP英文论文的abstract</li>\n<li>进行追加项目的分析：<ul>\n<li>确认数据分布的变化速度：变化量集中程度等</li>\n<li>对变化量去做 Moran’s I</li>\n<li>对数据计算尖度（Kurtosis）</li>\n</ul>\n</li>\n</ul>\n<h3 style=\"text-align:center; font-weight:bold;\">2025年12月</h3>\n<hr style=\"border: 2px solid #888; width: 100%; margin-top: 5px; margin-bottom: 15px;\">\n\n<h4 id=\"20251226\" style=\"text-align:center; font-weight:bold;\">2025/12/26 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>居然有一个月都没有记录研究进展了，今天给补齐。这一个月发生了很多事情，计划变化了很多，产出也有很多。我按时间一点一点来。</p>\n<p>···</p>\n<p>2025&#x2F;12&#x2F;08-2025&#x2F;12&#x2F;16 最终报告执笔<br>论文的最终目的是</p>\n<ol>\n<li>判断region 和 basin 模式下土地利用的推计哪一个在基准年更准确。</li>\n<li>判断在基准年以后的两个模式的分布模式：分布差别，数据集中程度，等等。</li>\n</ol>\n<p>所以基于以上目的做了如下分析</p>\n<ol>\n<li>计算各年份的两个模式的输出差值的四分位数以此判断差值的分布情况</li>\n<li>计算了在基准年下两个模式和LUH3的Kappa系数</li>\n<li>计算了耕作地、牧草地、森林各自的变化最大的流域并作图</li>\n<li>从流域分辨率聚合地域分辨率，计算两个模式的收量</li>\n<li>计算了两个模式对于基准年的Kappa系数的变化（2010 vs 2005; 2020 vs 2005）</li>\n<li>计算了两个模式之间的Kappa系数（判断两个模式间的输出差异）</li>\n<li>计算了两个模式以及三个土地利用分类下的Global Moran’s I的值（全世界+各地域）</li>\n<li>利用PREDICTS模型计算了两个模式下的生物多样性指标BII的值</li>\n</ol>\n<p>并总结成了论文。第一稿的话算上参考文献一共50页，20000+字。上述计算大多使用python的numpy、pandas和matplotlib库。为了计算一些特定系数（比如Kappa）和更改文件格式也用了一些特殊的库。</p>\n<p>在这途中有一些感悟：</p>\n<ol>\n<li>对于数据分析来说numpy和pandas真的是重中之重。</li>\n<li>不管对于什么而言，只要是科研，画图就是必须要掌握的。</li>\n<li>把功能用函数封装，目前来讲还用不到类</li>\n<li>每写完一个函数都要调试，所以用ipynb &gt;&gt;&gt; py 文件</li>\n<li>多用版本控制git</li>\n<li>文件夹的分类一定要细分，否则一堆文件在一个文件夹里分不清哪个是哪个的。</li>\n</ol>\n<p>···</p>\n<p>2025&#x2F;12&#x2F;16-2025&#x2F;12&#x2F;22 最终报告发表准备</p>\n<p>这段时间就是把论文准备成PPT。没什么太多可说的。</p>\n<p>有几点有些许变化：</p>\n<ol>\n<li>并不是收量变化会导致分布会变的分散或者集中。整体的机制是这样的：<u>AgLU模型会考虑各个国家和流域的需要、生产力、出口进口贸易等等来确认该国家、地域的农作物产出面积</u>。随后AgLU模型会输出400个地域的粮食生产面积，能力等，我们把这个数据输入到AIM-PLUM里，AIM-PLUM会去在考虑费用等情况下去吧耕作地面积给分配到各个各自里。所以说收量增长和土地利用面积增加会有<strong>相关关系</strong>但不是<strong>因果关系</strong>。</li>\n<li>从上面的解释就能看出来两个模式的区别，在basin模式中，因为输入数据完整的保留了各个流域的计算结果，所以下推后的地图包含了很多情报和细节。在region模式中，因为吧数据直接聚集到了大洲分辨率，所以所有情报就被消除掉了。</li>\n<li>结合1,2，进行了一个新的计算，就是对于特定的一年，把每一个地域的basin模式、region模式、AgLU的农作物输出面积做成两个散点图。（basin,Aglu）和（region,AgLU），实际结果来看，basin,AgLU的结果线性相关更大一些——basin模型会更加随着上游模型的输出变化而变化。</li>\n</ol>\n<p>···</p>\n<p>2025&#x2F;12&#x2F;23-2025&#x2F;12&#x2F;26 最终报告反馈及题目决定</p>\n<p>从反馈来看，研究整体已经满足了毕业论文的要求。但是很令我无语的一点是，在反馈和comment的环节，老师说：“你现在的指标不能反应我想看的东西。”意思就是说，其实我想看的是另外一个事情，你做的东西看不出来。后来经我了解，本来aimhub的17地域下推结果存在一个问题就是，经过线性规划之后，模型输出在有的地方会突然蹦到最大值然后锁死——这明显不符合规律因为作物面积的增长都是随时间线性增加的，不会出现突然一大片从无到有的情况。所以开发了用AgLU的Basin和Region模式，目的是通过使输入变得更加精细，避免上述问题。</p>\n<p>然而老师再给我传达研究目的的时候简单的把这个问题称为了：“我们想看哪个模式更好。” 能排除我最开始没听清楚的可能，因为我问了所有学长，所有人都表示他们也不清楚，不过他们也习惯了:「この研究室はそんなもんだ」。这么说的话我就释然了，不过依旧不能苟同这种做事方法。</p>\n<p>为了进一步的展现模型的问题到底有没有解决，准备做以下新的指标：</p>\n<ol>\n<li>不直接对数据做Moran’s I，对每相邻两年的差值做Moran’s I，这样应该能反映出变化是逐渐，均匀的还是突然、激烈的。</li>\n<li>对数据做尖度的计算，判断数据是否存在剑锋（就是突然增加）</li>\n<li>以及对于差值计算 比如说 最大的百分之五的格子的面积增加占了全体的百分之多少这样，来判断是不是增加全都被分配给了少数格子。</li>\n</ol>\n<p>然后还有一件事：正常来说我的研究是要去参加明年六月份在京都召开的GTAP会议的发表的。但是因为我明年不在研究室了，所以老师想让学长拿我的结果去发表（一作还是我的名字）。为了参加这个会议，我需要在一月份先交一个3页的英文abstract，如果合格了的话就在四月前再交一个完全版。</p>\n<p>我目前有点犹豫，在犹豫收货和付出是否成正比，因为写论文需要花时间，但是就算去发表了我也收获不到什么，因为可能不会读博。唉，再考虑考虑。</p>\n<p>···</p>\n<h3 style=\"text-align:center; font-weight:bold;\">2025年11月</h3>\n<hr style=\"border: 2px solid #888; width: 100%; margin-top: 5px; margin-bottom: 15px;\">\n\n<h4 id=\"20251127\" style=\"text-align:center; font-weight:bold;\">2025/11/27 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>周二一直都在尝试debug 流域和格点的mapping程序。<br>但是遇到了很多问题：</p>\n<ul>\n<li>程序的依赖packages在hpc上很难实装，而在本地电脑上因为计算量太大而不现实。</li>\n<li>程序的输出需要调用gams的api接口来输出gdxfiles 但是貌似我的gams版本不够没法调用（最新的因为要花钱不能装）</li>\n<li>因为没有办法运行所以也不知道怎么debug，单看代码又太抽象</li>\n</ul>\n<p>尝试解决：</p>\n<ul>\n<li>配置一个conda环境，在里面安装所有依赖</li>\n<li>第二个问题至今没有解决——学长和我说这种debug本来不应该是B4的学生做的，但是没办法老师就让了。 他说最好的方法就是先放置一下，不管他。</li>\n</ul>\n<p>周三进行了发表，发表整体还是比较顺利，但是在答疑的过程中对自己表现不是很满意，学姐用英文问我然后我也是好久没练了，也有点紧张，回答的没有什么逻辑。还是得多练练口语才行。</p>\n<p>发表结束后就正式的进入考察分析环节，接下来就是对数据进行各种计算了。最终报告的deadline是12.16，希望在这之前能顺利的写完。</p>\n<h4 id=\"20251123\" style=\"text-align:center; font-weight:bold;\">2025/11/23 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>才有时间更新一下周五的结果  <psw>（水一天）</psw></p>\n<p>老师貌似对于我的成果还是比较满意的，整体的组会下来整理几点：</p>\n<ul>\n<li>需要再去看一下mapping的程序，看看对于格子的分配有没有遗漏或者重叠。</li>\n<li>对于结果的考察增加以下内容：1、利用kappa系数观察不同地图的相似度。2、计算对于基准年的各年份的土地利用变化。3、继续修改predicts直到出结果。</li>\n</ul>\n<p>下周全体发表，发表完之后进入接下来的结果分析环节。</p>\n<h4 id=\"20251121\" style=\"text-align:center; font-weight:bold;\">2025/11/21 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天是sustainability的组会，趁着孔隙写一下总结。</p>\n<p>周一成功的跑出了结果，在<code>master branch</code>下<code>region mode</code> 和<code>basin mode</code>输出了看起来正确的数值。</p>\n<p>周二：为了验证数值的准确性，把400流域下的数值进行了聚类——合并成了17地域的类型。和<code>region mode</code>进行了比较后发现<u>几乎在所有项目两者都有近10%的误差</u>于是开始请教学长、查代码、问老师等等等。</p>\n<p>周三大组会，开完之后问了老师如何判断，小老板说了一大堆，我挑重点的回去试了试，但是也没太整明白。只查到了在<code>data prep</code>下有一些格子看起来有一些奇怪。等待今天组会问老师。</p>\n<p>周五小组组会，目前还没到我，我问完老师后更新。</p>\n<h4 id=\"20251117\" style=\"text-align:center; font-weight:bold;\">2025/11/17 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天又是收获满满的一天。</p>\n<p>到达研究室开始一直在debug：master branch 的 basin mode 的输出非常奇怪，所以一步步溯源往回找各个值是怎么算出来的。</p>\n<p>其实这是一个非常痛苦的过程，因为对于刚进研究室没怎么用过模型的人来说，是这样的：</p>\n<ul>\n<li>Z的数值有问题，需要看Z的数值是怎么计算来的</li>\n<li>Z由X+Y组成，看X+Y是怎么来的</li>\n<li>X由U+V+W组成，还分情况讨论</li>\n<li>Y由U+T+S组成，也分情况</li>\n<li>然后无限套娃</li>\n</ul>\n<p>重点是每一个变量的名字比我的例子里的复杂多了，比如</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Y_pre(&quot;OL&quot;,G)$(landshare(G))=Y_pre(&quot;OL&quot;,G)*landshare(G)+(1-landshare(G));</span><br><span class=\"line\">Y_pre(&quot;SL&quot;,G)$(Y_pre(&quot;SL&quot;,G) and landshare(G))=Y_pre(&quot;SL&quot;,G)*landshare(G);</span><br><span class=\"line\"></span><br><span class=\"line\">$else.baseyear</span><br><span class=\"line\">$ifthen.fileex exist &#x27;../output/gdx/%SceName%/%Sr%/%pre_year%.gdx&#x27;</span><br><span class=\"line\">$\tgdxin &#x27;../output/gdx/%SceName%/%Sr%/%pre_year%.gdx&#x27;</span><br><span class=\"line\">$\tload VY_load=VYL VZ_load=VZL</span><br><span class=\"line\">$\tload PLDM_load=PLDM PCDM_load=PCDM</span><br><span class=\"line\"></span><br><span class=\"line\">$gdxin &#x27;../output/gdx/base/%Sr%/basedata.gdx&#x27;</span><br><span class=\"line\">$load GATwoOL</span><br><span class=\"line\"></span><br><span class=\"line\">$else.fileex</span><br><span class=\"line\">  VY_load(L,G)=0;</span><br><span class=\"line\">$endif.fileex</span><br><span class=\"line\"></span><br><span class=\"line\">*Y_pre(L,G)$(VY_load(L,G))=VY_load(L,G);</span><br><span class=\"line\">Y_pre(L,G)$(VY_load(L,G) and not sameas(L,&quot;SL&quot;))=VY_load(L,G);</span><br><span class=\"line\"></span><br><span class=\"line\">*---load SL data for every year excl. base yr</span><br><span class=\"line\">Y_pre(&quot;SL&quot;,G)$(sum(R17,SSP_frac(&quot;SL&quot;,&quot;%Sy%&quot;,R17,G))*landshare(G)) = sum(R17,SSP_frac(&quot;SL&quot;,&quot;%Sy%&quot;,R17,G))*landshare(G);</span><br></pre></td></tr></table></figure>\n\n<p>寻找了一大通之后发现进入了纯nlp环节，代码不是我能看得懂的，遂打算求助于老师。这时候发现，<emp>模型的输入数据是错误的，所有作物面积都相等，学长之前虽然改正了但是没有给我发正确的。</emp></p>\n<p>现在在重新跑模型尝试。</p>\n<h4 id=\"20251110\" style=\"text-align:center; font-weight:bold;\">2025/11/10 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天干的事情有亿点点多：\n\n<ol>\n<li><p>小老板说模型做完了，于是我就试着跑了一下 <code>master branch</code> 的 <code>region mode</code> 和 <code>basin mode</code>。</p>\n</li>\n<li><p>上来直接是一个大失败<psw>D1/D20</psw>，仔细看了一会log之后发现是模型在映射scenario（情景）名字的时候，错误映射了一个已经被淘汰的情景名称。</p>\n</li>\n<li><p>修改了这个问题之后分开来讲</p>\n<ul>\n<li>basin mode: base year 和 future year 的simulation 都生成了，现在卡在scenario merge这一块，也就是把输出给合并起来的这一部分。截至写文时还在跑。</li>\n<li>region mode: 所有地域的base year simulation全部失败。输出： <code>Model has been proven infeasible</code> 。看了看原因发现是 <code>Reduced gradient less than tolerance</code> ,也就是梯度下降小于阈值（用人话说是计算不收敛，无效）。</li>\n</ul>\n</li>\n<li><p>给老板们发了slack说明问题，目前还在等回复。</p>\n</li>\n</ol>\n<p>看起来事情不多但是寻找哪里出现了问题占用了相当长的时间。精疲力尽。</p>\n<h4 id=\"20251105\" style=\"text-align:center; font-weight:bold;\">2025/11/05 周三</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n几乎毫无进展的一周：小老板还没有联系我她做没做完模型，她不进展我就没法继续。今天给她发了邮件询问，希望能有结果。\n\n<p>非要说干了什么的话，用develop_basin_mode跑通了predict,输出了生物多样性指标（BII）。不过貌似有点bug：有一些地域的值异常的高或者低，能到达10的30次方左右笑（BII应该在0-1之间）。</p>\n<h3 style=\"text-align:center; font-weight:bold;\">2025年10月</h3>\n<hr style=\"border: 2px solid #888; width: 100%; margin-top: 5px; margin-bottom: 15px;\">\n\n<h4 id=\"20251030\" style=\"text-align:center; font-weight:bold;\">2025/10/30 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n周一跑的两个模型都没有跑通，于是准备用之前的develop_basin_mode分支来跑AgLU/AIM-PLUM的basinmode + predict。\n\n<p>但是之前merge了老师上传的PR之后 这个分支就充斥着bug，根本无法运行。于是只能一遍一遍退回commit来找到一个可以运行的版本。</p>\n<p>回退了两次之后终于找到了一个似乎能用的，截止写文模型还在运行。</p>\n<p>（晚上八点多模型终于跑完了，这次比上次还多用了2个小时，模型模拟的时间已经来到了8小时）</p>\n<h4 id=\"20251027\" style=\"text-align:center; font-weight:bold;\">2025/10/27 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天主要内容就是和学长确认了一下整个模型的进度以及接下来的やること。</p>\n<div class='checkbox green checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>用master分支跑一下AgLU&#x2F;AIM-PLUM的basinmode + predict</p>\n            </div>\n<div class='checkbox red checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>用master分支测试一下AgLU&#x2F;AIM-PLUM的regionmode</p>\n            </div>\n<p>截止本文时间，模型已经跑完了但是结果确认需要等到周三去研究室才能进行</p>\n<h4 id=\"20251020\" style=\"text-align:center; font-weight:bold;\">2025/10/20 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>本来以为上周进展挺顺利，这周任务应该不重。但是今天又和老师来回mail了无数轮来确认模型运转时间长的原因，导致也没能早回家。</p>\n<p>和老师交流后目前确认到的内容如下：</p>\n<ul>\n<li>之前downscale AIMHUB的时候，模型输出的是17地域数据，也就是把世界分成17份。downscale一共用时90分钟。现在AgLU模型把全世界分成400份（虽然不均匀）但是其中有一些区域的用时反而比之前多了。也就是说模型下推小的面积比大的面积用时还要长。老师怀疑模型根本没有输出确定解但是没有证据。</li>\n<li>模型一共用32个CPU线程；整个模型里一共400个流域，每一个流域要按时间计算10次（2010，2020，…，2100），所以一共是4000次计算。这四千个计算是随机分配到32个CPU线程里的！（当然对于每一个流域而言，靠后的年份肯定是在所有的前置年份计算完成后再计算的（因为后面的需要前面的数据））我之前以为是把400个流域随机分给32个线程，没想到是完全随机分的。</li>\n<li>两个很有经验的学长以及老师们对原因毫无头绪😅</li>\n</ul>\n<p>接下来是等待小老板把需要改动的regionmode做完。</p>\n<h4 id=\"20251017\" style=\"text-align:center; font-weight:bold;\">2025/10/17 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天小老板给了我新版的AgLU模型，好像解决了昨天说的问题。截止写文模型还在跑。</p>\n<p>AgLU400流域的下推至此就小告一段落，接下来的是把400流域的数据重置为17地域的数据并让AIM-PLUM跑通，这涉及如下几个小问题：</p>\n<ul>\n<li>如何把数据从细分的400地域映射到17地域</li>\n<li>如何让AIM-PLUM识别这些数据</li>\n<li>更改AIM-PLUM的数据输入部分使其能直接对应AgLU的最新标准输出</li>\n</ul>\n<p>接下来就是一点一点做了。</p>\n<h4 id=\"20251016\" style=\"text-align:center; font-weight:bold;\">2025/10/16 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>模型运行结束了，虽然中间过程数据已生成，但最终的 nc 文件未出现预期更新，还是之前的零星几个国家的程度。</p>\n<p>于是开始从头看代码，运行文件，报错文件。最后定位到 base year simulation那里，有20个流域（多为热带岛国，可能由于这些流域在地理或数据特征上的共性所致）在进行基准年计算的时候显示<br> <div class=\"note bug red\"><p><code>Equation infeasible due to rhs value （约束条件右端值设置不当导致方程不可行）</code></p></div><br>  所以导致该流域的base.gdx, 2005.gdx无法生成。后续也就无法继续根据基准年数据来模拟未来的结果（2010…2100.gdx）。因为没有后续数据，所以在整合gdx的时候，形成了一个空文件，导致在进行计算的时候报错，无法形成base_SSP2_BaU_NoCC.gdx导致后续所有都生成失败。</p>\n<p>作为解决方法，我在第一次生成数据之后手动修改Plum_exe.sh；执行脚本文件，阻止其粘贴空文件到下一个执行文件夹。这样的话虽然少了20个流域，但是模型可以执行到最后并输出数据。后续计划加入在执行脚本中添加条件判断，避免空文件被复制至下一阶段目录。</p>\n<p>下面这张图是本次进展的结果之一：这张是模型预测的2100年全球农作物分布图。图片下方的scale的caption有一个小错误——并不是%百分率而是占比，也就是说<span style=\"color:darkred;\">深红</span>的那个格子百分之百都是农作物，而<span style=\"color:darkblue;\">深蓝</span>格子没有农作物出现。</p>\n<figure style=\"text-align:center\">\n  <img src=\"/images/251016r.png\" class=\"lazyload\" data-srcset=\"/images/251016r.png\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" width=\"600\" alt=\"模型下推图片\">\n  <figcaption>AgLU模型400流域集约结果下推图</figcaption>\n</figure>\n更加详尽的研究介绍参见分类-研究-本科研究\n\n<h4 id=\"20251015\" style=\"text-align:center; font-weight:bold;\">2025/10/15 周三</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>写模型的老师告诉了我把 AIMPLUM的Aglu版 的设定更改为 <code>global: on</code>之后应该对应修改Plum.sh 。至此，困扰了我和前辈一个月的模型bug终于被解决了。其实这不是bug，而是沟通问题，如果老师能在递交模型的时候告诉我们参数设定对应的改动，就不会有后续的麻烦了（因为模型本身并没有readme或者说明doc）。</p>\n<p>截止写总结，模型已经运行了3.5小时了，仍然没有结束。对于俄罗斯和加拿大的每个流域，每计算10年大概需要花40分钟，所以从2005年计算到2100就大致需要6个小时。大概是对比其他国家而言，上述的流域本身的面积非常大。</p>\n","categories":[{"name":"research","slug":"research","permalink":"https://middlemanz.com/categories/research/"},{"name":"研究记录","slug":"research/researchrecord","permalink":"https://middlemanz.com/categories/research/researchrecord/"}],"tags":[{"name":"日常","slug":"日常","permalink":"https://middlemanz.com/tags/%E6%97%A5%E5%B8%B8/"},{"name":"研究","slug":"研究","permalink":"https://middlemanz.com/tags/%E7%A0%94%E7%A9%B6/"}]},{"title":"桌游记录","date":"2025-10-15T08:45:30.000Z","path":"categories/daily/桌游/桌游记录/","permalink":"https://middlemanz.com/categories/daily/%E6%A1%8C%E6%B8%B8/%E6%A1%8C%E6%B8%B8%E8%AE%B0%E5%BD%95/","text":"记录每一次桌游🎲 2026/02/22 周日 今日桌游: 阿瑞迪亚 点击查看详细内容 12345678910date: 2026-02-22duration: 4hgame: 阿瑞迪亚players: - name: Middleman score: result: 胜 - name: Barbarian score: result: 胜 2026/02/21 周六 今日桌游: 灵迹岛 七大奇迹对决 点击查看详细内容 12345678910date: 2026-02-21duration: 2.5hgame: 灵迹岛players: - name: Middleman score: result: 胜 - name: Barbarian score: result: 胜12345678910date: 2026-02-21duration: 0.8hgame: 七大奇迹：对决players: - name: Middleman score: 58 result: 胜 - name: Barbarian score: 55 result: 负 2026/01/18 周日 今日桌游: SETI 点击查看详细内容 12345678910date: 2026-01-18duration: 2.5hgame: SETIplayers: - name: Middleman score: 253 result: 负 - name: 灰色小鸡 score: 258 result: 胜 2026/01/17 周六 今日桌游: 拼布艺术：情人节 王权骰铸：第一季 点击查看详细内容 12345678910date: 2026-01-17duration: 1hgame: 拼布艺术：情人节players: - name: Middleman score: 10 result: 胜 - name: 灰色小鸡 score: -10 result: 负12345678910date: 2026-01-17duration: 1hgame: 王权骰铸：第一季players: - name: Middleman score: result: 负 - name: 灰色小鸡 score: result: 胜 2026/01/16 周五 今日桌游: 哈德良长城 点击查看详细内容 1234567date: 2026-01-16duration: 2.5hgame: 哈德良长城players: - name: Middleman score: 46 result: 2026/01/14 周三 今日桌游: SETI 点击查看详细内容 12345678910date: 2026-01-15duration: 5hgame: SETIplayers: - name: Middleman score: 108 result: 负 - name: 灰色小鸡 score: 152 result: 胜 2026/01/11 周日 今日桌游: 恶夜杀机 点击查看详细内容 12345678910date: 2025-01-11duration: 1hgame: 恶夜杀机players: - name: Middleman score: result: 胜 - name: 灰色小鸡 score: result: 负12345678910date: 2025-01-11duration: 1hgame: 恶夜杀机players: - name: Middleman score: result: 胜 - name: 灰色小鸡 score: result: 负 2026/01/10 周六 今日桌游: 恶夜杀机 点击查看详细内容 12345678910date: 2026-01-10duration: 4hgame: 恶夜杀机players: - name: Middleman score: result: 负 - name: 灰色小鸡 score: result: 胜 2026/01/03 周六 今日桌游: 重返黑暗之塔 改造火星 雷霆之路：末路狂飙 黑玫瑰战争：重生 点击查看详细内容 123456789101112date: 2026-01-03duration: 2.5hgame: 重返黑暗之塔players: - name: Middleman result: 负 - name: KUMA result: 负 - name: ZHU result: 负 - name: Q result: 负12345678910111213141516date: 2026-01-03duration: 2hgame: 改造火星players: - name: Middleman score: 58 result: 负 - name: KUMA score: 58 result: 负 - name: ZHU score: 65 result: 胜 - name: Q score: 56 result: 负123456789101112date: 2026-01-03duration: 2hgame: 雷霆之路：末路狂飙players: - name: Middleman result: 负 - name: KUMA result: 负 - name: ZHU result: 负 - name: Q result: 胜12345678910111213141516date: 2026-01-03duration: 3hgame: 黑玫瑰战争：重生players: - name: Middleman score: 16 result: 胜 - name: KUMA score: 3 result: 负 - name: ZHU score: 6 result: 胜 - name: Q score: 4 result: 负 2025/12/27 周六 今日桌游: 复仇女神号：全面封锁 妙想保卫战 暗杀神 点击查看详细内容 12345678910date: 2025-12-27duration: 3hgame: 复仇女神号：全面封锁players: - name: Middleman result: 胜 - name: KUMA result: 胜 - name: ZHU result: 胜 12345678910date: 2025-12-27duration: 3hgame: 妙想保卫战players: - name: Middleman result: 胜 - name: KUMA result: 胜 - name: ZHU result: 胜 12345678date: 2025-12-27duration: 0.5hgame: 暗杀神players: - name: Middleman result: 负 - name: KUMA result: 胜 2025/12/25 周四 今日桌游: 末世亲缘 点击查看详细内容 12345678date: 2025-12-25duration: 4hgame: 末世亲缘players: - name: Middleman result: 胜 - name: 灰色小鸡 result: 胜 2025/12/20 周六 今日桌游: 血缘：诅咒 上古卷轴：第二纪元的背叛者 点击查看详细内容 12345678date: 2025-12-20duration: 2.5hgame: 血缘：诅咒players: - name: Middleman - name: KUMA - name: ZHU123456789date: 2025-12-20duration: 8hgame: 上古卷轴：第二纪元的背叛者players: - name: Middleman - name: KUMA - name: ZHU - name: LIU 2025/12/07 周日 今日桌游: 方舟动物园 点击查看详细内容 12345678910date: 2025-12-07duration: 4hgame: 方舟动物园players: - name: Middleman score: 119 result: &quot;&quot; - name: 灰色小鸡 score: 131 result: 胜 2025/12/04 周四 今日桌游: 冷战热斗 点击查看详细内容 12345678910date: 2025-12-04duration: 1.5hgame: 冷战热斗players: - name: Middleman score: &quot;&quot; result: - name: 想飞的鱼 score: &quot;&quot; result: 胜 2025/11/23 周六 今日桌游: 炸弹克星 点击查看详细内容 12345678910111213141516date: 2025-11-23duration: 5hgame: 炸弹克星players: - name: Middleman score: &quot;&quot; result: &quot;&quot; - name: 灰色小鸡 score: &quot;&quot; result: &quot;&quot; - name: Black.M score: &quot;&quot; result: &quot;&quot; - name: Neivalando score: &quot;&quot; result: &quot;&quot; 2025/11/15 周六 今日桌游: 并购 暗藏杀机 点击查看详细内容 12345678910date: 2025-11-15duration: 2hgame: 并购players: - name: Middleman score: 59200 result: 胜 - name: Neivalando score: 46800 result: 负12345678910date: 2025-11-15duration: 2hgame: 暗藏杀机players: - name: Middleman score: &quot;&quot; result: 负 - name: Neivalando score: &quot;&quot; result: 胜 2025/11/10 周一 今日桌游: 方舟动物园 心灵特工 点击查看详细内容 12345678910date: 2025-11-10duration: 2hgame: 方舟动物园players: - name: Middleman score: 113 result: - name: 灰色小鸡 score: 128 result: 胜12345678910date: 2025-11-10duration: 1hgame: 心灵特工players: - name: Middleman score: &quot;&quot; result: - name: 灰色小鸡 score: &quot;&quot; result: 胜12345678910date: 2025-11-10duration: 1hgame: 心灵特工players: - name: Middleman score: &quot;&quot; result: 胜 - name: 灰色小鸡 score: &quot;&quot; result: 方舟动物园 2025/11/04 周二 今日桌游: 方舟动物园 点击查看详细内容 12345678910date: 2025-11-04duration: 4hgame: 方舟动物园players: - name: Middleman score: 120 result: - name: 灰色小鸡 score: 126 result: 胜 2025/11/01 周六 今日桌游: 阿瑞迪亚 今天第一次去大佬家玩桌游，玩了阿瑞迪亚,一款类似于dnd的美式角色扮演游戏。 我玩的是奥术之路,也就是法师。可能是博德3选了盖尔之后有了一些执念 前期的话，众所周知，法师基本属于废物。所以基本都在用普攻去戳人笑。玩的时候走错路跳关了，于是前两波架打的是非常痛苦，差点团灭。后面走回去升级技能的时候才发现前面有好几波比较基础的战斗😂。 一共玩了六七个小时，也没玩特别多的内容，听说游戏本体时长大概是100h+。我觉得就游戏而言，比方说阿瑞迪亚（这个是盗版）售价在450左右，能提供三四个人一两百小时的乐趣。这么来看的话一人一小时一元，在爱好中是非常便宜的了笑。精神胜利法 期待下次去大佬那继续阿瑞。 阿瑞迪亚，这个地图应该是基普维克教区，在探索田野 在基普维克城里大战软泥怪 12345678date: 2025-11-02duration: 7hgame: 阿瑞迪亚players: - name: Middleman - name: KUMA - name: ZHU","content":"<div class=\"note info\"><p>记录每一次桌游🎲</p></div>\n\n<span id=\"more\"></span>\n<h4 id=\"20260222\" style=\"text-align:center; font-weight:bold;\">2026/02/22 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>阿瑞迪亚</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-02-22</span><br><span class=\"line\">duration: 4h</span><br><span class=\"line\">game: 阿瑞迪亚</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: Barbarian</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20260221\" style=\"text-align:center; font-weight:bold;\">2026/02/21 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>灵迹岛</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>七大奇迹对决</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-02-21</span><br><span class=\"line\">duration: 2.5h</span><br><span class=\"line\">game: 灵迹岛</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: Barbarian</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-02-21</span><br><span class=\"line\">duration: 0.8h</span><br><span class=\"line\">game: 七大奇迹：对决</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 58</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: Barbarian</span><br><span class=\"line\">    score: 55</span><br><span class=\"line\">    result: 负</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20260118\" style=\"text-align:center; font-weight:bold;\">2026/01/18 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>SETI</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-18</span><br><span class=\"line\">duration: 2.5h</span><br><span class=\"line\">game: SETI</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 253</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: 258</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20260117\" style=\"text-align:center; font-weight:bold;\">2026/01/17 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>拼布艺术：情人节</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>王权骰铸：第一季</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-17</span><br><span class=\"line\">duration: 1h</span><br><span class=\"line\">game: 拼布艺术：情人节</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 10</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: -10</span><br><span class=\"line\">    result: 负</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-17</span><br><span class=\"line\">duration: 1h</span><br><span class=\"line\">game: 王权骰铸：第一季</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n<h4 id=\"20260116\" style=\"text-align:center; font-weight:bold;\">2026/01/16 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>哈德良长城</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-16</span><br><span class=\"line\">duration: 2.5h</span><br><span class=\"line\">game: 哈德良长城</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 46</span><br><span class=\"line\">    result: </span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n<h4 id=\"20260114\" style=\"text-align:center; font-weight:bold;\">2026/01/14 周三</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>SETI</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-15</span><br><span class=\"line\">duration: 5h</span><br><span class=\"line\">game: SETI</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 108</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: 152</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>  \n\n<h4 id=\"20260111\" style=\"text-align:center; font-weight:bold;\">2026/01/11 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>恶夜杀机</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-01-11</span><br><span class=\"line\">duration: 1h</span><br><span class=\"line\">game: 恶夜杀机</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 负</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-01-11</span><br><span class=\"line\">duration: 1h</span><br><span class=\"line\">game: 恶夜杀机</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 负</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n<h4 id=\"20260110\" style=\"text-align:center; font-weight:bold;\">2026/01/10 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>恶夜杀机</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-10</span><br><span class=\"line\">duration: 4h</span><br><span class=\"line\">game: 恶夜杀机</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: </span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n<h4 id=\"20260103\" style=\"text-align:center; font-weight:bold;\">2026/01/03 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>重返黑暗之塔</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>改造火星</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>雷霆之路：末路狂飙</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>黑玫瑰战争：重生</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-03</span><br><span class=\"line\">duration: 2.5h</span><br><span class=\"line\">game: 重返黑暗之塔</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: Q</span><br><span class=\"line\">    result: 负</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-03</span><br><span class=\"line\">duration: 2h</span><br><span class=\"line\">game: 改造火星</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 58</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">    score: 58</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\">    score: 65</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: Q</span><br><span class=\"line\">    score: 56</span><br><span class=\"line\">    result: 负</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-03</span><br><span class=\"line\">duration: 2h</span><br><span class=\"line\">game: 雷霆之路：末路狂飙</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: Q</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2026-01-03</span><br><span class=\"line\">duration: 3h</span><br><span class=\"line\">game: 黑玫瑰战争：重生</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 16</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">    score: 3</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\">    score: 6</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: Q</span><br><span class=\"line\">    score: 4</span><br><span class=\"line\">    result: 负</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20251227\" style=\"text-align:center; font-weight:bold;\">2025/12/27 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>复仇女神号：全面封锁</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>妙想保卫战</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>暗杀神</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-12-27</span><br><span class=\"line\">duration: 3h</span><br><span class=\"line\">game: 复仇女神号：全面封锁</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\">    result: 胜  </span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-12-27</span><br><span class=\"line\">duration: 3h</span><br><span class=\"line\">game: 妙想保卫战</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\">    result: 胜  </span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-12-27</span><br><span class=\"line\">duration: 0.5h</span><br><span class=\"line\">game: 暗杀神</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n<h4 id=\"20251225\" style=\"text-align:center; font-weight:bold;\">2025/12/25 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>末世亲缘</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-12-25</span><br><span class=\"line\">duration: 4h</span><br><span class=\"line\">game: 末世亲缘</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n<h4 id=\"20251220\" style=\"text-align:center; font-weight:bold;\">2025/12/20 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>血缘：诅咒</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>上古卷轴：第二纪元的背叛者</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-12-20</span><br><span class=\"line\">duration: 2.5h</span><br><span class=\"line\">game: 血缘：诅咒</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-12-20</span><br><span class=\"line\">duration: 8h</span><br><span class=\"line\">game: 上古卷轴：第二纪元的背叛者</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\">  - name: LIU</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20251207\" style=\"text-align:center; font-weight:bold;\">2025/12/07 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>方舟动物园</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-12-07</span><br><span class=\"line\">duration: 4h</span><br><span class=\"line\">game: 方舟动物园</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 119</span><br><span class=\"line\">    result: &quot;&quot;</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: 131</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20251204\" style=\"text-align:center; font-weight:bold;\">2025/12/04 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>冷战热斗</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-12-04</span><br><span class=\"line\">duration: 1.5h</span><br><span class=\"line\">game: 冷战热斗</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: </span><br><span class=\"line\">  - name: 想飞的鱼</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20251123\" style=\"text-align:center; font-weight:bold;\">2025/11/23 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>炸弹克星</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-11-23</span><br><span class=\"line\">duration: 5h</span><br><span class=\"line\">game: 炸弹克星</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: &quot;&quot;</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: &quot;&quot;</span><br><span class=\"line\">  - name: Black.M</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: &quot;&quot;</span><br><span class=\"line\">  - name: Neivalando</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: &quot;&quot;</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20251115\" style=\"text-align:center; font-weight:bold;\">2025/11/15 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>并购</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>暗藏杀机</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-11-15</span><br><span class=\"line\">duration: 2h</span><br><span class=\"line\">game: 并购</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 59200</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: Neivalando</span><br><span class=\"line\">    score: 46800</span><br><span class=\"line\">    result: 负</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-11-15</span><br><span class=\"line\">duration: 2h</span><br><span class=\"line\">game: 暗藏杀机</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: 负</span><br><span class=\"line\">  - name: Neivalando</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20251110\" style=\"text-align:center; font-weight:bold;\">2025/11/10 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>方舟动物园</strong></p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>心灵特工</strong></p>\n            </div>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-11-10</span><br><span class=\"line\">duration: 2h</span><br><span class=\"line\">game: 方舟动物园</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 113</span><br><span class=\"line\">    result: </span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: 128</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-11-10</span><br><span class=\"line\">duration: 1h</span><br><span class=\"line\">game: 心灵特工</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result:</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-11-10</span><br><span class=\"line\">duration: 1h</span><br><span class=\"line\">game: 心灵特工</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: 胜</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: &quot;&quot;</span><br><span class=\"line\">    result: </span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<div align=\"center\">\n  <img src=\"/images/daily/boardgame/record/20251110.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/boardgame/record/20251110.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"桌游照片\" width=\"70%\">\n  <p style=\"text-align:center;\">方舟动物园</p >\n</div>\n\n<h4 id=\"20251104\" style=\"text-align:center; font-weight:bold;\">2025/11/04 周二</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n<u>今日桌游:</u><br>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>方舟动物园</strong></p>\n            </div><br>\n\n<details green><summary> 点击查看详细内容 </summary>\n              <div class='content'>\n              <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-11-04</span><br><span class=\"line\">duration: 4h</span><br><span class=\"line\">game: 方舟动物园</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">    score: 120</span><br><span class=\"line\">    result:</span><br><span class=\"line\">  - name: 灰色小鸡</span><br><span class=\"line\">    score: 126</span><br><span class=\"line\">    result: 胜</span><br></pre></td></tr></table></figure>\n              </div>\n            </details>\n\n<h4 id=\"20251101\" style=\"text-align:center; font-weight:bold;\">2025/11/01 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<u>今日桌游:</u>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p><strong>阿瑞迪亚</strong></p>\n            </div>\n<p>今天第一次去大佬家玩桌游，玩了阿瑞迪亚,一款类似于dnd的美式角色扮演游戏。</p>\n<p>我玩的是奥术之路,也就是法师。<psw>可能是博德3选了盖尔之后有了一些执念</psw></p>\n<p>前期的话，众所周知，法师基本属于废物。所以基本都在用普攻去戳人笑。玩的时候走错路跳关了，于是前两波架打的是非常痛苦，差点团灭。后面走回去升级技能的时候才发现前面有好几波比较基础的战斗😂。</p>\n<p>一共玩了六七个小时，也没玩特别多的内容，听说游戏本体时长大概是100h+。我觉得就游戏而言，比方说阿瑞迪亚（这个是盗版）售价在450左右，能提供三四个人一两百小时的乐趣。这么来看的话一人一小时一元，在爱好中是非常便宜的了笑。<del>精神胜利法</del></p>\n<p>期待下次去大佬那继续阿瑞。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/boardgame/record/110101.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/boardgame/record/110101.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"桌游\" width=\"70%\">\n  <p style=\"text-align:center;\">阿瑞迪亚，这个地图应该是基普维克教区，在探索田野</p>\n</div>\n<div align=\"center\">\n  <img src=\"/images/daily/boardgame/record/110102.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/boardgame/record/110102.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"桌游\" width=\"70%\">\n  <p style=\"text-align:center;\">在基普维克城里大战软泥怪</p>\n</div>\n\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">date: 2025-11-02</span><br><span class=\"line\">duration: 7h</span><br><span class=\"line\">game: 阿瑞迪亚</span><br><span class=\"line\">players:</span><br><span class=\"line\">  - name: Middleman</span><br><span class=\"line\">  - name: KUMA</span><br><span class=\"line\">  - name: ZHU</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>","categories":[{"name":"daily","slug":"daily","permalink":"https://middlemanz.com/categories/daily/"},{"name":"桌游","slug":"daily/boardgame","permalink":"https://middlemanz.com/categories/daily/boardgame/"}],"tags":[{"name":"桌游","slug":"桌游","permalink":"https://middlemanz.com/tags/%E6%A1%8C%E6%B8%B8/"},{"name":"日常","slug":"日常","permalink":"https://middlemanz.com/tags/%E6%97%A5%E5%B8%B8/"}]},{"title":"每日记录","date":"2025-10-15T08:45:30.000Z","path":"categories/daily/每日/每日记录/","permalink":"https://middlemanz.com/categories/daily/%E6%AF%8F%E6%97%A5/%E6%AF%8F%E6%97%A5%E8%AE%B0%E5%BD%95/","text":"这里记录我的每一天🎭，如果每天都能想起来的话。 记录的内容为流水账📰与心流📖的不可观测态————如果你想观察的话，那他就是流水账，反之亦然。 2026年01月 2026/01/30 周五 又是一个周五写总结的环节。 这一周总体还是很忙的，修正毕业论文的摘要、提出；修正毕业论文本身，等等等。 在这周里忙里抽闲还处理了一下搬家的各种事项： 办理网络的“搬家” 办理停煤气和停电 计划退室立会 找搬家公司: 第一家是79200，来見積もり的日本人横的像我是客户一样。 第二家是80000，挺客气但是有点超出预算了。 第三家是68860，包括了所有东西（捆包材免费，所有家具，床和桌子拆装）。个人觉得非常nice,直接就决定他家了。也是懒得来回比较了，所以直接选一个相对便宜的就完事了。 新家的水电煤气办理（还未定） 论文相关部分见：今日学术记录 今天组会的时候（写这篇的5分前）提到了下次小组组会的日程，估计我是参加不太上了，老师对这个也是比较宽容：“明年开始不在研究室的同学，就自己看着参加吧。” 很好 2026/01/24 周六 又是两周没记录了，这两周不是很忙，但需要做的事还是很满的。写了一篇英文论文的摘要，准备了发表，进行了发表，写了毕业论文的摘要，稍微整理的毕业论文1-3章的内容。详细的还是见今日学术记录 除了研究的话，1&#x2F;18去了大阪进行博物馆访问，参观了绢谷幸二 天空美术馆和大阪暮らしの今昔館(大阪生活变迁馆)。参观博物馆需要给财团写感想文，在这里一并贴出来： “今年，我参观了大阪生活今昔馆和绢谷幸二天空美术馆。在大阪生活今昔馆中，最令我印象深刻的是那些制作精细的模型。通过这些模型，我能够以直观、具体的方式理解大约一百年前大阪的生活状况和城市风貌。 另一方面，我在三年前也曾参观过绢谷幸二天空美术馆。当时，除了绢谷幸二先生色彩鲜明、多姿多彩的经历之外，他在高龄之际仍持续积极投身于艺术创作与艺术教育的姿态，也让我感到由衷的惊讶与感动。 今年的展览内容本身与三年前相比几乎没有变化，但在入馆前发放的一份宣传册却给我留下了深刻印象。宣传册中汇总了绢谷先生的生平经历，其内容是一篇追悼文。得知三年前仍为实现自身梦想而精力充沛地持续活动的绢谷先生，已经辞世，我感到极大的震撼。 人生是短暂的。然而，如果能够像绢谷先生那样，将一生投入到自己真正热爱的事物之中，即使人生并不漫长，也依然能够具有深刻而重要的意义。” 写的日语的然后用chatgpt翻译过来的，AI味有点重 20号那天让一个搬家公司来进行了見積もり（就是上门报价），在几乎装了我所有家具的情况下，从京都到东京是79200。感觉还是可以的，但是没有直接同意，准备再比一比价格再去判断。 21号那天的晚上本来预报说要下大雪，学校的通勤车都因此停运了（害我自己倒车回家）。但是从第二天白天的景象来看，好像完全没下雪一样。等于说校车白白休息了lol。 2025/01/07 周三 2025&#x2F;12&#x2F;27-2026&#x2F;01&#x2F;04是日本的新年假期，这段时间没学习，一直玩来着。 12&#x2F;27和01&#x2F;03都去了KUMA家玩桌游，玩了什么的话见桌游记录，在生活&gt;桌游里。 12&#x2F;27的晚上去和日本朋友吃饭，一共五个人，吃了火凤源的火锅。当初他们提出要去吃火锅的时候我还挺惊讶，因为在我的印象中日本人不吃火锅这种共用餐具的东西。不过显然我的这种担心是多余的，他们是一点没见外，吃的比我都多。 01&#x2F;02去了初詣（はつもうで｜hatsumoude）。日本的习俗里，每年的大年初一开始一直到正月十五（阳历）都可以去参拜，我们去了北野天满宫（是京都最大的天满宫）。我觉得这个参拜和国内的新年去逛土地庙财神庙的感觉差不多。大家对着神许下愿望，希望接下来的一年里身体健康，学业有成，事业圆满等等。进入天满宫之前有很长的小路，两端都是商贩，卖年糕、猪肉串、糖果、玩具之类的小玩意。 日本在这一点和国内区别很大，国内的话商贩往往是在平常的时候出现，比如早夜市，路边摊等等。而日本的话平时是找不到路边摊的，只有在节日，庙会这些时候才会出现。他们比较像在“肝活动”：没有固定的出摊位置，而是随着活动地点的变化而出现。他们每次都会去报名各个活动的摊位，所以每次的活动里出现的摊位就那么几个（因为都是一拨人）。今日学术记录 2025年12月 2025/12/26 周五 又是在小组组会的间隙时抽空写博客的一天。 ··· 好巧不巧，虽然刚发表完最终报告以及和老师讨论完接下来要做的事情，但是这周恰巧也是我们小组的组会。于是就导致了一个比较尴尬的场面，能讨论的都讨论完了，只能尬聊。而日本人还比较不变通，也不改变时间，大家就尬聊（当然也有可能是如果改了我们这周的日程就以后的都得改，牵一发而动全身了）。 周三的反馈总体也还行。目前为止的研究内容已经可以作为毕业论文发表了。但是如果想真正的解决老师想看的问题还不太够，得构思几个新的指标然后看看结果。详细的还是见研究记录。对于我是挺好的，毕竟意味着我如果想要有事情干也能有，想摆烂也ok哈哈。没什么压力的时候就发现做研究还是挺有意思的。貌似什么都是这样吧，就算是爱好，当他变成工作的时候也会有压力。不过如果没有压力的话，因为没有对比，爱好也就没什么意思了。两者就是一个巨大的围城：没有压力只玩的时候会觉得空虚，找点事情做；而正事很多、压力很大的时候就会一直期盼着能玩一玩，享受属于自己的一隅。今日学术记录··· 周四是圣诞节，收到了女朋友送我的想要已久的《战锤试涂包》！！！。周五和女朋友试着涂了一下，不愧之前学过很多类型的美术，她真的是比我在这方面更有天赋，在上色和控笔上都更稳一些。 第一次涂得战锤，以后也是锤佬了哈哈哈 涂装还是很有趣的，对于我也是很重要的。因为我发现在涂装的时候我找到了久违的那种专注感。这种感觉自从我小时候拼乐高的时候就很少出现了。玩游戏很难让我找到这种感觉因为负罪感很重，而涂装就刚刚好。涂装的时候，精神集中在面前的阿斯塔特上，而可以把耳朵空出来来听视频，评书之类的。控笔的紧张感和听视频的放松感两者相辅相成，很适合放空大脑。 另一面 ··· 圣诞节和女朋友买了吮指原味鸡以及订了巧克力蛋糕吃。略有遗憾的就是今年年末年初因为两个人都很忙就没能出去玩上，不过我相信毕业旅行会弥补的。晚上一边吃蛋糕，一边看CBA辽宁打浙江来着，谁赢了不知道，看到一半就看不下去了。辽宁这球传的真是离谱。 2025/12/24 周三 昨天的发表整体上没什么问题，但是老师给我的反馈，或者说疑问让我很头疼。简单来说就是在给我题目的时候，说这个研究的目的是A。我按照A做好了结果和分析，发表之后，老师说我们的目的其实是A+++（本质上是A但是复杂多的多得多）你这个结果不能证明我们想要的结论。 发表结束后是一个 Chistmas lunchparty 有寿司和肯德基的吮指原味鸡和冰淇淋。很好吃。其实我觉得我们研究室这种中型的小party还挺多，每次都能吃到不一样的食物。这一点还是很棒的。 lunchparty结束后就四点了，本来晚上6点有忘年会，但是学长看大家的都吃的很饱了，就把时间调成了七点。忘年会在PISOLA，一个西餐（披萨，意面，烩饭，冷盘）的自助餐厅。3400日元一个人，食物很好吃但是大家都没什么肚子了，于是唠嗑闲谈偏多。 今天的全体组会之后老师会一对一的给出研究上的反馈和接下来一个月的建议。希望不要给我改动太多。 2025/12/23 周二 时隔一个月，终于有时间来更新博客了。上次更新是11.27，这一个月可真的是忙到脚打后脑勺。主要干了两件大事：12.3-6去东京找房子；12.8-23准备研究室的最终报告和发表。一件一件说 12.3-6东京： 因为明年要去东京读研，所以要提前把房子给找好，不然到时候一是没有房子，二是有的话条件会很差且贵（因为好的被别人挑完了）。正好这一周研究室没有zemi，于是打好提前量，出发去了东京。到了东京之后先在东大附近转了转，发现一般的中介公司都没有开门。 漫步东大周围，左看看右看看，好似刘姥姥进大观园。正是银杏落叶的季节，满大街都是金黄的叶和散发着气味的银杏果，这两者结合就产生了一幅很有趣的画面：游人三三两两聚在一起，一边为让自己与银杏的金黄融为一体去寻找最合适的角度拍照，一边为了避免踩到银杏果而蹦蹦跳跳。东京大学的校徽就是两片银杏叶，校园里也种满了银杏。黄灿灿的叶子尽职尽责，一丝不苟的覆盖着大地，直到让他失去了原本的颜色才肯罢休。 走着走着终于发现了一家中介开着门，便走了进去。这是一家非常日式，且有年代的店了，看起来不像是连锁的。进门后说明来意，一位爷爷接待了我，并奉上热茶。他解释说周三一般是不动产业的休息日，因为中介公司都要向不动产业来确认各种事项，所以也在这一天一并休息了。给我介绍了两个房子之后，都因为不太和我的胃口，所以也就不了了之了。 晚上去吃了心心念念的烤鸭。还是东京的食物总类比较丰富，想吃到什么都能吃到啊。 周四去了中介公司，简单看过推荐的物件之后便直奔之前在网上看好的 house。因为房子里的住户还没有退房，所以仅仅在外面看了一下日照和周围环境便告一段落。这个房子无论在大小还是价格还是位置都非常令我满意，唯一的缺点可能是向东，采光一般。上一个住户在这里住了十年，所以我坚持在进入看看房子的内部状态之后再签约。计划的是一月份拜托朋友去看一下内部状态，然后决定签约与否。 因为周四提前完成了找房子的任务，周五就变为了单纯的逛逛东京。先后去了几个地方：原宿的怪奇物语快闪店；新宿的骏河屋；新宿的黄色潜水艇；最后在高马吃了两顿饭。原宿的怪奇物语店比较小，一楼右手边是买东西的地方（可能因为我去的比较晚性价比高的东西都没了，只剩衣服拖鞋之类的），左手边模拟了拜尔斯家的经典沙发后面彩灯1-17数字的场景，旁边的小桌子上还有dnd的模型。二楼是卖冲浪小子披萨和咖啡茶冰淇淋的地方。人多还比较狭窄所以十分拥挤。 周六去参加财团活动然后回京都，晚上去看了《疯狂动物城2》剧情很简单，但是不愧是迪士尼大IP，总能让人找到最原始，最纯粹的幸福感。 12.8-23 最终报告的执笔；最终发表的准备 接下来是痛苦的半个月，无休无尽的写程序、debug、写论文、改论文、做ppt、改ppt是这半个月的最真实的写照了。好在写完了，23号也就是今天，最终发表，现在我正在等待自己的发表，终于空下来时间不用研究，遂回忆一下这半个也然后写一下记录。 研究内容相关的话见研究记录。最后截止第一次最终报告交稿（还不是毕业论文），算参考文献我的论文已经写到50页，20000字了。真是个大工程。 现在在等待我的发表，我已经能想象到发表完得被不少说，因为我仅仅来得及把结果都列出来，从结果能得到一个初步结论，但是尚未有时间来写是什么原因导致了这个结果等等。随遇而安吧。 12.20 忙里抽闲，去了大佬家玩桌游 人，总是要稍微休息一下的。经历了两周高压的研究之后，下定决心放松一下，周六便去玩桌游了。详细的还是放在桌游记录里 2025年11月 2025/11/27 周四 周二周三都在研究室度过。周三完成了发表，周四终于能休息一下了。没有太多要说的 见今日学术记录 2025/11/22 周六 今天终于又组起来了桌游局，开了炸弹克星。 炸弹克星应该是我们几个一直在一起玩的朋友一致觉得的本年度最佳游戏了（真的真的很好玩）详细测评见炸弹克星短评 2025/11/21 周五 周一到周五手忙脚乱，没有闲暇时间顾及博客。直到今天的组会听别人发表的时候才有机会小小更新一下。今日学术记录周二周三都是研究室度过完整一天。周四去了财团的hirose展。今天开组会。 晚上都在准备组会和下周的发表的材料。 展馆外 说一下hirose展吧： hirose技術展，是我的财团——ヒロセ財団法人的母公司 ヒロセ電機 所创办的展示公司技术的展会。 展会每三年一次，届时邀请各个使用了hirose技术的公司，以及借出他们的产品来进行展示。这里需要说明一下：因为hirose本身的产品主要为***连接器(connector)***所以需要依靠各个下流公司的产品来进行说明。 ChatGPT：连接器（connector） 连接器（connector）是一种使两个电子部件能够电性连接并传输信号或电力的元件。它的作用就像“桥梁”，让电路板、线缆或设备之间能够方便、稳定地接合与分离。常见于手机接口、电脑主板插槽、汽车电子等，是所有电子设备中不可或缺的基础部件。 展会里有很多hirose电机的产品的应用：耳机，手机，医疗机器人，电脑，电动车等等等。学环境的着实是看不懂 2025/11/17 周一 上周因为研究室的学长学姐去了巴西开IAMC年会【Integrated Assessment Modeling Consortium（综合评估模型协会）】，所以研究室取消了zemi，喜提一周假期😋。 一周里倒是明确和学习了不少关于ML的东西。 其中最重要的是明确了以后想干什么——查了一些资料，看了看学长学姐的经验贴，想了想自己到底想干什么。 看了很多，最后觉得自己还是喜欢编程，想干IT相关。但是因为非科班，所以还不能干非常纯粹的IT。遂觉得咨询行业的IT岗（MLE, Machine learning engineer）是不错的选择。（如果能进四大+A社就最好了） 确定下来自己的想干什么之后，就开始着手学习。因为学部学的内容完全不同，所以很多科班出身的同学习以为常的事情需要从头学起。以下是上周学习了的内容。 （特别提一句，这个docker部署耽误了我起码两天的时间。因为docker拉镜像和部署ubuntu之类的东西非常占内存而我的笔记本c盘还爆满，所以删缓存和尝试软链接废了不少功夫。最后也是成功的放弃了 看了看成为MLE需要掌握的内容 MLE面试的主要流程 下载了相关资料（ebook,学习路线） DOCKER是什么，有什么用和试部署 看完了《深度学习入门：基于Python的理论与实现 (斋藤康毅)》 统计学习的基础(B站简博士，正在看) 准备写一个MLE面试的准备随笔。 不过俗话说得好：“如果你平时一直在很悠闲的洗脚，那么期末的时候就是你把洗了一学期的洗脚水喝掉的时候。”这周开始就得给前些日子买单了，周五个别zemi；下周三大zemi全都要准备。 今天一天在研究室 详见今日学术记录 2025/11/16 周日 今天终于把大名鼎鼎的鱼书，也就是《深度学习入门：基于Python的理论与实现 (斋藤康毅)》给看完了，之前看到MNIST的地方发现完全看不懂，所以索性自学了一遍MNIST的pytorch和scratch版文章点此跳转。今天看的时候才发现原来后面整篇都在讲MNIST😅。不过话说回来，这本书对于初学者还是很有帮助的，无论是在讲误差反向传播法还是后面的超参数优化，感觉学到了蛮多东西。推荐一下。 鱼书 2025/11/15 周六 今天新开了《并购》和《暗藏杀机》都是两人局。 《并购》给我的感觉是机制很简单（好像是1963年的桌游），但是计算量很大。两个人玩的话博弈点比较少，可能多人局会好一些。 《暗藏杀机》是比较机制基础的推理类桌游本质上是排除法练习器笑。我相对来说喜欢这个一些。 玩了一局后感觉凶手比较好赢？可能是我比较菜。 2025/11/10 周一 今天去研究室。一天都在跑模型，见链接。晚上完了方舟动物园，又输了555😭。 今日学术记录 2025/11/09 周日 今天在家一天。整理了博客的一些内容，创建了一个github库准备作为自己作品集来展示。与其说是作品不如说是破烂我发现当我开始整理这些东西的时候就有无穷的精力和兴趣。人还是得做一些自己感兴趣的事情。 吃饭之余看了《惊天魔盗团2》从芯片公司出来那段其实从各种剪辑中已经看过无数次了。不过第一次完整的看完的时候还是感觉很震撼。这才叫魔术！ 2025/11/08 周六 今天去四条吃了烤肉和配了新眼镜。至此陪伴我三年的眼镜就告一段落了。三年来左眼涨了50，右眼涨了25。（我感觉我平时因为学习和研究用电脑的时间还是很长的，只变化了这么少感觉还可以） 烤肉真香，给あぶりや打广告 2025/11/07 周五 今天看了《惊天魔盗团》。 惊天魔盗团 豆瓣https://movie.douban.com/subject/6517421/ 这电影也是在各种电影剪辑中出现的常客了笑，今天也终于一睹芳容。电影很好看，不论是魔术本身还是剧情，都很吸引人。 最后有一点没太看懂： 警探召集四个魔术师是为了报复保险公司和黑人老头。报复保险公司可以理解，因为保险公司直接导致了他父亲的死亡。但报复老头这一点我没太看懂，究其原因，本质上他父亲还是因为着急证明自己才失败的，和老头并没有直接关系。所以就动机而言没太明白。 2025/11/06 周四 今天终于通关了银河破裂者的战役模式。下一步就是生存了，感觉这个游戏还有可以发掘的潜力。 2025/11/05 周三 今天去了研究室，无话。今日学术记录 2025/11/04 周二 今天试着开了《方舟动物园ark nova》。整体玩下来感觉如下： 游戏入门不难，精通很难 机制很多很杂糅但是融合的很好 风味很足，卡面上的原画照片很写实出彩 打出一串combo之后很爽 买的是鹿王的diy，不知道是什么原因灰很大，玩完了直接粉尘过敏 2025/11/03 周一 今天集运的桌游到货了!又能玩很长时间了😁新桌游收藏+： 方舟动物园 灵迹岛+扩 权力的游戏版图版+扩 SETI 暗藏杀机 并购 在煤炉上购入了+: 惨剧轮回 2025/11/02 周日 今天女朋友给我烙一直想吃的牛肉馅饼了！🥙 好吃！！完美符合心里的味道。 我也做了小白菜土豆汤🥬和西红柿牛腩。🐂 两个人一起照着星露谷物语的食谱书做了爆炒青椒🌶(芝士青椒) 星露谷的爆炒青椒 挺像的 图片详见foods页面。 2025/11/01 周六 今天终于有机会去大佬家里一睹大佬的收藏了。 最开始是在小红书上刷到了大佬的帖子，当时就被大佬的丰富的桌游收藏和舒适的配套设备给震惊到了。正好大佬也在找人一起玩，遂联系了大佬。 无奈他工作比较忙，一直等到了这个三连休才有了一些空闲时间。于是终于如愿以偿去拜访大佬了。 —————— 一进门，映入眼帘的是一个桌游专用桌子（似乎是满座家的）。围绕着桌椅有四个架子和数不清的柜子。左边先是一个小矮柜，放着一些毛线（作弊飞蛾、血蔷薇什么的），柜子的右边紧挨着一个挤满了中号盒子的德式+小美式的架子。大佬的收藏真的是包罗万象，就中号盒子大小的桌游来说，不存在我认识但是没看到的情况。新出至ARCS，经典如MANILA，无奇不有。 大佬的家 在右边是一个大美的战区，从上往下，诡镇惊魂、血源诅咒、德鲁纳格编年史等等琳琅满目，模型收纳在对应的盒子里，可以直接抽出来欣赏。 大美架子 拐角的右面也是一个大美的架子，右面还是一个大美的架子（貌似大佬家里全是大美笑）。简单列一下大佬的收藏的话：大老鼠、COC、PRIMAL、Return to the darktower、阿瑞迪亚、霜港迷城 ...... 大美架子2 大美架子n 除了传统的桌游，当然还少不了各式模型。我对模型的了解不多，仅仅能从茫茫模型海中识别出来一部分：战锤的极限战士，COC的经典模型等等。 战锤的模型 未知模型不过很酷 ::从现在开始，我的人生目标变更为能拥有这样的收藏笑 题外话:我觉得拥有一个桌游专用的大桌子对于提升幸福感是非常重要的。无论是从便利方面还是从‘专用’方面都能很高的提升玩桌游的体验。争取到了东京之后搞一个大桌子。 今天在大佬家玩了《阿瑞迪亚》,详见: 今日桌游记录 2025年10月 2025/10/30 周四 今天是研究室运动大会。因为周四一般不去研究室，早上生物钟没调过来，没起来去坐往常那班校车，只能坐下一班。不过好歹也是赶上了。 着重说一下今天的研究室的スポーツ大会： スポーツ大会スケジュール（体育大会安排） 12:15-13:00 サッカー(10分×2セット) 13:00-13:30 バドミントン(ダブルス3面×3) 13:40-14:10 バスケットボール(10分×2セット) 14:20-14:50 バレー(30点先取・デュースあり) Sports Tournament Schedule 12:15-1:00 PM Soccer (2 sets of 10 minutes) 1:00-1:30 PM Badminton (3 courts of doubles) 1:40-2:10 PM Basketball (2 sets of 10 minutes) 2:20-2:50 PM Volleyball (First to 30 points, with deuce) 日本人这个体能是真的强，从12:15到15:00点全是高强度有氧，可谓是铁人四项了。 我没参加足球（因为一窍不通），但是参加了其他三项。篮球和羽毛球虽然说之前都学过，但是已经荒废很久了，也就是一个略懂规则的水平。排球从初一打到高三，比前两者能强不少。和研究室同学们打绰绰有余，但是去专业的社团就只有被吊打的份了。 之前健身一直都是健无氧，基本不做有氧，今天三个小时的有氧坐下来感觉整个人已经离世界有一段距离了🤣今日学术记录 2025/10/28 周二 和tutee吃饭，学习，更新blog，打游戏。 本来今天要去复查眼睛的，正好因为镜框掉漆想重新配一个，一起安排到下周二了就不用去两次了。 2025/10/27 周一 又是weekly report去了研究室。 因为上周一直在摸鱼，研究根本没有什么进展，所以在去学校的路上还想了好一阵子能报告点什么。最后还是使用模糊的语言糊弄过去了。 所谓模糊的语言，也是向研究室的前辈们学的，无非就是： 进行了文献调查 对模型进行了debug 整理了代码 这种，似是而非的话术。我看了一个报告，也算进行了文献调查；看了看代码，也叫整理了代码。看上去非常唬人，实际上根本不能细致推敲。 还好老师也不细问大家都干了什么，所以皆大欢喜。 这部分内容在以后把网站发给hr之前可得删掉 今日学术记录 本质上上一周要专门记录的内容比较少，为了避免过于流水账，就只在这一条下面挑重点来写了。 周二因为淘宝双十一活动开始了，激情下单了很多桌游，坐等集运。等集运到了会po周三和周四和朋友联机了银河破裂者 银河破裂者https://store.steampowered.com/app/780310/The_Riftbreaker/?l=schinese。最开始以为是RTS，但玩了半天发现没有造兵元素。与其说是RTS不如说是基地建设+第三人称打怪爽游。不过游戏还是不错的周日学习复现了一下MNIST手写数字识别的机器学习项目。 2025/10/20 周一 今天weekly report 去了研究室。 今日学术记录 有一个很搞笑的好消息。为了继续我的研究，本来有A、B两个活，学长帮我干了A说接下来想然我干B。然后老师发邮件过来让我干A，学长一看就把他做好的A发过去了。老师大喜过望说太好了那你等一会我给你把B整完。合着两个都不需要我做哈哈哈。 2025/10/19 周日 今天去大阪天下茶屋玩了线下血染钟楼。 应该是我第二回正式玩血染，第一回是和老瘸在沈阳的桌游店里玩的。 当时还觉得这个游戏云里雾里，后面才知道这个游戏的乐趣。 在我看来血染的乐趣在于1：参与感；2：不确定性。参与感指每一个人都有技能能干自己的事情，不至于像狼人杀的平民一样束手无策只能靠瞎猜。而不确定性代表这个游戏的逻辑是基本上不会闭环的，意味着大概率出现两个截然相反而又互相不能证伪的逻辑。这就给了游戏以及玩家很大的发挥空间，玩家比起死盘逻辑更需要“证明给别人看自己是对的”。我很喜欢这种，至少他赋予了每一位玩家可操作的空间。 2025/10/18 周六 今天女朋友给我买了最新的苹果手表作为生日礼物！其实很多事情没必要拿来炫耀😅就好像我女朋友2025年10月18日给我买了Apple Watch S11，女朋友给我买了Apple Watch S11这件事没必要天天提，因为我知道2025年10月18日女朋友给买Apple Watch S11的人多的是，天天提2025年10月18日女朋友给我买就显得好像只有我知道我2025年10月18日拥有了Apple Watch S11一样，现在你也知道2025年10月18日我女朋友给买了Apple Watch S11，我女朋友在2025年10月18日给我买了Apple Watch S11就买了呗，就这样吧，反正我女朋友在2025年10月18日给我买了Apple Watch S11。 作为圣诞礼物，给小鸡买了迪奥的圣诞眼影礼盒，她看起来很开心。就很好。 2025/10/17 周五 今天个别zemi，早上九点半开始。 每次个别zemi就需要我去做一个抉择： 7:30出发，换乘2次bus,9:06到——这个选择就是早起+公交站票+提前到。 8:30出发，做学校bus,不换乘，9：25-35到——这个是睡觉+舒服+有可能迟到。 那聪明的人已经猜到我会选什么了，只是正常人类都会选的😁 不过今天迟到了五分钟。意外的是个别zemi的发表很顺利。老板好像挺满意我的进展。这就好。 今日学术记录 2025/10/16 周四 今天还是研究室，研究又出现了进展，令人欣喜。 研究就像是淘金和掏粪的合体。你永远不知道下一秒是暴富还是给你拉个大的。 一直做个别zemi的资料做到十二点，无话。 今日学术记录 2025/10/15 周三 今天全体组会，加上周五有个别组会，无论如何都得去研究室了。 上周因为财团旅游而小小逃课了一下，很爽，但是终究今天和明天还得给逃的课买单。不做研究没成果的话，组会就得挨说。 幸好今天研究终于取得了一些进展。不过因为模型还没跑完，能不能成功还是未知。 已经四个小时了，等不下去了，回家。周五个别zemi，明天还得来做资料。 补：晚上买了作战室的预售，1450，出血。 今日学术记录","content":"<div class=\"note info\"><p>这里记录我的每一天🎭，如果每天都能想起来的话。<br> 记录的内容为流水账📰与心流📖的不可观测态————如果你想观察的话，那他就是流水账，反之亦然。</p></div>\n\n<span id=\"more\"></span>\n\n<h3 id=\"202601\" style=\"text-align:center; font-weight:bold;\">2026年01月</h3>\n<hr style=\"border: 2px solid #888; width: 100%; margin-top: 5px; margin-bottom: 15px;\">\n\n<h4 id=\"20260130\" style=\"text-align:center; font-weight:bold;\">2026/01/30 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>又是一个周五写总结的环节。</p>\n<p>这一周总体还是很忙的，修正毕业论文的摘要、提出；修正毕业论文本身，等等等。</p>\n<p>在这周里忙里抽闲还处理了一下搬家的各种事项：</p>\n<ul>\n<li>办理网络的“搬家”</li>\n<li>办理停煤气和停电</li>\n<li>计划退室立会</li>\n<li>找搬家公司:<ul>\n<li>第一家是79200，来見積もり的日本人横的像我是客户一样。</li>\n<li>第二家是80000，挺客气但是有点超出预算了。</li>\n<li>第三家是68860，包括了所有东西（捆包材免费，所有家具，床和桌子拆装）。个人觉得非常nice,直接就决定他家了。也是懒得来回比较了，所以直接选一个相对便宜的就完事了。</li>\n</ul>\n</li>\n<li>新家的水电煤气办理（还未定）</li>\n</ul>\n<p>论文相关部分见：<br><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20260130\">今日学术记录</a></p>\n<p>今天组会的时候（写这篇的5分前）提到了下次小组组会的日程，估计我是参加不太上了，老师对这个也是比较宽容：“明年开始不在研究室的同学，就自己看着参加吧。” 很好</p>\n<h4 id=\"20260124\" style=\"text-align:center; font-weight:bold;\">2026/01/24 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>又是两周没记录了，这两周不是很忙，但需要做的事还是很满的。写了一篇英文论文的摘要，准备了发表，进行了发表，写了毕业论文的摘要，稍微整理的毕业论文1-3章的内容。详细的还是见<a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20260124\">今日学术记录</a></p>\n<p>除了研究的话，1&#x2F;18去了大阪进行博物馆访问，参观了绢谷幸二 天空美术馆和大阪暮らしの今昔館(大阪生活变迁馆)。参观博物馆需要给财团写感想文，在这里一并贴出来：</p>\n<p>“今年，我参观了大阪生活今昔馆和绢谷幸二天空美术馆。在大阪生活今昔馆中，最令我印象深刻的是那些制作精细的模型。通过这些模型，我能够以直观、具体的方式理解大约一百年前大阪的生活状况和城市风貌。</p>\n<p>另一方面，我在三年前也曾参观过绢谷幸二天空美术馆。当时，除了绢谷幸二先生色彩鲜明、多姿多彩的经历之外，他在高龄之际仍持续积极投身于艺术创作与艺术教育的姿态，也让我感到由衷的惊讶与感动。</p>\n<p>今年的展览内容本身与三年前相比几乎没有变化，但在入馆前发放的一份宣传册却给我留下了深刻印象。宣传册中汇总了绢谷先生的生平经历，其内容是一篇追悼文。得知三年前仍为实现自身梦想而精力充沛地持续活动的绢谷先生，已经辞世，我感到极大的震撼。</p>\n<p>人生是短暂的。然而，如果能够像绢谷先生那样，将一生投入到自己真正热爱的事物之中，即使人生并不漫长，也依然能够具有深刻而重要的意义。”</p>\n<psw>写的日语的然后用chatgpt翻译过来的，AI味有点重</psw>\n\n<p>20号那天让一个搬家公司来进行了見積もり（就是上门报价），在几乎装了我所有家具的情况下，从京都到东京是79200。感觉还是可以的，但是没有直接同意，准备再比一比价格再去判断。</p>\n<p>21号那天的晚上本来预报说要下大雪，学校的通勤车都因此停运了（害我自己倒车回家）。但是从第二天白天的景象来看，好像完全没下雪一样。等于说校车白白休息了lol。</p>\n<h4 id=\"20250107\" style=\"text-align:center; font-weight:bold;\">2025/01/07 周三</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>2025&#x2F;12&#x2F;27-2026&#x2F;01&#x2F;04是日本的新年假期，这段时间没学习，一直玩来着。</p>\n<p>12&#x2F;27和01&#x2F;03都去了KUMA家玩桌游，玩了什么的话见桌游记录，在生活&gt;桌游里。</p>\n<p>12&#x2F;27的晚上去和日本朋友吃饭，一共五个人，吃了火凤源的火锅。当初他们提出要去吃火锅的时候我还挺惊讶，因为在我的印象中日本人不吃火锅这种共用餐具的东西。不过显然我的这种担心是多余的，他们是一点没见外，吃的比我都多。</p>\n<p>01&#x2F;02去了初詣（はつもうで｜hatsumoude）。日本的习俗里，每年的大年初一开始一直到正月十五（阳历）都可以去参拜，我们去了北野天满宫（是京都最大的天满宫）。我觉得这个参拜和国内的新年去逛土地庙财神庙的感觉差不多。大家对着神许下愿望，希望接下来的一年里身体健康，学业有成，事业圆满等等。进入天满宫之前有很长的小路，两端都是商贩，卖年糕、猪肉串、糖果、玩具之类的小玩意。</p>\n<p>日本在这一点和国内区别很大，国内的话商贩往往是在平常的时候出现，比如早夜市，路边摊等等。而日本的话平时是找不到路边摊的，只有在节日，庙会这些时候才会出现。他们比较像在“肝活动”：没有固定的出摊位置，而是随着活动地点的变化而出现。他们每次都会去报名各个活动的摊位，所以每次的活动里出现的摊位就那么几个（因为都是一拨人）。<br><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20260107\">今日学术记录</a></p>\n<h3 id=\"202512\" style=\"text-align:center; font-weight:bold;\">2025年12月</h3>\n<hr style=\"border: 2px solid #888; width: 100%; margin-top: 5px; margin-bottom: 15px;\">\n\n<h4 id=\"20251226\" style=\"text-align:center; font-weight:bold;\">2025/12/26 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>又是在小组组会的间隙时抽空写博客的一天。</p>\n<p>···</p>\n<p>好巧不巧，虽然刚发表完最终报告以及和老师讨论完接下来要做的事情，但是这周恰巧也是我们小组的组会。于是就导致了一个比较尴尬的场面，能讨论的都讨论完了，只能尬聊。而日本人还比较不变通，也不改变时间，大家就尬聊（当然也有可能是如果改了我们这周的日程就以后的都得改，牵一发而动全身了）。</p>\n<p>周三的反馈总体也还行。目前为止的研究内容已经可以作为毕业论文发表了。但是如果想真正的解决老师想看的问题还不太够，得构思几个新的指标然后看看结果。详细的还是见研究记录。对于我是挺好的，毕竟意味着我如果想要有事情干也能有，想摆烂也ok哈哈。没什么压力的时候就发现做研究还是挺有意思的。貌似什么都是这样吧，就算是爱好，当他变成工作的时候也会有压力。不过如果没有压力的话，因为没有对比，爱好也就没什么意思了。两者就是一个巨大的围城：没有压力只玩的时候会觉得空虚，找点事情做；而正事很多、压力很大的时候就会一直期盼着能玩一玩，享受属于自己的一隅。<br><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251226\">今日学术记录</a><br>···</p>\n<p>周四是圣诞节，收到了女朋友送我的想要已久的《战锤试涂包》！！！。周五和女朋友试着涂了一下，不愧之前学过很多类型的美术，她真的是比我在这方面更有天赋，在上色和控笔上都更稳一些。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/20251225.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/20251225.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"阿斯塔特\" width=\"70%\">\n  <p style=\"text-align:center;\">第一次涂得战锤，以后也是锤佬了哈哈哈</p >\n</div>\n\n<p>涂装还是很有趣的，对于我也是很重要的。因为我发现在涂装的时候我找到了久违的那种专注感。这种感觉自从我小时候拼乐高的时候就很少出现了。玩游戏很难让我找到这种感觉因为负罪感很重，而涂装就刚刚好。涂装的时候，精神集中在面前的阿斯塔特上，而可以把耳朵空出来来听视频，评书之类的。控笔的紧张感和听视频的放松感两者相辅相成，很适合放空大脑。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/2025122502.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/2025122502.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"战锤涂装\" width=\"70%\">\n  <p style=\"text-align:center;\">另一面</p >\n</div>\n\n<p>···</p>\n<p>圣诞节和女朋友买了吮指原味鸡以及订了巧克力蛋糕吃。略有遗憾的就是今年年末年初因为两个人都很忙就没能出去玩上，不过我相信毕业旅行会弥补的。晚上一边吃蛋糕，一边看CBA辽宁打浙江来着，谁赢了不知道，看到一半就看不下去了。辽宁这球传的真是离谱。</p>\n<h4 id=\"20251224\" style=\"text-align:center; font-weight:bold;\">2025/12/24 周三</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>昨天的发表整体上没什么问题，但是老师给我的反馈，或者说疑问让我很头疼。<wavy>简单来说就是在给我题目的时候，说这个研究的目的是A。我按照A做好了结果和分析，发表之后，老师说我们的目的其实是A+++（本质上是A但是复杂多的多得多）你这个结果不能证明我们想要的结论。</wavy></p>\n<p>发表结束后是一个 Chistmas lunchparty 有寿司和肯德基的吮指原味鸡和冰淇淋。很好吃。其实我觉得我们研究室这种中型的小party还挺多，每次都能吃到不一样的食物。这一点还是很棒的。</p>\n<p>lunchparty结束后就四点了，本来晚上6点有忘年会，但是学长看大家的都吃的很饱了，就把时间调成了七点。忘年会在PISOLA，一个西餐（披萨，意面，烩饭，冷盘）的自助餐厅。3400日元一个人，食物很好吃但是大家都没什么肚子了，于是唠嗑闲谈偏多。</p>\n<p>今天的全体组会之后老师会一对一的给出研究上的反馈和接下来一个月的建议。希望不要给我改动太多。</p>\n<h4 id=\"20251223\" style=\"text-align:center; font-weight:bold;\">2025/12/23 周二</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n时隔一个月，终于有时间来更新博客了。上次更新是11.27，这一个月可真的是忙到脚打后脑勺。主要干了两件大事：12.3-6去东京找房子；12.8-23准备研究室的最终报告和发表。一件一件说\n\n<p><u>12.3-6东京：</u></p>\n<p>因为明年要去东京读研，所以要提前把房子给找好，不然到时候一是没有房子，二是有的话条件会很差且贵（因为好的被别人挑完了）。正好这一周研究室没有zemi，于是打好提前量，出发去了东京。到了东京之后先在东大附近转了转，发现一般的中介公司都没有开门。</p>\n<p>漫步东大周围，左看看右看看，好似刘姥姥进大观园。正是银杏落叶的季节，满大街都是金黄的叶和散发着气味的银杏果，这两者结合就产生了一幅很有趣的画面：游人三三两两聚在一起，一边为让自己与银杏的金黄融为一体去寻找最合适的角度拍照，一边为了避免踩到银杏果而蹦蹦跳跳。东京大学的校徽就是两片银杏叶，校园里也种满了银杏。黄灿灿的叶子尽职尽责，一丝不苟的覆盖着大地，直到让他失去了原本的颜色才肯罢休。</p>\n<p>走着走着终于发现了一家中介开着门，便走了进去。这是一家非常日式，且有年代的店了，看起来不像是连锁的。进门后说明来意，一位爷爷接待了我，并奉上热茶。他解释说周三一般是不动产业的休息日，因为中介公司都要向不动产业来确认各种事项，所以也在这一天一并休息了。给我介绍了两个房子之后，都因为不太和我的胃口，所以也就不了了之了。</p>\n<p>晚上去吃了心心念念的烤鸭。还是东京的食物总类比较丰富，想吃到什么都能吃到啊。</p>\n<p>周四去了中介公司，简单看过推荐的物件之后便直奔之前在网上看好的 house。因为房子里的住户还没有退房，所以仅仅在外面看了一下日照和周围环境便告一段落。这个房子无论在大小还是价格还是位置都非常令我满意，唯一的缺点可能是向东，采光一般。上一个住户在这里住了十年，所以我坚持在进入看看房子的内部状态之后再签约。计划的是一月份拜托朋友去看一下内部状态，然后决定签约与否。</p>\n<p>因为周四提前完成了找房子的任务，周五就变为了单纯的逛逛东京。先后去了几个地方：原宿的怪奇物语快闪店；新宿的骏河屋；新宿的黄色潜水艇；最后在高马吃了两顿饭。原宿的怪奇物语店比较小，一楼右手边是买东西的地方（可能因为我去的比较晚性价比高的东西都没了，只剩衣服拖鞋之类的），左手边模拟了拜尔斯家的经典沙发后面彩灯1-17数字的场景，旁边的小桌子上还有dnd的模型。二楼是卖冲浪小子披萨和咖啡茶冰淇淋的地方。人多还比较狭窄所以十分拥挤。</p>\n<p>周六去参加财团活动然后回京都，晚上去看了《疯狂动物城2》剧情很简单，但是不愧是迪士尼大IP，总能让人找到最原始，最纯粹的幸福感。</p>\n<p><u>12.8-23 最终报告的执笔；最终发表的准备</u></p>\n<p>接下来是痛苦的半个月，无休无尽的写程序、debug、写论文、改论文、做ppt、改ppt是这半个月的最真实的写照了。好在写完了，23号也就是今天，最终发表，现在我正在等待自己的发表，终于空下来时间不用研究，遂回忆一下这半个也然后写一下记录。</p>\n<p>研究内容相关的话见研究记录。最后截止第一次最终报告交稿（还不是毕业论文），算参考文献我的论文已经写到50页，20000字了。真是个大工程。</p>\n<p>现在在等待我的发表，我已经能想象到发表完得被不少说，因为我仅仅来得及把结果都列出来，从结果能得到一个初步结论，但是尚未有时间来写是什么原因导致了这个结果等等。随遇而安吧。</p>\n<p><u> 12.20 忙里抽闲，去了大佬家玩桌游</u></p>\n<p>人，总是要稍微休息一下的。经历了两周高压的研究之后，下定决心放松一下，周六便去玩桌游了。详细的还是放在桌游记录里</p>\n<h3 id=\"202511\" style=\"text-align:center; font-weight:bold;\">2025年11月</h3>\n<hr style=\"border: 2px solid #888; width: 100%; margin-top: 5px; margin-bottom: 15px;\">\n\n<h4 id=\"20251127\" style=\"text-align:center; font-weight:bold;\">2025/11/27 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>周二周三都在研究室度过。<br>周三完成了发表，周四终于能休息一下了。没有太多要说的 见<a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251127\">今日学术记录</a></p>\n<h4 id=\"20251122\" style=\"text-align:center; font-weight:bold;\">2025/11/22 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天终于又组起来了桌游局，开了炸弹克星。\n\n<p>炸弹克星应该是我们几个一直在一起玩的朋友一致觉得的本年度最佳游戏了（真的真的很好玩）<br>详细测评见<a href=\"/categories/daily/%E6%A1%8C%E6%B8%B8/%E7%82%B8%E5%BC%B9%E5%85%8B%E6%98%9F%E7%9F%AD%E8%AF%84\">炸弹克星短评</a></p>\n<h4 id=\"20251121\" style=\"text-align:center; font-weight:bold;\">2025/11/21 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>周一到周五手忙脚乱，没有闲暇时间顾及博客。直到今天的组会<del>听别人发表的时候</del>才有机会小小更新一下。<br><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251123\">今日学术记录</a><br>周二周三都是研究室度过完整一天。周四去了财团的<strong>hirose展</strong>。今天开组会。 晚上都在准备组会和下周的发表的材料。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/20251120.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/20251120.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"展馆外\" width=\"70%\">\n  <p style=\"text-align:center;\">展馆外</p >\n</div>\n\n<p>说一下hirose展吧：</p>\n<ul>\n<li>hirose技術展，是我的财团——ヒロセ財団法人的母公司 <strong>ヒロセ電機</strong> 所创办的展示公司技术的展会。</li>\n<li>展会每三年一次，届时邀请各个使用了hirose技术的公司，以及借出他们的产品来进行展示。<em>这里需要说明一下</em>：因为hirose本身的产品主要为***连接器(connector)***所以需要依靠各个下流公司的产品来进行说明。</li>\n</ul>\n<div class=\"note info\"><p>ChatGPT：<strong>连接器（connector）</strong><br/> 连接器（connector）是一种使两个电子部件能够电性连接并传输信号或电力的元件。它的作用就像“桥梁”，让电路板、线缆或设备之间能够方便、稳定地接合与分离。常见于手机接口、电脑主板插槽、汽车电子等，是所有电子设备中不可或缺的基础部件。</p></div>\n\n<ul>\n<li>展会里有很多hirose电机的产品的应用：耳机，手机，医疗机器人，电脑，电动车等等等。<del>学环境的着实是看不懂</del></li>\n</ul>\n<h4 id=\"20251117\" style=\"text-align:center; font-weight:bold;\">2025/11/17 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n上周因为研究室的学长学姐去了巴西开IAMC年会【Integrated Assessment Modeling Consortium（综合评估模型协会）】，所以研究室取消了zemi，喜提一周假期😋。\n\n<p>一周里倒是明确和学习了不少关于ML的东西。</p>\n<p>其中最重要的是明确了以后想干什么——查了一些资料，看了看学长学姐的经验贴，想了想自己到底想干什么。</p>\n<p>看了很多，最后觉得自己还是喜欢编程，想干IT相关。但是因为非科班，所以还不能干非常纯粹的IT。遂觉得咨询行业的IT岗（MLE, Machine learning engineer）是不错的选择。（如果能进四大+A社就最好了）</p>\n<p>确定下来自己的想干什么之后，就开始着手学习。因为学部学的内容完全不同，所以很多科班出身的同学习以为常的事情需要从头学起。以下是上周学习了的内容。</p>\n<p>（特别提一句，这个docker部署耽误了我起码两天的时间。因为docker拉镜像和部署ubuntu之类的东西非常占内存而我的笔记本c盘还爆满，所以删缓存和尝试软链接废了不少功夫。<psw>最后也是成功的放弃了</psw></p>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>看了看成为MLE需要掌握的内容</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>MLE面试的主要流程</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>下载了相关资料（ebook,学习路线）</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>DOCKER是什么，有什么用和试部署</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>看完了《深度学习入门：基于Python的理论与实现 (斋藤康毅)》</p>\n            </div>\n<div class='checkbox blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>统计学习的基础(B站简博士，正在看)</p>\n            </div>\n\n<p>准备写一个MLE面试的准备随笔。</p>\n<p>不过俗话说得好：“如果你平时一直在很悠闲的洗脚，那么期末的时候就是你把洗了一学期的洗脚水喝掉的时候。”<br>这周开始就得给前些日子买单了，周五个别zemi；下周三大zemi全都要准备。</p>\n<p>今天一天在研究室 详见<a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251117\">今日学术记录</a></p>\n<h4 id=\"20251116\" style=\"text-align:center; font-weight:bold;\">2025/11/16 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天终于把大名鼎鼎的鱼书，也就是《深度学习入门：基于Python的理论与实现 (斋藤康毅)》给看完了，之前看到MNIST的地方发现完全看不懂，所以索性自学了一遍MNIST的pytorch和scratch版<a href=\"https://middlemanz.com/categories/research/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%88%E4%BB%8E%E9%9B%B6%E5%AE%9E%E7%8E%B0%EF%BC%89/\">文章点此跳转</a>。今天看的时候才发现原来后面整篇都在讲MNIST😅。<br>不过话说回来，这本书对于初学者还是很有帮助的，无论是在讲误差反向传播法还是后面的超参数优化，感觉学到了蛮多东西。推荐一下。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/20251116.png\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/20251116.png\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"鱼书\" width=\"40%\">\n  <p style=\"text-align:center;\">鱼书</p >\n</div>\n\n<h4 id=\"20251115\" style=\"text-align:center; font-weight:bold;\">2025/11/15 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天新开了《并购》和《暗藏杀机》都是两人局。\n\n<p>《并购》给我的感觉是机制很简单（好像是1963年的桌游），但是计算量很大。两个人玩的话博弈点比较少，可能多人局会好一些。</p>\n<p>《暗藏杀机》是比较机制基础的推理类桌游<psw>本质上是排除法练习器笑</psw>。我相对来说喜欢这个一些。</p>\n<p>玩了一局后感觉凶手比较好赢？可能是我比较菜。</p>\n<h4 id=\"20251110\" style=\"text-align:center; font-weight:bold;\">2025/11/10 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天去研究室。一天都在跑模型，见链接。<br>晚上完了方舟动物园，又输了555😭。</p>\n<p><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251110\">今日学术记录</a></p>\n<h4 id=\"20251109\" style=\"text-align:center; font-weight:bold;\">2025/11/09 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天在家一天。<br>整理了博客的一些内容，创建了一个github库准备作为自己作品集来展示。<del>与其说是作品不如说是破烂</del><br>我发现当我开始整理这些东西的时候就有无穷的精力和兴趣。<br>人还是得做一些自己感兴趣的事情。</p>\n<p>吃饭之余看了《惊天魔盗团2》从芯片公司出来那段其实从各种剪辑中已经看过无数次了。不过第一次完整的看完的时候还是感觉很震撼。这才叫魔术！</p>\n<h4 id=\"20251108\" style=\"text-align:center; font-weight:bold;\">2025/11/08 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天去四条吃了烤肉和配了新眼镜。至此陪伴我三年的眼镜就告一段落了。<br>三年来左眼涨了50，右眼涨了25。（我感觉我平时因为学习和研究用电脑的时间还是很长的，只变化了这么少感觉还可以）</p>\n<psw>烤肉真香，给あぶりや打广告</psw>\n\n<h4 id=\"20251107\" style=\"text-align:center; font-weight:bold;\">2025/11/07 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天看了《惊天魔盗团》。\n<div class=\"tag link\"><a class=\"link-card\" title=\"惊天魔盗团 豆瓣\" href=\"https://movie.douban.com/subject/6517421/\"><div class=\"left\"><img src=\"https://unpkg.com/volantis-static@0.0.1660614606622/media/org.volantis/logo/256/safari.png\" class=\"lazyload\" data-srcset=\"https://unpkg.com/volantis-static@0.0.1660614606622/media/org.volantis/logo/256/safari.png\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\"/></div><div class=\"right\"><p class=\"text\">惊天魔盗团 豆瓣</p><p class=\"url\">https://movie.douban.com/subject/6517421/</p></div></a></div>\n这电影也是在各种电影剪辑中出现的常客了笑，今天也终于一睹芳容。电影很好看，不论是魔术本身还是剧情，都很吸引人。\n\n<p>最后有一点没太看懂：</p>\n<p>警探召集四个魔术师是为了报复保险公司和黑人老头。报复保险公司可以理解，因为保险公司直接导致了他父亲的死亡。但报复老头这一点我没太看懂，究其原因，本质上他父亲还是因为着急证明自己才失败的，和老头并没有直接关系。所以就动机而言没太明白。</p>\n<h4 id=\"20251106\" style=\"text-align:center; font-weight:bold;\">2025/11/06 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天终于通关了银河破裂者的战役模式。下一步就是生存了，感觉这个游戏还有可以发掘的潜力。\n\n<h4 id=\"20251105\" style=\"text-align:center; font-weight:bold;\">2025/11/05 周三</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天去了研究室，无话。<br><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251105\">今日学术记录</a></p>\n<h4 id=\"20251104\" style=\"text-align:center; font-weight:bold;\">2025/11/04 周二</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天试着开了《方舟动物园ark nova》。整体玩下来感觉如下：\n<div class='checkbox green checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>游戏入门不难，精通很难</p>\n            </div>\n<div class='checkbox green checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>机制很多很杂糅但是融合的很好</p>\n            </div>\n<div class='checkbox green checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>风味很足，卡面上的原画照片很写实出彩</p>\n            </div>\n<div class='checkbox green checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>打出一串combo之后很爽</p>\n            </div>\n<div class='checkbox times red checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>买的是鹿王的diy，不知道是什么原因灰很大，玩完了直接粉尘过敏</p>\n            </div>\n\n<h4 id=\"20251103\" style=\"text-align:center; font-weight:bold;\">2025/11/03 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n\n<p>今天集运的桌游到货了!又能玩很长时间了😁<br>新桌游收藏+：</p>\n<div class='checkbox plus blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>方舟动物园</p>\n            </div>\n<div class='checkbox plus blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>灵迹岛+扩</p>\n            </div>\n<div class='checkbox plus blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>权力的游戏版图版+扩</p>\n            </div>\n<div class='checkbox plus blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>SETI</p>\n            </div>\n<div class='checkbox plus blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>暗藏杀机</p>\n            </div>\n<div class='checkbox plus blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>并购</p>\n            </div>\n<p>在煤炉上购入了+:<br></p>\n<div class='checkbox plus blue checked'><input type=\"checkbox\" checked=\"checked\"/>\n            <p>惨剧轮回</p>\n            </div>\n\n<h4 id=\"20251102\" style=\"text-align:center; font-weight:bold;\">2025/11/02 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天女朋友给我烙一直想吃的牛肉馅饼了！🥙\n好吃！！完美符合心里的味道。\n\n<p>我也做了小白菜土豆汤🥬和西红柿牛腩。🐂</p>\n<p>两个人一起照着星露谷物语的食谱书做了爆炒青椒🌶(芝士青椒)</p>\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/25110201.png\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/25110201.png\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"爆炒青椒\" width=\"85%\">\n  <p style=\"text-align:center;\">星露谷的爆炒青椒 挺像的</p >\n</div>\n图片详见foods页面。\n\n<h4 id=\"20251101\" style=\"text-align:center; font-weight:bold;\">2025/11/01 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天终于有机会去大佬家里一睹大佬的收藏了。\n\n<p>最开始是在小红书上刷到了大佬的帖子，当时就被大佬的丰富的桌游收藏和舒适的配套设备给震惊到了。正好大佬也在找人一起玩，遂联系了大佬。</p>\n<p>无奈他工作比较忙，一直等到了这个三连休才有了一些空闲时间。于是终于如愿以偿去拜访大佬了。</p>\n<p>——————</p>\n<p>一进门，映入眼帘的是一个桌游专用桌子（似乎是满座家的）。围绕着桌椅有四个架子和数不清的柜子。左边先是一个小矮柜，放着一些毛线（作弊飞蛾、血蔷薇什么的），柜子的右边紧挨着一个挤满了中号盒子的德式+小美式的架子。大佬的收藏真的是包罗万象，就中号盒子大小的桌游来说，不存在我认识但是没看到的情况。新出至ARCS，经典如MANILA，无奇不有。</p>\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/110101.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/110101.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"家\" width=\"70%\">\n  <p style=\"text-align:center;\">大佬的家</p>\n</div>\n在右边是一个大美的战区，从上往下，诡镇惊魂、血源诅咒、德鲁纳格编年史等等琳琅满目，模型收纳在对应的盒子里，可以直接抽出来欣赏。\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/110102.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/110102.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"家\" width=\"70%\">\n  <p style=\"text-align:center;\">大美架子</p>\n</div>\n拐角的右面也是一个大美的架子，右面还是一个大美的架子（貌似大佬家里全是大美笑）。简单列一下大佬的收藏的话：大老鼠、COC、PRIMAL、Return to the darktower、阿瑞迪亚、霜港迷城 ......\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/110103.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/110103.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"家\" width=\"70%\">\n  <p style=\"text-align:center;\">大美架子2</p>\n</div>\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/110104.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/110104.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"家\" width=\"70%\">\n  <p style=\"text-align:center;\">大美架子n</p>\n</div>\n除了传统的桌游，当然还少不了各式模型。我对模型的了解不多，仅仅能从茫茫模型海中识别出来一部分：战锤的极限战士，COC的经典模型等等。\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/110105.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/110105.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"家\" width=\"70%\">\n  <p style=\"text-align:center;\">战锤的模型</p>\n</div>\n<div align=\"center\">\n  <img src=\"/images/daily/daily/record/110106.jpg\" class=\"lazyload\" data-srcset=\"/images/daily/daily/record/110106.jpg\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\" alt=\"家\" width=\"70%\">\n  <p style=\"text-align:center;\">未知模型不过很酷</p>\n</div>\n<psw>::从现在开始，我的人生目标变更为能拥有这样的收藏笑</psw>\n\n<p>题外话:我觉得拥有一个桌游专用的大桌子对于提升幸福感是非常重要的。无论是从便利方面还是从‘专用’方面都能很高的提升玩桌游的体验。争取到了东京之后搞一个大桌子。</p>\n<p>今天在大佬家玩了《阿瑞迪亚》,详见:</p>\n<p><a href=\"/categories/daily/%E6%A1%8C%E6%B8%B8/%E6%A1%8C%E6%B8%B8%E6%97%A5%E5%B8%B8/#20251101\">今日桌游记录</a></p>\n<h3 id=\"202510\" style=\"text-align:center; font-weight:bold;\">2025年10月</h3>\n<hr style=\"border: 2px solid #888; width: 100%; margin-top: 5px; margin-bottom: 15px;\">\n\n<h4 id=\"20251030\" style=\"text-align:center; font-weight:bold;\">2025/10/30 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天是研究室运动大会。因为周四一般不去研究室，早上生物钟没调过来，没起来去坐往常那班校车，只能坐下一班。不过好歹也是赶上了。\n\n<p>着重说一下今天的研究室的スポーツ大会：</p>\n<div class=\"note info\"><p><strong>スポーツ大会スケジュール（体育大会安排）</strong><br> 12:15-13:00　サッカー(10分×2セット)<br> 13:00-13:30 バドミントン(ダブルス3面×3)<br> 13:40-14:10 バスケットボール(10分×2セット)<br> 14:20-14:50 バレー(30点先取・デュースあり)<br> <strong>Sports Tournament Schedule</strong><br> 12:15-1:00 PM Soccer (2 sets of 10 minutes)<br> 1:00-1:30 PM Badminton (3 courts of doubles)<br> 1:40-2:10 PM Basketball (2 sets of 10 minutes)<br> 2:20-2:50 PM Volleyball (First to 30 points, with deuce)</p></div>\n\n<p>日本人这个体能是真的强，从12:15到15:00点全是高强度有氧，可谓是铁人四项了。</p>\n<p>我没参加足球（因为一窍不通），但是参加了其他三项。篮球和羽毛球虽然说之前都学过，但是已经荒废很久了，也就是一个略懂规则的水平。排球从初一打到高三，比前两者能强不少。和研究室同学们打绰绰有余，但是去专业的社团就只有被吊打的份了。</p>\n<p>之前健身一直都是健无氧，基本不做有氧，今天三个小时的有氧坐下来感觉整个人已经离世界有一段距离了🤣<br><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251030\">今日学术记录</a></p>\n<h4 id=\"20251028\" style=\"text-align:center; font-weight:bold;\">2025/10/28 周二</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n和tutee吃饭，学习，更新blog，打游戏。\n本来今天要去复查眼睛的，正好因为镜框掉漆想重新配一个，一起安排到下周二了就不用去两次了。\n\n<h4 id=\"20251027\" style=\"text-align:center; font-weight:bold;\">2025/10/27 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n又是weekly report去了研究室。\n因为上周一直在摸鱼，研究根本没有什么进展，所以在去学校的路上还想了好一阵子能报告点什么。最后还是使用模糊的语言糊弄过去了。\n所谓模糊的语言，也是向研究室的前辈们学的，无非就是：\n<div class=\"note quote\"><p>进行了文献调查</p></div>\n<div class=\"note quote\"><p>对模型进行了debug</p></div>\n<div class=\"note quote\"><p>整理了代码</p></div>\n这种，似是而非的话术。我看了一个报告，也算进行了文献调查；看了看代码，也叫整理了代码。看上去非常唬人，实际上根本不能细致推敲。\n还好老师也不细问大家都干了什么，所以皆大欢喜。\n\n<psw>这部分内容在以后把网站发给hr之前可得删掉</psw>\n\n<p><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251027\">今日学术记录</a></p>\n<p>本质上上一周要专门记录的内容比较少，为了避免过于流水账，<emp>就只在这一条下面挑重点来写了。</emp></p>\n<p>周二因为淘宝双十一活动开始了，激情下单了很多桌游，坐等集运。等集运到了会po<br>周三和周四和朋友联机了银河破裂者 <div class=\"tag link\"><a class=\"link-card\" title=\"银河破裂者\" href=\"https://store.steampowered.com/app/780310/The_Riftbreaker/?l=schinese\"><div class=\"left\"><img src=\"https://unpkg.com/volantis-static@0.0.1660614606622/media/org.volantis/logo/256/safari.png\" class=\"lazyload\" data-srcset=\"https://unpkg.com/volantis-static@0.0.1660614606622/media/org.volantis/logo/256/safari.png\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\"/></div><div class=\"right\"><p class=\"text\">银河破裂者</p><p class=\"url\">https://store.steampowered.com/app/780310/The_Riftbreaker/?l=schinese</p></div></a></div>。最开始以为是RTS，但玩了半天发现没有造兵元素。与其说是RTS不如说是基地建设+第三人称打怪爽游。不过游戏还是不错的<br>周日学习复现了一下MNIST手写数字识别的机器学习项目。</p>\n<h4 id=\"20251020\" style=\"text-align:center; font-weight:bold;\">2025/10/20 周一</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天weekly report 去了研究室。\n\n<p><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251020\">今日学术记录</a></p>\n<p>有一个很搞笑的好消息。为了继续我的研究，本来有A、B两个活，学长帮我干了A说接下来想然我干B。然后老师发邮件过来让我干A，学长一看就把他做好的A发过去了。老师大喜过望说太好了那你等一会我给你把B整完。<br>合着两个都不需要我做哈哈哈。</p>\n<h4 id=\"20251019\" style=\"text-align:center; font-weight:bold;\">2025/10/19 周日</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天去大阪天下茶屋玩了线下血染钟楼。\n应该是我第二回正式玩血染，第一回是和老瘸在沈阳的桌游店里玩的。\n当时还觉得这个游戏云里雾里，后面才知道这个游戏的乐趣。\n在我看来血染的乐趣在于1：参与感；2：不确定性。参与感指每一个人都有技能能干自己的事情，不至于像狼人杀的平民一样束手无策只能靠瞎猜。而不确定性代表这个游戏的逻辑是基本上不会闭环的，意味着大概率出现两个截然相反而又互相不能证伪的逻辑。这就给了游戏以及玩家很大的发挥空间，玩家比起死盘逻辑更需要“证明给别人看自己是对的”。我很喜欢这种，至少他赋予了每一位玩家可操作的空间。\n\n<h4 id=\"20251018\" style=\"text-align:center; font-weight:bold;\">2025/10/18 周六</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天女朋友给我买了最新的苹果手表作为生日礼物！其实很多事情没必要拿来炫耀😅就好像我女朋友2025年10月18日给我买了Apple Watch S11，女朋友给我买了Apple Watch S11这件事没必要天天提，因为我知道2025年10月18日女朋友给买Apple Watch S11的人多的是，天天提2025年10月18日女朋友给我买就显得好像只有我知道我2025年10月18日拥有了Apple Watch S11一样，现在你也知道2025年10月18日我女朋友给买了Apple Watch S11，我女朋友在2025年10月18日给我买了Apple Watch S11就买了呗，就这样吧，反正我女朋友在2025年10月18日给我买了Apple Watch S11。\n\n<p>作为圣诞礼物，给小鸡买了迪奥的圣诞眼影礼盒，她看起来很开心。就很好。</p>\n<h4 id=\"20251017\" style=\"text-align:center; font-weight:bold;\">2025/10/17 周五</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天个别zemi，早上九点半开始。\n\n<p>每次个别zemi就需要我去做一个抉择：</p>\n<ul>\n<li>7:30出发，换乘2次bus,9:06到——这个选择就是早起+公交站票+提前到。</li>\n<li>8:30出发，做学校bus,不换乘，9：25-35到——这个是睡觉+舒服+有可能迟到。</li>\n</ul>\n<p>那聪明的人已经猜到我会选什么了，只是正常人类都会选的😁</p>\n<p><del>不过今天迟到了五分钟。</del><br>意外的是个别zemi的发表很顺利。老板好像挺满意我的进展。这就好。</p>\n<p><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251017\">今日学术记录</a></p>\n<h4 id=\"20251016\" style=\"text-align:center; font-weight:bold;\">2025/10/16 周四</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天还是研究室，研究又出现了进展，令人欣喜。\n\n<p>研究就像是淘金和掏粪的合体。你永远不知道下一秒是暴富还是给你拉个大的。</p>\n<p>一直做个别zemi的资料做到十二点，无话。</p>\n<p><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251016\">今日学术记录</a></p>\n<h4 id=\"20251015\" style=\"text-align:center; font-weight:bold;\">2025/10/15 周三</h4>\n<hr style=\"border: 1px solid #bbb; width: 100%; margin-top: 3px; margin-bottom: 10px;\">\n今天全体组会，加上周五有个别组会，无论如何都得去研究室了。\n\n<p>上周因为财团旅游而小小逃课了一下，很爽，但是终究今天和明天还得给逃的课买单。不做研究没成果的话，组会就得挨说。</p>\n<p>幸好今天研究终于取得了一些进展。不过因为模型还没跑完，能不能成功还是未知。</p>\n<p>已经四个小时了，等不下去了，回家。周五个别zemi，明天还得来做资料。</p>\n<p>补：晚上买了<strong>作战室</strong>的预售，1450，出血。</p>\n<p><a href=\"/categories/research/%E6%97%A5%E5%B8%B8/%E7%A0%94%E7%A9%B6%E6%97%A5%E5%B8%B8/#20251015\">今日学术记录</a></p>\n","categories":[{"name":"daily","slug":"daily","permalink":"https://middlemanz.com/categories/daily/"},{"name":"每日记录","slug":"daily/dailyrecord","permalink":"https://middlemanz.com/categories/daily/dailyrecord/"}],"tags":[{"name":"桌游","slug":"桌游","permalink":"https://middlemanz.com/tags/%E6%A1%8C%E6%B8%B8/"},{"name":"日常","slug":"日常","permalink":"https://middlemanz.com/tags/%E6%97%A5%E5%B8%B8/"},{"name":"生活","slug":"生活","permalink":"https://middlemanz.com/tags/%E7%94%9F%E6%B4%BB/"}]}]